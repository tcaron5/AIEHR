{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc9378b-aa4a-480f-a08a-4a0177fa793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ChatGoogleGenerativeAI (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for ChatGoogleGenerativeAI\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain-community langchain-openai langchain-chroma langchain langchain-huggingface \n",
    "\n",
    "# !pip install langchain_google_genai\n",
    "# !pip install langchain_groq \n",
    "\n",
    "# !pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55152de9-756b-4bfd-b609-01a36875c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e21c6cf3-4d03-426e-bd0c-a51bfae67a91",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory not found: 'discharge_me/data/test_phase_2/all_text_data_by_hadm_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdischarge_me/data/test_phase_2/all_text_data_by_hadm_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(path, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, loader_cls\u001b[38;5;241m=\u001b[39mTextLoader)\n\u001b[0;32m----> 3\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_community/document_loaders/directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/langchain_community/document_loaders/directory.py:123\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m p \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory not found: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected directory, got file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory not found: 'discharge_me/data/test_phase_2/all_text_data_by_hadm_id'"
     ]
    }
   ],
   "source": [
    "path = \"/work/AI-EHR/discharge_me/data/test_phase_2/all_text_data_by_hadm_id\"\n",
    "loader = DirectoryLoader(path, glob=\"*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e89089f9-8cde-42f0-8dee-91bb1e0f2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import GROQ_API_KEY, OPENAI_API_KEY2\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e01cf4-3c63-49a6-98e0-13a7b39058c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ca3097-eda7-4d21-9de6-0bbf69c37f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards: 100%|██████████| 4/4 [01:36<00:00, 24.16s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:25<00:00,  6.39s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=500, device = 0\n",
    ")\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2e17f8-c5a7-4c01-a051-4b340c1a1c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahajan.d/.conda/envs/ai-ehr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:11<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"epfl-llm/meditron-7b\",\n",
    "    task=\"text-generation\",\n",
    "    device=0,\n",
    "    pipeline_kwargs={\"max_new_tokens\": 500},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59626524-8ec8-4c2e-8346-c3101b18433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    " \n",
    "History of Present Illness:\n",
    "___ with ___ pemphigoid who presents with leg swelling and \n",
    "complaints of oral ulcers.  \n",
    " Patient is very difficult to get an accurate history from as he \n",
    "exhibits significant tangentiality and does not answer questions \n",
    "directly.  \n",
    " He states both legs are very swollen. Unclear how long this has \n",
    "been going on for. He was discharged from the ED in ___ for \n",
    "similar complaints. He was given a course of Keflex for \n",
    "cellulitis, but he states that the antibiotics never work.  \n",
    " He also complains of his bullous pemphigoid and how it has \n",
    "turned into lymphoma in his mouth. He also endorses diffuse \n",
    "lymphadenopathy. This has been going on for years. He has not \n",
    "seen a dermatologist in ___ in a long time (unclear just how \n",
    "long) because according to him not a single dermatologist in \n",
    "___ treats bullous pemphigoid. He says he has talked to ___ \n",
    "___ about getting his BP treated but has had trouble ever \n",
    "getting in touch with a doctor directly.  \n",
    " Patient states that his abdomen is swollen but cannot give a \n",
    "time course. He  \n",
    " He was referred into the ED by his PCP for evaluation of his \n",
    "leg lesions and abdominal swelling. His weight is 205 today, \n",
    "which is up from 162 in ___.  \n",
    " In the ED, initial vitals were: 97.9 92 116/72 22 97% RA \n",
    "93.2kgs  \n",
    " - Labs notable for WBC of 12.5  \n",
    " - Imaging: LLE US did not show evidence of DVT; CXR showed mild \n",
    "cardiomegaly and mild vascular congestion.  \n",
    " - Bedside US did not show any evidence of ascites.  \n",
    " Patient was given: Duonebs and CTX 1g IV for LLE cellulitis  \n",
    " \n",
    "Past Medical History:\n",
    "PAST MEDICAL HISTORY:  \n",
    "- Bipolar  \n",
    "- Hepatitis C  \n",
    "- HLD  \n",
    "- Diabetes, steroid-induced  \n",
    "- Self-reported bullous pemphigoid, but no clinic or laboratory \n",
    "evidence to support this diagnosis\n",
    "- COPD  \n",
    "- Cholelithiasis  \n",
    "- GERD  \n",
    "- Aortic aneurysm  \n",
    "- Osteoporosis  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74823df3-b218-42fa-a0fc-5bd0f0d2e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "            You are a helpful Medical AI assistant. Answer the question based on the context provided. Respond only if the answer is in the context.\n",
    "            If the answer is not in the context then respond, Cannot answer the question.\n",
    "            Stick to the context while answering and be concise.\n",
    "            context: {context}\n",
    "            question: {input}\n",
    "            answer:\n",
    "            \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ba7d32-1e60-46bc-b4ef-cf38ac67b35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "question = \"Given the History of Present Illness, What is the relevant past medical history?\"\n",
    "gpu_chain = prompt | hf\n",
    "response = gpu_chain.invoke({\"input\": question, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424e0dbf-4004-4ab8-917a-02e868cae674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            You are a helpful Medical AI assistant. Answer the question based on the context provided. Respond only if the answer is in the context.\n",
      "            If the answer is not in the context then respond, Cannot answer the question.\n",
      "            Stick to the context while answering and be concise.\n",
      "            context: \n",
      " \n",
      "History of Present Illness:\n",
      "___ with ___ pemphigoid who presents with leg swelling and \n",
      "complaints of oral ulcers.  \n",
      " Patient is very difficult to get an accurate history from as he \n",
      "exhibits significant tangentiality and does not answer questions \n",
      "directly.  \n",
      " He states both legs are very swollen. Unclear how long this has \n",
      "been going on for. He was discharged from the ED in ___ for \n",
      "similar complaints. He was given a course of Keflex for \n",
      "cellulitis, but he states that the antibiotics never work.  \n",
      " He also complains of his bullous pemphigoid and how it has \n",
      "turned into lymphoma in his mouth. He also endorses diffuse \n",
      "lymphadenopathy. This has been going on for years. He has not \n",
      "seen a dermatologist in ___ in a long time (unclear just how \n",
      "long) because according to him not a single dermatologist in \n",
      "___ treats bullous pemphigoid. He says he has talked to ___ \n",
      "___ about getting his BP treated but has had trouble ever \n",
      "getting in touch with a doctor directly.  \n",
      " Patient states that his abdomen is swollen but cannot give a \n",
      "time course. He  \n",
      " He was referred into the ED by his PCP for evaluation of his \n",
      "leg lesions and abdominal swelling. His weight is 205 today, \n",
      "which is up from 162 in ___.  \n",
      " In the ED, initial vitals were: 97.9 92 116/72 22 97% RA \n",
      "93.2kgs  \n",
      " - Labs notable for WBC of 12.5  \n",
      " - Imaging: LLE US did not show evidence of DVT; CXR showed mild \n",
      "cardiomegaly and mild vascular congestion.  \n",
      " - Bedside US did not show any evidence of ascites.  \n",
      " Patient was given: Duonebs and CTX 1g IV for LLE cellulitis  \n",
      " \n",
      "Past Medical History:\n",
      "PAST MEDICAL HISTORY:  \n",
      "- Bipolar  \n",
      "- Hepatitis C  \n",
      "- HLD  \n",
      "- Diabetes, steroid-induced  \n",
      "- Self-reported bullous pemphigoid, but no clinic or laboratory \n",
      "evidence to support this diagnosis\n",
      "- COPD  \n",
      "- Cholelithiasis  \n",
      "- GERD  \n",
      "- Aortic aneurysm  \n",
      "- Osteoporosis  \n",
      "\n",
      "            question: Given the History of Present Illness, What is the relevant past medical history?\n",
      "            answer:\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62642d0b-2942-4aa1-aa54-3d5079b83e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import GOOGLE_API_KEY2\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8f8c10d-5b03-46bf-b66b-941380b010b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatGroq(\n",
    "    temperature=0,\n",
    "    model=\"llama3-8b-8192\",\n",
    "    # api_key=\"\" # Optional if not set as an environment variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6753bbbc-d80c-42fe-a43e-2fb5cf53a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(retriever, query):\n",
    "\n",
    "    try:\n",
    "        # llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "        # llm = ChatOpenAI(model=\"gpt-4\")\n",
    "        llm =chat\n",
    "#         llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"epfl-llm/meditron-7b\",\n",
    "#     task=\"text-generation\",\n",
    "# )\n",
    "        template = \"\"\"\n",
    "            You are a helpful Medical AI assistant. Answer based on the context provided. \n",
    "            context: {context}\n",
    "            input: {input}\n",
    "            answer:\n",
    "            \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "        retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "        response = retrieval_chain.invoke({\"input\": query})\n",
    "        # print(response[\"answer\"])\n",
    "        return response[\"answer\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while generating the response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2a9df09-b6fe-44e6-8979-02a8446abf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "\"Given the History of Present Illness, What is the relevant past medical history?\",\n",
    "\"Given the HPI, chief complaint, and initial ICD diagnosis, Why was the patient admitted to the hospital? What symptoms, medical condition, or other reason caused the patient to come to or be brought into the hospital?\",\n",
    "\"Based on the admission medication list, what other existing or ongoing medical conditions did the patient have?\",\n",
    "\"Given the history of present illness, admission and discharge diagnosis, What medical conditions or symptoms was this patient treated for in the hospital?\",\n",
    "\"given the history of present illness, What was the initial treatment course?\",\n",
    "\"Given the History of Present illness, What was the initial diagnostic work up and pertinent results?\",\n",
    "\"Given the radiology notes, What radiology, imaging or other studies that were performed and for what inducation? Summarize the impressions from each study. Make a table of Imaging study, indication, and impression.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e54a1-c8ec-4cc4-8e93-12498ec4c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an internal medicine physician conducting a review of a patient's EHR. \n",
    "        You need to find relevant and accurate information contained in the text of clinical notes. \n",
    "        Using the information contained in the context provided, answer the question about the patient's medical records..\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "If the answer cannot be deduced from the context, respond that the information can not be deduced from the information provided.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e251756-7ff2-4596-a6df-9b5e76f62aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Bipolar  \n",
      "- Hepatitis C  \n",
      "- HLD  \n",
      "- Diabetes, steroid-induced  \n",
      "- Self-reported bullous pemphigoid, but no clinic or laboratory \n",
      "evidence to support this diagnosis\n",
      "- COPD  \n",
      "- Cholelithiasis  \n",
      "- GERD  \n",
      "- Aortic aneurysm  \n",
      "- Osteoporosis\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(retriever, questions[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8baeaab3-6239-4910-b2c5-51bc9087cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while generating the response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Given the History of Present Illness, What is the relevant past medical history? \n",
      "\n",
      "None\n",
      "\n",
      "*********************\n",
      "An error occurred while generating the response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Given the HPI, chief complaint, and initial ICD diagnosis, Why was the patient admitted to the hospital? What symptoms, medical condition, or other reason caused the patient to come to or be brought into the hospital? \n",
      "\n",
      "None\n",
      "\n",
      "*********************\n",
      "An error occurred while generating the response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Based on the admission medication list, what other existing or ongoing medical conditions did the patient have? \n",
      "\n",
      "None\n",
      "\n",
      "*********************\n",
      "An error occurred while generating the response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Given the history of present illness, admission and discharge diagnosis, What medical conditions or symptoms was this patient treated for in the hospital? \n",
      "\n",
      "None\n",
      "\n",
      "*********************\n",
      "An error occurred while generating the response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "given the history of present illness, What was the initial treatment course? \n",
      "\n",
      "None\n",
      "\n",
      "*********************\n",
      "An error occurred while generating the response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Given the History of Present illness, What was the initial diagnostic work up and pertinent results? \n",
      "\n",
      "None\n",
      "\n",
      "*********************\n",
      "An error occurred while generating the response: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Given the radiology notes, What radiology, imaging or other studies that were performed and for what inducation? Summarize the impressions from each study. Make a table of Imaging study, indication, and impression. \n",
      "\n",
      "None\n",
      "\n",
      "*********************\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    response = generate_response(retriever, question)\n",
    "    print(question,\"\\n\")\n",
    "    print(response)\n",
    "    print(\"\\n*********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e926f5-d792-49ec-baf6-8dbb80179a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
