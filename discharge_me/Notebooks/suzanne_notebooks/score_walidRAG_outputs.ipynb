{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30bbd57f-baf2-4d23-b878-c7f6c7f4e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# path to walid's output data\n",
    "\n",
    "output_path = '/work/AI-EHR/discharge_me/data/Experiments/RAG/Walid_RAG_20240708/hadm_answers_summary_and_letter'\n",
    "\n",
    "# path to reference data\n",
    "\n",
    "ref_path = '/work/AI-EHR/discharge_me/data/test_phase_2'\n",
    "\n",
    "# hadm_id_list\n",
    "\n",
    "hadm_id_list_df = pd.read_csv(os.path.join(ref_path, 'hadm_ids_for_discharge_me_scoring.csv'))\n",
    "# hadm_id_list_file = (os.path.join(ref_path, 'hadm_ids_for_discharge_me_scoring.csv'))\n",
    "\n",
    "# Read the file identifiers from the CSV file\n",
    "hadm_id_list_df.head()\n",
    "\n",
    "# list all the txt files with a suffix of _masked_summary_out.txt\n",
    "summary_out_txt_files = [f for f in os.listdir(output_path) if f.endswith('_masked_summary_out.txt')]\n",
    "letter_out_txt_files = [f for f in os.listdir(output_path) if f.endswith('_masked_letter_out.txt')]\n",
    "\n",
    "# refs will be our segmentation of BHC and discharge summaries for each hadm_id in the list\n",
    "discharge_sections_df = pd.read_csv(os.path.join(ref_path, 'discharge_sections.csv'), keep_default_na=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5cf4acc-96f8-44b5-b194-915680fd39f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brief Hospital Course:\n",
      "Ms. ___ is a ___ female with history of \n",
      "COPD on home O2, atrial fibrillation on apixaban, hypertension, \n",
      "CAD, and hyperlipidemia who presents with shortness of breath, \n",
      "cough, and wheezing for one day. Pt recently DC'd from hospital \n",
      "for dyspnea, treated only w/nebs and steroids as not thought ___ \n",
      "true COPD exacerbation, c/f anxiety component. Pt re-admitted \n",
      "w/similar Sx, thought ___ COPD exacerbation, received nebs, \n",
      "steroids, azithromycin. Pt's wheezing, cough, SOB improved \n",
      "shortly after admission, O2 titrated down & satting well on 2L \n",
      "in mid-90s which is baseline. Evaluated by ___, recommended DC to \n",
      "pulmonary rehab, pt was agreeable. \n",
      "\n",
      "ACTIVE ISSUES\n",
      "=================\n",
      "# Shortness of Breath: Patient with history of COPD and recent \n",
      "admission for dyspnea in the setting of steroid taper. Her \n",
      "symptoms on presentation were consistent with severe COPD given \n",
      "diffuse wheezing and poor air movement. She likely had an \n",
      "exacerbation in the setting of a decrease in her steroids. There \n",
      "may also be a component of anxiety. She underwent CT last \n",
      "admission that was negative for infections such as ___. She was \n",
      "continued on home spiriva, theophylline, advair. She was started \n",
      "on standing duonebs q6h and albuterol q2h prn and prednisone was \n",
      "started at 40mg daily with slow taper. She was also given \n",
      "azithromycin to complete 5 day course. She had improvement in \n",
      "her wheezing and returned to baseline O2 requirement after 48 \n",
      "hours. She was seen by ___ who felt that she would benefit from \n",
      "discharge to inpatient pulmonary rehabilitation program. On DC \n",
      "to ___ rehab, recommended continued Prendisone 40mg \n",
      "daily for 1x week with slow taper by 5mg every 5 days. ___ also \n",
      "consider starting bactrim ppx with extended duration of steroids \n",
      "if unable to wean less than 20mg qd. Will also f/u as outpatient \n",
      "with pulm.\n",
      "\n",
      "CHRONIC ISSUES: \n",
      "==================\n",
      "# Anxiety/Insomnia: Continued home lorazepam. Consider starting \n",
      "SRRI as an outpatient. \n",
      "# Atrial Fibrillation: Continued dilt for rate control and \n",
      "apixaban for anticoagulation.\n",
      "# Hypertension: Continued home imdur, hydrochlorothiazide, and \n",
      "diltiazem.\n",
      "# CAD: Cardiac catheterization in ___ without evidence of \n",
      "significant stenosis of coronaries. ECHO on ___ with EF > \n",
      "55% and no regional or global wall motion abnormalities. \n",
      "Continued home aspirin and atorvastatin.\n",
      "# Anemia: Continued home iron supplements.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CC</th>\n",
       "      <th>Service</th>\n",
       "      <th>Major Surgical Procedure</th>\n",
       "      <th>HPI</th>\n",
       "      <th>PMH</th>\n",
       "      <th>SOC</th>\n",
       "      <th>FH</th>\n",
       "      <th>...</th>\n",
       "      <th>Problem List</th>\n",
       "      <th>Physical Exam</th>\n",
       "      <th>Medication Lists</th>\n",
       "      <th>Pertinent Results</th>\n",
       "      <th>BHC</th>\n",
       "      <th>Transitional Issues</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Discharge Instructions</th>\n",
       "      <th>Followup Instructions</th>\n",
       "      <th>Discharge Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Chief Complaint:\\nShortness of Breath</td>\n",
       "      <td>Service: MEDICINE\\n \\nAllergies: \\nIV Dye, Iod...</td>\n",
       "      <td>Major Surgical or Invasive Procedure:\\nN/A</td>\n",
       "      <td>History of Present Illness:\\nMs. ___ is a ___ ...</td>\n",
       "      <td>Past Medical History:\\n- COPD/Asthma on home 2...</td>\n",
       "      <td>Social History:\\n___</td>\n",
       "      <td>Family History:\\nMother with asthma and hypert...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Physical Exam:\\nADMISSION PHYSICAL EXAM:\\n====...</td>\n",
       "      <td>Preadmission Medication list is accurate and c...</td>\n",
       "      <td>Pertinent Results:\\nADMISSION LABS: \\n========...</td>\n",
       "      <td>Brief Hospital Course:\\nMs. ___ is a ___ femal...</td>\n",
       "      <td>TRANSITIONAL ISSUES:\\n========================...</td>\n",
       "      <td>Disposition:\\nExtended Care\\n \\nFacility:\\n___...</td>\n",
       "      <td>Discharge Instructions:\\nDear Ms. ___,\\n\\nYou ...</td>\n",
       "      <td></td>\n",
       "      <td>Diagnosis:\\nPRIMARY:\\nCOPD Exacerbation\\n\\nSEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>Chief Complaint:\\nfever</td>\n",
       "      <td>Service: MEDICINE\\n \\nAllergies: \\nRagweed / m...</td>\n",
       "      <td>Major Surgical or Invasive Procedure:\\nnone</td>\n",
       "      <td>History of Present Illness:\\nMr ___ is a ___ w...</td>\n",
       "      <td>Past Medical History:\\n1. Sarcoidosis, dx skin...</td>\n",
       "      <td>Social History:\\n___</td>\n",
       "      <td>Family History:\\nMother: ___, cardiac disease....</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Physical Exam:\\nADMISSION EXAM\\nVitals: 124/67...</td>\n",
       "      <td>Medications on Admission:\\nThe Preadmission Me...</td>\n",
       "      <td>Pertinent Results:\\nADMISSION LABS\\n___ 10:40A...</td>\n",
       "      <td>Brief Hospital Course:\\n___ male with h/o Hodg...</td>\n",
       "      <td></td>\n",
       "      <td>Disposition:\\nHome With Service\\n \\nFacility:\\...</td>\n",
       "      <td>Discharge Instructions:\\nDear Mr. ___,\\n\\nIt h...</td>\n",
       "      <td></td>\n",
       "      <td>Discharge Diagnosis:\\nPrimary Diagnosis\\nNeutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10003299</td>\n",
       "      <td>29323205</td>\n",
       "      <td>Chief Complaint:\\nleft leg weakness, falls</td>\n",
       "      <td>Service: NEUROLOGY\\n \\nAllergies: \\nIodine-Iod...</td>\n",
       "      <td>Major Surgical or Invasive Procedure:\\nNone</td>\n",
       "      <td>History of Present Illness:\\n___ is a ___ RH f...</td>\n",
       "      <td>Past Medical History:\\n- prior paramedian pont...</td>\n",
       "      <td>Social History:\\n___</td>\n",
       "      <td>Family History:\\nMother had stroke in her ___ ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Physical Exam:\\nAdmission Exam:\\nVitals: T: 97...</td>\n",
       "      <td>Medications on Admission:\\nThe Preadmission Me...</td>\n",
       "      <td>Pertinent Results:\\n___ 01:10PM   GLUCOSE-125*...</td>\n",
       "      <td>Brief Hospital Course:\\n___ RH female with a P...</td>\n",
       "      <td></td>\n",
       "      <td>Disposition:\\nHome With Service\\n \\nFacility:\\...</td>\n",
       "      <td>Discharge Instructions:\\nDear ___ were hospita...</td>\n",
       "      <td></td>\n",
       "      <td>Discharge Diagnosis:\\nIschemic stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10003502</td>\n",
       "      <td>20459702</td>\n",
       "      <td>Chief Complaint:\\nNausea</td>\n",
       "      <td>Service: MEDICINE\\n \\nAllergies: \\nnifedipine ...</td>\n",
       "      <td>Major Surgical or Invasive Procedure:\\nNone</td>\n",
       "      <td>History of Present Illness:\\nMs. ___ is an ___...</td>\n",
       "      <td>Past Medical History:\\nHypertension/hyperlipid...</td>\n",
       "      <td>Social History:\\n___</td>\n",
       "      <td>Family History:\\nMother deceased at ___ yo fro...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Physical Exam:\\nOn admission: \\nVS 97.4 140/P ...</td>\n",
       "      <td>Medications on Admission:\\nThe Preadmission Me...</td>\n",
       "      <td>Pertinent Results:\\n___ 10:15AM BLOOD WBC-6.4 ...</td>\n",
       "      <td>Brief Hospital Course:\\nHospitalization Summar...</td>\n",
       "      <td>Transitional Issues: \\n- monitoring of volume ...</td>\n",
       "      <td>Disposition:\\nHome With Service\\n \\nFacility:\\...</td>\n",
       "      <td>Discharge Instructions:\\nIt was a pleasure car...</td>\n",
       "      <td></td>\n",
       "      <td>Discharge Diagnosis:\\nPrimary: \\nAcute diastol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10004322</td>\n",
       "      <td>28755331</td>\n",
       "      <td>Chief Complaint:\\nmultiple falls at group home</td>\n",
       "      <td>Service: MEDICINE\\n \\nAllergies: \\nNo Known Al...</td>\n",
       "      <td>Major Surgical or Invasive Procedure:\\nNone</td>\n",
       "      <td>History of Present Illness:\\nMr. ___ is a ___ ...</td>\n",
       "      <td>Past Medical History:\\nPsychosis \\nDiabetes \\n...</td>\n",
       "      <td>Social History:\\n___</td>\n",
       "      <td>Family History:\\nUnknown to patient.</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Physical Exam:\\nADMISSION PHYSICAL EXAM: \\nVS:...</td>\n",
       "      <td>Medications on Admission:\\nThe Preadmission Me...</td>\n",
       "      <td>Pertinent Results:\\nADMISSION LABS:\\n___ 03:40...</td>\n",
       "      <td>Brief Hospital Course:\\n___ with h/o psychosis...</td>\n",
       "      <td>TRANSITIONAL ISSUES:\\n-He was discharged back ...</td>\n",
       "      <td>Disposition:\\nHome With Service\\n \\nFacility:\\...</td>\n",
       "      <td>Discharge Instructions:\\nDear Mr. ___,\\n\\nIt w...</td>\n",
       "      <td></td>\n",
       "      <td>Discharge Diagnosis:\\nPrimary: mechanical fall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id  \\\n",
       "0           0    10001884  24962904   \n",
       "1           1    10003019  22774359   \n",
       "2           2    10003299  29323205   \n",
       "3           3    10003502  20459702   \n",
       "4           4    10004322  28755331   \n",
       "\n",
       "                                               CC  \\\n",
       "0           Chief Complaint:\\nShortness of Breath   \n",
       "1                         Chief Complaint:\\nfever   \n",
       "2      Chief Complaint:\\nleft leg weakness, falls   \n",
       "3                        Chief Complaint:\\nNausea   \n",
       "4  Chief Complaint:\\nmultiple falls at group home   \n",
       "\n",
       "                                             Service  \\\n",
       "0  Service: MEDICINE\\n \\nAllergies: \\nIV Dye, Iod...   \n",
       "1  Service: MEDICINE\\n \\nAllergies: \\nRagweed / m...   \n",
       "2  Service: NEUROLOGY\\n \\nAllergies: \\nIodine-Iod...   \n",
       "3  Service: MEDICINE\\n \\nAllergies: \\nnifedipine ...   \n",
       "4  Service: MEDICINE\\n \\nAllergies: \\nNo Known Al...   \n",
       "\n",
       "                      Major Surgical Procedure  \\\n",
       "0   Major Surgical or Invasive Procedure:\\nN/A   \n",
       "1  Major Surgical or Invasive Procedure:\\nnone   \n",
       "2  Major Surgical or Invasive Procedure:\\nNone   \n",
       "3  Major Surgical or Invasive Procedure:\\nNone   \n",
       "4  Major Surgical or Invasive Procedure:\\nNone   \n",
       "\n",
       "                                                 HPI  \\\n",
       "0  History of Present Illness:\\nMs. ___ is a ___ ...   \n",
       "1  History of Present Illness:\\nMr ___ is a ___ w...   \n",
       "2  History of Present Illness:\\n___ is a ___ RH f...   \n",
       "3  History of Present Illness:\\nMs. ___ is an ___...   \n",
       "4  History of Present Illness:\\nMr. ___ is a ___ ...   \n",
       "\n",
       "                                                 PMH                   SOC  \\\n",
       "0  Past Medical History:\\n- COPD/Asthma on home 2...  Social History:\\n___   \n",
       "1  Past Medical History:\\n1. Sarcoidosis, dx skin...  Social History:\\n___   \n",
       "2  Past Medical History:\\n- prior paramedian pont...  Social History:\\n___   \n",
       "3  Past Medical History:\\nHypertension/hyperlipid...  Social History:\\n___   \n",
       "4  Past Medical History:\\nPsychosis \\nDiabetes \\n...  Social History:\\n___   \n",
       "\n",
       "                                                  FH  ... Problem List  \\\n",
       "0  Family History:\\nMother with asthma and hypert...  ...                \n",
       "1  Family History:\\nMother: ___, cardiac disease....  ...                \n",
       "2  Family History:\\nMother had stroke in her ___ ...  ...                \n",
       "3  Family History:\\nMother deceased at ___ yo fro...  ...                \n",
       "4               Family History:\\nUnknown to patient.  ...                \n",
       "\n",
       "                                       Physical Exam  \\\n",
       "0  Physical Exam:\\nADMISSION PHYSICAL EXAM:\\n====...   \n",
       "1  Physical Exam:\\nADMISSION EXAM\\nVitals: 124/67...   \n",
       "2  Physical Exam:\\nAdmission Exam:\\nVitals: T: 97...   \n",
       "3  Physical Exam:\\nOn admission: \\nVS 97.4 140/P ...   \n",
       "4  Physical Exam:\\nADMISSION PHYSICAL EXAM: \\nVS:...   \n",
       "\n",
       "                                    Medication Lists  \\\n",
       "0  Preadmission Medication list is accurate and c...   \n",
       "1  Medications on Admission:\\nThe Preadmission Me...   \n",
       "2  Medications on Admission:\\nThe Preadmission Me...   \n",
       "3  Medications on Admission:\\nThe Preadmission Me...   \n",
       "4  Medications on Admission:\\nThe Preadmission Me...   \n",
       "\n",
       "                                   Pertinent Results  \\\n",
       "0  Pertinent Results:\\nADMISSION LABS: \\n========...   \n",
       "1  Pertinent Results:\\nADMISSION LABS\\n___ 10:40A...   \n",
       "2  Pertinent Results:\\n___ 01:10PM   GLUCOSE-125*...   \n",
       "3  Pertinent Results:\\n___ 10:15AM BLOOD WBC-6.4 ...   \n",
       "4  Pertinent Results:\\nADMISSION LABS:\\n___ 03:40...   \n",
       "\n",
       "                                                 BHC  \\\n",
       "0  Brief Hospital Course:\\nMs. ___ is a ___ femal...   \n",
       "1  Brief Hospital Course:\\n___ male with h/o Hodg...   \n",
       "2  Brief Hospital Course:\\n___ RH female with a P...   \n",
       "3  Brief Hospital Course:\\nHospitalization Summar...   \n",
       "4  Brief Hospital Course:\\n___ with h/o psychosis...   \n",
       "\n",
       "                                 Transitional Issues  \\\n",
       "0  TRANSITIONAL ISSUES:\\n========================...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  Transitional Issues: \\n- monitoring of volume ...   \n",
       "4  TRANSITIONAL ISSUES:\\n-He was discharged back ...   \n",
       "\n",
       "                                         Disposition  \\\n",
       "0  Disposition:\\nExtended Care\\n \\nFacility:\\n___...   \n",
       "1  Disposition:\\nHome With Service\\n \\nFacility:\\...   \n",
       "2  Disposition:\\nHome With Service\\n \\nFacility:\\...   \n",
       "3  Disposition:\\nHome With Service\\n \\nFacility:\\...   \n",
       "4  Disposition:\\nHome With Service\\n \\nFacility:\\...   \n",
       "\n",
       "                              Discharge Instructions Followup Instructions  \\\n",
       "0  Discharge Instructions:\\nDear Ms. ___,\\n\\nYou ...                         \n",
       "1  Discharge Instructions:\\nDear Mr. ___,\\n\\nIt h...                         \n",
       "2  Discharge Instructions:\\nDear ___ were hospita...                         \n",
       "3  Discharge Instructions:\\nIt was a pleasure car...                         \n",
       "4  Discharge Instructions:\\nDear Mr. ___,\\n\\nIt w...                         \n",
       "\n",
       "                                 Discharge Diagnosis  \n",
       "0  Diagnosis:\\nPRIMARY:\\nCOPD Exacerbation\\n\\nSEC...  \n",
       "1  Discharge Diagnosis:\\nPrimary Diagnosis\\nNeutr...  \n",
       "2              Discharge Diagnosis:\\nIschemic stroke  \n",
       "3  Discharge Diagnosis:\\nPrimary: \\nAcute diastol...  \n",
       "4  Discharge Diagnosis:\\nPrimary: mechanical fall...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(discharge_sections_df['BHC'][0])\n",
    "discharge_sections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5da69631-c352-4cc5-ac83-74daa7a457fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        list\n",
       "\u001b[0;31mString form:\u001b[0m ['hadm_id_20226692_inputs_summary_out.txt_masked_summary_out.txt', 'hadm_id_20279012_inputs_summa <...> ut.txt_masked_summary_out.txt', 'hadm_id_29991915_inputs_summary_out.txt_masked_summary_out.txt']\n",
       "\u001b[0;31mLength:\u001b[0m      243\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Built-in mutable sequence.\n",
       "\n",
       "If no argument is given, the constructor creates a new empty list.\n",
       "The argument must be an iterable if specified.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_out_txt_files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21ab3286-8a17-4c4a-9b72-417dd43f38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract text data from walid's text files and put them in a csv/data frame with the corresponding human generated target data\n",
    "\n",
    "file_list = summary_out_txt_files #for BHC LLM outputs\n",
    "\n",
    "# Function to extract numeric identifier from filename\n",
    "def extract_identifier(filename):\n",
    "  \n",
    "    match = re.search(r'_(\\d+)_', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each file in the list\n",
    "for file_name in file_list:\n",
    "    filename = os.path.join(output_path, file_name)\n",
    "    identifier = extract_identifier(file_name)\n",
    "    if identifier:\n",
    "        with open(filename, 'r') as file:\n",
    "            content = file.read()\n",
    "            data.append({'identifier': identifier, 'content': content})\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.rename(columns={'identifier': 'hadm_id', 'content': 'BHC_LLM_out'}, inplace=True)\n",
    "df['hadm_id'] = df['hadm_id'].astype(int)\n",
    "\n",
    "# Merge with target data, in this case human generated sections\n",
    "\n",
    "merged_df = df.merge(discharge_sections_df[['hadm_id', 'BHC']], on='hadm_id', how='left')\n",
    "merged_df.rename(columns={'BHC': 'BHC_human_generated'}, inplace=True)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "merged_df.to_csv(os.path.join(output_path, 'summary_out_with_targets.csv'), index=False)\n",
    "summary_out_df = merged_df\n",
    "\n",
    "##  for discharge instruction letter outputs\n",
    "file_list = letter_out_txt_files #for discharge instructions letter outputs\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through each file in the list\n",
    "for file_name in file_list:\n",
    "    filename = os.path.join(output_path, file_name)\n",
    "    identifier = extract_identifier(file_name)\n",
    "    if identifier:\n",
    "        with open(filename, 'r') as file:\n",
    "            content = file.read()\n",
    "            data.append({'identifier': identifier, 'content': content})\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.rename(columns={'identifier': 'hadm_id', 'content': 'Letter_LLM_out'}, inplace=True)\n",
    "df['hadm_id'] = df['hadm_id'].astype(int)\n",
    "\n",
    "# Merge with target data, in this case human generated sections\n",
    "\n",
    "merged_df = df.merge(discharge_sections_df[['hadm_id', 'Discharge Instructions']], on='hadm_id', how='left')\n",
    "merged_df.rename(columns={'Discharge Instructions': 'Letter_human_generated'}, inplace=True)\n",
    "                          \n",
    "# merged_df.head(3)\n",
    "\n",
    "\n",
    "# # Optionally, save the DataFrame to a CSV file\n",
    "merged_df.to_csv(os.path.join(output_path, 'letter_out_with_targets.csv'), index=False)\n",
    "letter_out_df = merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3ff0261-df4f-45d0-a5a6-9e4e1e24f1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "letter_out_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa8165bd-3434-4d1e-9e04-96f900b59d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Patient,\n",
      "\n",
      "I hope this letter finds you well. I wanted to take a moment to provide you with an update on your recent hospital admission.\n",
      "\n",
      "You were admitted to the hospital due to concerns regarding your heart health. The main reason for your admission was to investigate chest pain and shortness of breath that you had been experiencing. After conducting various tests, it was determined that you had a blockage in one of your coronary arteries, which was affecting the blood flow to your heart muscle.\n",
      "\n",
      "During your stay, you underwent several diagnostic tests, including an electrocardiogram (ECG) and a cardiac catheterization. These tests helped us confirm the blockage in your artery and assess the extent of the damage to your heart.\n",
      "\n",
      "Based on the results of these tests, you received a coronary angioplasty and stent placement procedure to open up the blocked artery and restore proper blood flow to your heart. This treatment was successful, and you responded well to the procedure.\n",
      "\n",
      "Currently, there are no pending results from the tests that were conducted during your hospital stay. However, it is important to note that you will be prescribed new medications to manage your heart condition effectively. These medications will help control your blood pressure, reduce the risk of blood clots, and improve your heart function.\n",
      "\n",
      "As part of your follow-up care, it is recommended that you schedule a visit with your cardiologist within the next two weeks. During this appointment, your doctor will assess your recovery progress, review your medications, and discuss any further steps that may be needed to ensure your continued well-being.\n",
      "\n",
      "Please feel free to reach out if you have any questions or concerns about your recent hospitalization or the information provided in this letter. Your health and well-being are our top priorities, and we are here to support you every step of the way.\n",
      "\n",
      "Take care and wishing you a speedy recovery.\n",
      "\n",
      "Sincerely,\n",
      "[Your Healthcare Provider]\n"
     ]
    }
   ],
   "source": [
    "print(letter_out_df['Letter_LLM_out'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "359012ea-11d0-4621-a906-7eb3e3fe0c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/s.wendelken/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/s.wendelken/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/s.wendelken/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "\"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the patient was admitted to the hospital due to exacerbation of congestive heart failure . they were admitted to the cardiology service and underwent a cardiac catheterization procedure . for the congestive heart failure the patient presented with shortness of breath and lower extremity edema . the differential diagnosis included acute decompensated heart failure and pneumonia . diagnostic workup included chest xray showing pulmonary congestion bnp levels were elevated and echocardiogram revealed reduced ejection fraction . treatment involved diuresis with iv furosemide and ace inhibitor therapy . physical exam findings included bilateral crackles in the lungs and jugular venous distension . lab work showed elevated bnp levels . pending results include renal function tests . followup includes outpatient cardiology visit in 2 weeks . medications administered were iv furosemide and lisinopril .",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 163>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Call the function with the merged_df, hypothesis column, and reference column\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m summary_result_df \u001b[38;5;241m=\u001b[39m \u001b[43mappend_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_out_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBHC_LLM_out\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBHC_human_generated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Display the DataFrame with scores\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary_result_df)\n",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36mappend_scores\u001b[0;34m(df, hyp_col, ref_col)\u001b[0m\n\u001b[1;32m    144\u001b[0m ref_raw \u001b[38;5;241m=\u001b[39m preprocess_text(ref_raw, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Calculate scores\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMETEOR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcalculate_meteor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyp_tokenized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_tokenized\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    148\u001b[0m scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGLEU\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(calculate_gleu(hyp_tokenized, ref_tokenized))\n\u001b[1;32m    149\u001b[0m P, R, F1 \u001b[38;5;241m=\u001b[39m calculate_bertscore(hyp_raw, ref_raw)\n",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36mcalculate_meteor\u001b[0;34m(hypothesis, reference)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_meteor\u001b[39m(hypothesis, reference):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# METEOR: Requires tokenized input but does not require padding.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# return sacrebleu.metrics.meteor.METEOR().score([hypothesis], [[reference]])\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeteor_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreference\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/nltk/translate/meteor_score.py:397\u001b[0m, in \u001b[0;36mmeteor_score\u001b[0;34m(references, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_meteor_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstemmer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwordnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/nltk/translate/meteor_score.py:398\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeteor_score\u001b[39m(\n\u001b[1;32m    348\u001b[0m     references: Iterable[Iterable[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    349\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    356\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for hypothesis with multiple references as\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    described in \"Meteor: An Automatic Metric for MT Evaluation with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m--> 398\u001b[0m         \u001b[43msingle_meteor_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstemmer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstemmer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwordnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwordnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m reference \u001b[38;5;129;01min\u001b[39;00m references\n\u001b[1;32m    409\u001b[0m     )\n",
      "File \u001b[0;32m/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/nltk/translate/meteor_score.py:326\u001b[0m, in \u001b[0;36msingle_meteor_score\u001b[0;34m(reference, hypothesis, preprocess, stemmer, wordnet, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_meteor_score\u001b[39m(\n\u001b[1;32m    283\u001b[0m     reference: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    284\u001b[0m     hypothesis: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m     gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    291\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Calculates METEOR score for single hypothesis and reference as per\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    \"Meteor: An Automatic Metric for MT Evaluation with HighLevels of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    :return: The sentence-level METEOR score.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     enum_hypothesis, enum_reference \u001b[38;5;241m=\u001b[39m \u001b[43m_generate_enums\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     translation_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_hypothesis)\n\u001b[1;32m    330\u001b[0m     reference_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(enum_reference)\n",
      "File \u001b[0;32m/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/nltk/translate/meteor_score.py:33\u001b[0m, in \u001b[0;36m_generate_enums\u001b[0;34m(hypothesis, reference, preprocess)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mTakes in pre-tokenized inputs for hypothesis and reference and returns\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03menumerated word lists for each of them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m:return: enumerated words list\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hypothesis, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects pre-tokenized hypothesis (Iterable[str]): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypothesis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(reference, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects pre-tokenized reference (Iterable[str]): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the patient was admitted to the hospital due to exacerbation of congestive heart failure . they were admitted to the cardiology service and underwent a cardiac catheterization procedure . for the congestive heart failure the patient presented with shortness of breath and lower extremity edema . the differential diagnosis included acute decompensated heart failure and pneumonia . diagnostic workup included chest xray showing pulmonary congestion bnp levels were elevated and echocardiogram revealed reduced ejection fraction . treatment involved diuresis with iv furosemide and ace inhibitor therapy . physical exam findings included bilateral crackles in the lungs and jugular venous distension . lab work showed elevated bnp levels . pending results include renal function tests . followup includes outpatient cardiology visit in 2 weeks . medications administered were iv furosemide and lisinopril ."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import mauve\n",
    "import bert_score\n",
    "import sacrebleu\n",
    "from rouge_score import rouge_scorer\n",
    "# import moverscore_v2 as mv_sc\n",
    "import re\n",
    "import torch \n",
    "\n",
    "\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Example custom medical acronym dictionary #TODO\n",
    "medical_acronyms = {\n",
    "    'MI': 'myocardial infarction',\n",
    "    'COPD': 'chronic obstructive pulmonary disease',\n",
    "    'DM': 'diabetes mellitus',\n",
    "    'CHF': 'congestive heart failure',\n",
    "    'HTN': 'hypertension',\n",
    "    'CAD': 'coronary artery disease',\n",
    "    # Add more acronyms as needed\n",
    "}\n",
    "\n",
    "# Specific Metric Requirements:\n",
    "# METEOR: Requires tokenized input but does not require padding.\n",
    "# GLEU: Typically uses tokenized sentences, no padding required.\n",
    "# BERTScore: Handles tokenization internally.\n",
    "# Rouge-L: Handles tokenization internally.\n",
    "# MoverScore: Requires tokenized input, no padding required.\n",
    "# Mauve: Handles tokenization internally.\n",
    "\n",
    "# Function to remove extraneous text and punctuation, with tokenization flag\n",
    "def preprocess_text(text, tokenize=False):\n",
    "    # Expand medical acronyms\n",
    "    # text = expand_acronyms(text) #TODO\n",
    "    \n",
    "    # Remove HTML/XML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Remove non-alphanumeric characters except ., ? : = )\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\:\\?\\=]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    if tokenize:\n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stop words #TODO\n",
    "        # stop_words = set(stopwords.words('english'))\n",
    "        # tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "# Function to expand medical acronyms #TODO\n",
    "def expand_acronyms(text):\n",
    "    for acronym, expansion in medical_acronyms.items():\n",
    "        text = re.sub(r'\\b{}\\b'.format(acronym), expansion, text)\n",
    "    return text\n",
    "\n",
    "# Custom stemmer that handles medical acronyms\n",
    "class MedicalStemmer:\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer()\n",
    "    \n",
    "    def stem(self, word):\n",
    "        return self.porter.stem(word)\n",
    "    \n",
    "    def stem_text(self, text):\n",
    "        expanded_text = expand_acronyms(text)\n",
    "        tokens = word_tokenize(expanded_text.lower())\n",
    "        stemmed_tokens = [self.stem(token) for token in tokens]\n",
    "        return ' '.join(stemmed_tokens)\n",
    "    \n",
    "    \n",
    "\n",
    "# Function to calculate METEOR score\n",
    "def calculate_meteor(hypothesis, reference):\n",
    "    # METEOR: Requires tokenized input but does not require padding.\n",
    "    # return sacrebleu.metrics.meteor.METEOR().score([hypothesis], [[reference]])\n",
    "    return meteor_score([reference], hypothesis)\n",
    "\n",
    "# Function to calculate GLEU score\n",
    "def calculate_gleu(hypothesis, reference):\n",
    "    # GLEU: Typically uses tokenized sentences, no padding required.\n",
    "    return sacrebleu.sentence_gleu([reference], hypothesis)\n",
    "\n",
    "# Function to calculate BERTScore using BioBERT\n",
    "def calculate_bertscore(hypothesis, reference):\n",
    "    # BERTScore: Handles tokenization internally.\n",
    "\n",
    "    P, R, F1 = bert_score.score(\n",
    "        [hypothesis], [reference], \n",
    "        model_type='monologg/biobert_v1.1_pubmed', \n",
    "        lang='en', \n",
    "        rescale_with_baseline=True\n",
    "    )\n",
    "    return P.mean().item(), R.mean().item(), F1.mean().item()\n",
    "\n",
    "# Function to calculate Rouge-L score\n",
    "def calculate_rouge_l(hypothesis, reference):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, hypothesis)\n",
    "    return scores['rougeL'].fmeasure\n",
    "\n",
    "# Function to calculate MoverScore\n",
    "def calculate_moverscore(hypothesis, reference): #TODO\n",
    "    # return mv_sc.get_scores([hypothesis], [reference], n_gram=1)[0]\n",
    "    return \n",
    "\n",
    "# Function to calculate Mauve score\n",
    "def calculate_mauve(hypothesis, reference):\n",
    "    mauve_result = mauve.compute_mauve(p_text=[hypothesis], q_text=[reference])\n",
    "    return mauve_result.mauve\n",
    "\n",
    "# Function to calculate and append scores to the DataFrame\n",
    "def append_scores(df, hyp_col, ref_col):\n",
    "    scores = {\n",
    "        'METEOR': [], 'GLEU': [], 'BERTScore_P': [], 'BERTScore_R': [],\n",
    "        'BERTScore_F1': [], 'Rouge-L': [], 'MoverScore': [], 'Mauve': []\n",
    "    } \n",
    "    for idx, row in df.iterrows():\n",
    "        hyp_raw = row[hyp_col]\n",
    "        ref_raw = row[ref_col]\n",
    "        \n",
    "      # Preprocessed text for tokenization-dependent metrics\n",
    "        hyp_tokenized = preprocess_text(hyp_raw, tokenize=True)\n",
    "        ref_tokenized = preprocess_text(ref_raw, tokenize=True)\n",
    "        \n",
    "        hyp_raw = preprocess_text(hyp_raw, tokenize=False)\n",
    "        ref_raw = preprocess_text(ref_raw, tokenize=False)\n",
    "\n",
    "        # Calculate scores\n",
    "        scores['METEOR'].append(calculate_meteor(hyp_tokenized, ref_tokenized))\n",
    "        scores['GLEU'].append(calculate_gleu(hyp_tokenized, ref_tokenized))\n",
    "        P, R, F1 = calculate_bertscore(hyp_raw, ref_raw)\n",
    "        scores['BERTScore_P'].append(P)\n",
    "        scores['BERTScore_R'].append(R)\n",
    "        scores['BERTScore_F1'].append(F1)\n",
    "        scores['Rouge-L'].append(calculate_rouge_l(hyp_raw, ref_raw))\n",
    "        # scores['MoverScore'].append(calculate_moverscore(hyp_tokenized, ref_tokenized)) #todo\n",
    "        # scores['Mauve'].append(calculate_mauve(hyp_raw, ref_raw))\n",
    "   \n",
    "    for metric in scores:\n",
    "        df[metric] = scores[metric]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Call the function with the merged_df, hypothesis column, and reference column\n",
    "summary_result_df = append_scores(summary_out_df, 'BHC_LLM_out', 'BHC_human_generated')\n",
    "\n",
    "# Display the DataFrame with scores\n",
    "print(summary_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d2e7353-4d15-4332-92f0-8db44ba52bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>BHC_LLM_out</th>\n",
       "      <th>BHC_human_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20226692</td>\n",
       "      <td>The patient was admitted to the hospital due t...</td>\n",
       "      <td>Brief Hospital Course:\\nOn ___, Ms. ___ was ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20279012</td>\n",
       "      <td>The patient was admitted to the hospital due t...</td>\n",
       "      <td>Brief Hospital Course:\\nHospital course summar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20289285</td>\n",
       "      <td>The patient was admitted to the cardiology ser...</td>\n",
       "      <td>Brief Hospital Course:\\n___ PMH severe dilated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20390086</td>\n",
       "      <td>The patient was admitted to the hospital due t...</td>\n",
       "      <td>Brief Hospital Course:\\nP: ___ y/o F with uncl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20449726</td>\n",
       "      <td>The patient was admitted to the hospital for s...</td>\n",
       "      <td>Brief Hospital Course:\\nMr. ___ was admitted t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id                                        BHC_LLM_out  \\\n",
       "0  20226692  The patient was admitted to the hospital due t...   \n",
       "1  20279012  The patient was admitted to the hospital due t...   \n",
       "2  20289285  The patient was admitted to the cardiology ser...   \n",
       "3  20390086  The patient was admitted to the hospital due t...   \n",
       "4  20449726  The patient was admitted to the hospital for s...   \n",
       "\n",
       "                                 BHC_human_generated  \n",
       "0  Brief Hospital Course:\\nOn ___, Ms. ___ was ad...  \n",
       "1  Brief Hospital Course:\\nHospital course summar...  \n",
       "2  Brief Hospital Course:\\n___ PMH severe dilated...  \n",
       "3  Brief Hospital Course:\\nP: ___ y/o F with uncl...  \n",
       "4  Brief Hospital Course:\\nMr. ___ was admitted t...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc9172ae-8702-4dcc-9bdc-29afb2b91c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytest in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (7.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/s.wendelken/.local/lib/python3.9/site-packages (from pytest) (23.2.0)\n",
      "Requirement already satisfied: iniconfig in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from pytest) (1.1.1)\n",
      "Requirement already satisfied: packaging in /home/s.wendelken/.local/lib/python3.9/site-packages (from pytest) (24.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from pytest) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from pytest) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages (from pytest) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk mauve-text sacrebleu rouge-score evaluate\n",
    "# !pip install bert-score torch\n",
    "# !pip install moverscore\n",
    "# !pip install pyemd\n",
    "# !pip install transformers\n",
    "!pip install pytest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
