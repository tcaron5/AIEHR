{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aae1247-8177-4fa5-ab37-16cf2c7ef6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "# path for input and target data tables\n",
    "\n",
    "diagnosis_path = '../discharge_me/data/test_phase_2/diagnosis_hadm.csv'\n",
    "discharge_path ='../discharge_me/data/test_phase_2/discharge.csv'\n",
    "edstays_path = '../discharge_me/data/test_phase_2/edstays.csv'\n",
    "radiology_path = '../discharge_me/data/test_phase_2/radiology.csv'\n",
    "triage_path = '../discharge_me/data/test_phase_2/triage.csv'\n",
    "target_path = '../discharge_me/data/test_phase_2/discharge_target.csv'\n",
    "discharge_sections_path = '../discharge_me/data/test_phase_2/discharge_sections.csv'\n",
    "radiology_sections_path = '../discharge_me/data/test_phase_2/radiology_sections.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# read data\n",
    "diagnosis_df = pd.read_csv(diagnosis_path, keep_default_na=False)\n",
    "discharge_df = pd.read_csv(discharge_path, keep_default_na=False)\n",
    "edstays_df = pd.read_csv(edstays_path, keep_default_na=False)\n",
    "radiology_df = pd.read_csv(radiology_path, keep_default_na=False)\n",
    "triage_df = pd.read_csv(triage_path, keep_default_na=False)\n",
    "target_df = pd.read_csv(target_path, keep_default_na=False)\n",
    "\n",
    "discharge_sections_df = pd.read_csv(discharge_sections_path, keep_default_na=False)\n",
    "radiology_sections_df = pd.read_csv(radiology_sections_path, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429c9d7a-ff55-486e-9f68-6a2aee7049f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CC</th>\n",
       "      <th>Service</th>\n",
       "      <th>Major Surgical Procedure</th>\n",
       "      <th>HPI</th>\n",
       "      <th>PMH</th>\n",
       "      <th>SOC</th>\n",
       "      <th>FH</th>\n",
       "      <th>...</th>\n",
       "      <th>Problem List</th>\n",
       "      <th>Physical Exam</th>\n",
       "      <th>Medication Lists</th>\n",
       "      <th>Pertinent Results</th>\n",
       "      <th>BHC</th>\n",
       "      <th>Transitional Issues</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Discharge Instructions</th>\n",
       "      <th>Followup Instructions</th>\n",
       "      <th>Discharge Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Shortness of Breath</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>- COPD/Asthma on home 2L O2\\n- Atypical Chest ...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother with asthma and hypertension. Father wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION PHYSICAL EXAM:\\n====================...</td>\n",
       "      <td>is accurate and complete.\\n1. Acetaminophen 32...</td>\n",
       "      <td>ADMISSION LABS: \\n=========================\\n_...</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>==========================\\n[] For pt's contin...</td>\n",
       "      <td>Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...</td>\n",
       "      <td>Dear Ms. ___,\\n\\nYou were admitted to ___ afte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>fever</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nRagweed / morphine /...</td>\n",
       "      <td>none</td>\n",
       "      <td>Mr ___ is a ___ with h/o stage IV Hodgkins c1d...</td>\n",
       "      <td>1. Sarcoidosis, dx skin bx: intestinal &amp; pulmo...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother: ___, cardiac disease.  \\nFather: diver...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION EXAM\\nVitals: 124/67 on neosynephrin...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>ADMISSION LABS\\n___ 10:40AM BLOOD WBC-0.2* RBC...</td>\n",
       "      <td>___ male with h/o Hodgkin's lymphoma C1D17 ABV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>Dear Mr. ___,\\n\\nIt has been our pleasure to b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary Diagnosis\\nNeutropenic Fever, no sourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10003299</td>\n",
       "      <td>29323205</td>\n",
       "      <td>left leg weakness, falls</td>\n",
       "      <td>NEUROLOGY\\n \\nAllergies: \\nIodine-Iodine Conta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>___ is a ___ RH female with a PMHx of\\nparamed...</td>\n",
       "      <td>- prior paramedian pontine infarct (___) \\n- r...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother had stroke in her ___ or ___.  Her pate...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Exam:\\nVitals: T: 97.4 P: 65 R: 16  ...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>___ 01:10PM   GLUCOSE-125* UREA N-9 CREAT-0.9 ...</td>\n",
       "      <td>___ RH female with a PMHx of paramedian pontin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>Dear ___ were hospitalized due to symptoms of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ischemic stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10003502</td>\n",
       "      <td>20459702</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nnifedipine / Amitrip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ms. ___ is an ___ with atrial fibrillation/flu...</td>\n",
       "      <td>Hypertension/hyperlipidemia\\nCoronary artery d...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother deceased at ___ yo from breast cancer. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On admission: \\nVS 97.4 140/P 62 18 96\\nGEN Al...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>___ 10:15AM BLOOD WBC-6.4 RBC-3.64* Hgb-11.1* ...</td>\n",
       "      <td>Hospitalization Summary: \\nMs. ___ is an ___ y...</td>\n",
       "      <td>- monitoring of volume status and titration of...</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>It was a pleasure caring for you at ___ \\n___....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary: \\nAcute diastolic CHF exacerbation\\nN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10004322</td>\n",
       "      <td>28755331</td>\n",
       "      <td>multiple falls at group home</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nNo Known Allergies /...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr. ___ is a ___ year old male with a h/o psyc...</td>\n",
       "      <td>Psychosis \\nDiabetes \\nCOPD</td>\n",
       "      <td>___</td>\n",
       "      <td>Unknown to patient.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION PHYSICAL EXAM: \\nVS: 98.1 117/62 97 ...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>ADMISSION LABS:\\n___ 03:40PM BLOOD WBC-17.7* R...</td>\n",
       "      <td>___ with h/o psychosis admitted because of mul...</td>\n",
       "      <td>-He was discharged back home to the ___ Home\\n...</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>Dear Mr. ___,\\n\\nIt was our pleasure to care f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary: mechanical fall\\nSecondary: \\npsychos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id                            CC  \\\n",
       "0           0    10001884  24962904           Shortness of Breath   \n",
       "1           1    10003019  22774359                         fever   \n",
       "2           2    10003299  29323205      left leg weakness, falls   \n",
       "3           3    10003502  20459702                        Nausea   \n",
       "4           4    10004322  28755331  multiple falls at group home   \n",
       "\n",
       "                                             Service Major Surgical Procedure  \\\n",
       "0  MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...                      NaN   \n",
       "1  MEDICINE\\n \\nAllergies: \\nRagweed / morphine /...                     none   \n",
       "2  NEUROLOGY\\n \\nAllergies: \\nIodine-Iodine Conta...                      NaN   \n",
       "3  MEDICINE\\n \\nAllergies: \\nnifedipine / Amitrip...                      NaN   \n",
       "4  MEDICINE\\n \\nAllergies: \\nNo Known Allergies /...                      NaN   \n",
       "\n",
       "                                                 HPI  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "1  Mr ___ is a ___ with h/o stage IV Hodgkins c1d...   \n",
       "2  ___ is a ___ RH female with a PMHx of\\nparamed...   \n",
       "3  Ms. ___ is an ___ with atrial fibrillation/flu...   \n",
       "4  Mr. ___ is a ___ year old male with a h/o psyc...   \n",
       "\n",
       "                                                 PMH  SOC  \\\n",
       "0  - COPD/Asthma on home 2L O2\\n- Atypical Chest ...  ___   \n",
       "1  1. Sarcoidosis, dx skin bx: intestinal & pulmo...  ___   \n",
       "2  - prior paramedian pontine infarct (___) \\n- r...  ___   \n",
       "3  Hypertension/hyperlipidemia\\nCoronary artery d...  ___   \n",
       "4                        Psychosis \\nDiabetes \\nCOPD  ___   \n",
       "\n",
       "                                                  FH  ... Problem List  \\\n",
       "0  Mother with asthma and hypertension. Father wi...  ...          NaN   \n",
       "1  Mother: ___, cardiac disease.  \\nFather: diver...  ...          NaN   \n",
       "2  Mother had stroke in her ___ or ___.  Her pate...  ...          NaN   \n",
       "3  Mother deceased at ___ yo from breast cancer. ...  ...          NaN   \n",
       "4                                Unknown to patient.  ...          NaN   \n",
       "\n",
       "                                       Physical Exam  \\\n",
       "0  ADMISSION PHYSICAL EXAM:\\n====================...   \n",
       "1  ADMISSION EXAM\\nVitals: 124/67 on neosynephrin...   \n",
       "2  Admission Exam:\\nVitals: T: 97.4 P: 65 R: 16  ...   \n",
       "3  On admission: \\nVS 97.4 140/P 62 18 96\\nGEN Al...   \n",
       "4  ADMISSION PHYSICAL EXAM: \\nVS: 98.1 117/62 97 ...   \n",
       "\n",
       "                                    Medication Lists  \\\n",
       "0  is accurate and complete.\\n1. Acetaminophen 32...   \n",
       "1  The Preadmission Medication list is accurate a...   \n",
       "2  The Preadmission Medication list is accurate a...   \n",
       "3  The Preadmission Medication list is accurate a...   \n",
       "4  The Preadmission Medication list is accurate a...   \n",
       "\n",
       "                                   Pertinent Results  \\\n",
       "0  ADMISSION LABS: \\n=========================\\n_...   \n",
       "1  ADMISSION LABS\\n___ 10:40AM BLOOD WBC-0.2* RBC...   \n",
       "2  ___ 01:10PM   GLUCOSE-125* UREA N-9 CREAT-0.9 ...   \n",
       "3  ___ 10:15AM BLOOD WBC-6.4 RBC-3.64* Hgb-11.1* ...   \n",
       "4  ADMISSION LABS:\\n___ 03:40PM BLOOD WBC-17.7* R...   \n",
       "\n",
       "                                                 BHC  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "1  ___ male with h/o Hodgkin's lymphoma C1D17 ABV...   \n",
       "2  ___ RH female with a PMHx of paramedian pontin...   \n",
       "3  Hospitalization Summary: \\nMs. ___ is an ___ y...   \n",
       "4  ___ with h/o psychosis admitted because of mul...   \n",
       "\n",
       "                                 Transitional Issues  \\\n",
       "0  ==========================\\n[] For pt's contin...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  - monitoring of volume status and titration of...   \n",
       "4  -He was discharged back home to the ___ Home\\n...   \n",
       "\n",
       "                                         Disposition  \\\n",
       "0  Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...   \n",
       "1  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "2  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "3  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "4  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "\n",
       "                              Discharge Instructions Followup Instructions  \\\n",
       "0  Dear Ms. ___,\\n\\nYou were admitted to ___ afte...                   NaN   \n",
       "1  Dear Mr. ___,\\n\\nIt has been our pleasure to b...                   NaN   \n",
       "2  Dear ___ were hospitalized due to symptoms of ...                   NaN   \n",
       "3  It was a pleasure caring for you at ___ \\n___....                   NaN   \n",
       "4  Dear Mr. ___,\\n\\nIt was our pleasure to care f...                   NaN   \n",
       "\n",
       "                                 Discharge Diagnosis  \n",
       "0  PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...  \n",
       "1  Primary Diagnosis\\nNeutropenic Fever, no sourc...  \n",
       "2                                    Ischemic stroke  \n",
       "3  Primary: \\nAcute diastolic CHF exacerbation\\nN...  \n",
       "4  Primary: mechanical fall\\nSecondary: \\npsychos...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discharge_sections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89368b2a-adfa-4c9c-8a4a-b141f0add9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>EXAMINATION</th>\n",
       "      <th>INDICATION</th>\n",
       "      <th>TECHNIQUE</th>\n",
       "      <th>COMPARISON</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Chest:  Frontal and lateral views</td>\n",
       "      <td>History: ___ with dyspnea  // eval for pneumonia</td>\n",
       "      <td>Chest:  Frontal and Lateral</td>\n",
       "      <td>:  ___</td>\n",
       "      <td>Mild basilar atelectasis is seen without focal...</td>\n",
       "      <td>Mild basilar atelectasis without definite foca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>Chest, frontal and lateral views.</td>\n",
       "      <td>Fever, on chemotherapy.\\n\\n___.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frontal and lateral views of the chest were ob...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>Chest, single AP upright portable view.</td>\n",
       "      <td>Neutropenic fever, septic shock, worsening hyp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There has been interval placement of a right i...</td>\n",
       "      <td>Interval placement of right internal jugular c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AP chest compared to ___:\\n\\nMultifocal pulmon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>Evaluation of the patient with Hodgkin's lymph...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDCT of the chest was obtained from thoracic i...</td>\n",
       "      <td>:  ___ PET CT and chest radiograph from ___.</td>\n",
       "      <td>Aorta and pulmonary arteries are normal in dia...</td>\n",
       "      <td>1.  No evidence of new pulmonary abnormalities...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id  \\\n",
       "0           0    10001884  24962904   \n",
       "1           1    10003019  22774359   \n",
       "2           2    10003019  22774359   \n",
       "3           3    10003019  22774359   \n",
       "4           4    10003019  22774359   \n",
       "\n",
       "                                         EXAMINATION  \\\n",
       "0                  Chest:  Frontal and lateral views   \n",
       "1                  Chest, frontal and lateral views.   \n",
       "2            Chest, single AP upright portable view.   \n",
       "3                                                NaN   \n",
       "4  Evaluation of the patient with Hodgkin's lymph...   \n",
       "\n",
       "                                          INDICATION  \\\n",
       "0   History: ___ with dyspnea  // eval for pneumonia   \n",
       "1                    Fever, on chemotherapy.\\n\\n___.   \n",
       "2  Neutropenic fever, septic shock, worsening hyp...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                           TECHNIQUE  \\\n",
       "0                        Chest:  Frontal and Lateral   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  MDCT of the chest was obtained from thoracic i...   \n",
       "\n",
       "                                     COMPARISON  \\\n",
       "0                                        :  ___   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4  :  ___ PET CT and chest radiograph from ___.   \n",
       "\n",
       "                                            FINDINGS  \\\n",
       "0  Mild basilar atelectasis is seen without focal...   \n",
       "1  Frontal and lateral views of the chest were ob...   \n",
       "2  There has been interval placement of a right i...   \n",
       "3                                                NaN   \n",
       "4  Aorta and pulmonary arteries are normal in dia...   \n",
       "\n",
       "                                          IMPRESSION  \n",
       "0  Mild basilar atelectasis without definite foca...  \n",
       "1                                                NaN  \n",
       "2  Interval placement of right internal jugular c...  \n",
       "3  AP chest compared to ___:\\n\\nMultifocal pulmon...  \n",
       "4  1.  No evidence of new pulmonary abnormalities...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiology_sections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f5823c-fc20-4ce4-a215-6c55f3893112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CC</th>\n",
       "      <th>Service</th>\n",
       "      <th>Major Surgical Procedure</th>\n",
       "      <th>HPI</th>\n",
       "      <th>PMH</th>\n",
       "      <th>SOC</th>\n",
       "      <th>FH</th>\n",
       "      <th>...</th>\n",
       "      <th>Problem List</th>\n",
       "      <th>Physical Exam</th>\n",
       "      <th>Medication Lists</th>\n",
       "      <th>Pertinent Results</th>\n",
       "      <th>BHC</th>\n",
       "      <th>Transitional Issues</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Discharge Instructions</th>\n",
       "      <th>Followup Instructions</th>\n",
       "      <th>Discharge Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Shortness of Breath</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>- COPD/Asthma on home 2L O2\\n- Atypical Chest ...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother with asthma and hypertension. Father wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION PHYSICAL EXAM:\\n====================...</td>\n",
       "      <td>is accurate and complete.\\n1. Acetaminophen 32...</td>\n",
       "      <td>ADMISSION LABS: \\n=========================\\n_...</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>==========================\\n[] For pt's contin...</td>\n",
       "      <td>Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...</td>\n",
       "      <td>Dear Ms. ___,\\n\\nYou were admitted to ___ afte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id                   CC  \\\n",
       "0           0    10001884  24962904  Shortness of Breath   \n",
       "\n",
       "                                             Service Major Surgical Procedure  \\\n",
       "0  MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...                      NaN   \n",
       "\n",
       "                                                 HPI  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "\n",
       "                                                 PMH  SOC  \\\n",
       "0  - COPD/Asthma on home 2L O2\\n- Atypical Chest ...  ___   \n",
       "\n",
       "                                                  FH  ... Problem List  \\\n",
       "0  Mother with asthma and hypertension. Father wi...  ...          NaN   \n",
       "\n",
       "                                       Physical Exam  \\\n",
       "0  ADMISSION PHYSICAL EXAM:\\n====================...   \n",
       "\n",
       "                                    Medication Lists  \\\n",
       "0  is accurate and complete.\\n1. Acetaminophen 32...   \n",
       "\n",
       "                                   Pertinent Results  \\\n",
       "0  ADMISSION LABS: \\n=========================\\n_...   \n",
       "\n",
       "                                                 BHC  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "\n",
       "                                 Transitional Issues  \\\n",
       "0  ==========================\\n[] For pt's contin...   \n",
       "\n",
       "                                         Disposition  \\\n",
       "0  Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...   \n",
       "\n",
       "                              Discharge Instructions Followup Instructions  \\\n",
       "0  Dear Ms. ___,\\n\\nYou were admitted to ___ afte...                   NaN   \n",
       "\n",
       "                                 Discharge Diagnosis  \n",
       "0  PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discharge_sections_df[discharge_sections_df['hadm_id']==24962904]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59b1ad5-183e-4632-ba3e-b69422e4779c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>EXAMINATION</th>\n",
       "      <th>INDICATION</th>\n",
       "      <th>TECHNIQUE</th>\n",
       "      <th>COMPARISON</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Chest:  Frontal and lateral views</td>\n",
       "      <td>History: ___ with dyspnea  // eval for pneumonia</td>\n",
       "      <td>Chest:  Frontal and Lateral</td>\n",
       "      <td>:  ___</td>\n",
       "      <td>Mild basilar atelectasis is seen without focal...</td>\n",
       "      <td>Mild basilar atelectasis without definite foca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id                        EXAMINATION  \\\n",
       "0           0    10001884  24962904  Chest:  Frontal and lateral views   \n",
       "\n",
       "                                         INDICATION  \\\n",
       "0  History: ___ with dyspnea  // eval for pneumonia   \n",
       "\n",
       "                     TECHNIQUE COMPARISON  \\\n",
       "0  Chest:  Frontal and Lateral     :  ___   \n",
       "\n",
       "                                            FINDINGS  \\\n",
       "0  Mild basilar atelectasis is seen without focal...   \n",
       "\n",
       "                                          IMPRESSION  \n",
       "0  Mild basilar atelectasis without definite foca...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiology_sections_df[radiology_sections_df['hadm_id']==24962904]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119ca17e-187d-4277-bca8-de378b53327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-5.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138d23c8-6c21-4963-bc23-18f5ed13c9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11f1bb798794961935bf5df91d68863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the radiological tests and findings Based on the following details: Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15\n",
      "___ 06:38AM BLOOD Calcium-9.8 Phos-4.1 Mg-2.0\n",
      "___ 06:38AM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 06:38AM BLOOD Lactate-1.5\n",
      "___ 06:38AM BLOOD proBNP-181\n",
      "___ 06:38AM BLOOD cTropnT-<0.01\n",
      "\n",
      "DIAGNOSIS: \n",
      "=========================\n",
      "Pneumonia due to Streptococcus pneumoniae.\n",
      "\n",
      "What are the radiological findings?\n",
      "What are the laboratory findings?\n",
      "What is the diagnosis?\n",
      "\n",
      "Based on the details provided, the radiological findings are:\n",
      "\n",
      "* Mild basilar atelectasis without definite focal consolidation (as seen on the frontal and lateral views of the chest X-ray)\n",
      "\n",
      "The laboratory findings are:\n",
      "\n",
      "* White blood cell count (WBC) of 7.1 x 10^9/L with a neutrophil count of 81.8%\n",
      "* Red blood cell count (RBC) of 4.74 x 10^12/L with a hemoglobin (Hb) level of 12.8 g/dL and a hematocrit (Hct) level of 41.1%\n",
      "* Mean corpuscular volume (MCV) of 87 fL, mean corpuscular hemoglobin (MCH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "def generate_summary(hadm_id, discharge_df, radiology_df, question):\n",
    "    # Columns relevant for the discharge summary and radiology summary\n",
    "    discharge_cols = ['Pertinent Results']\n",
    "    radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Prepare the input for the model\n",
    "    combined_input = f\"{question} Based on the following details: {radiology_info} {discharge_info}\"\n",
    "    inputs = tokenizer(combined_input, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=1024, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary(hadm_id, discharge_sections_df, radiology_sections_df, question)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8022fd-61a2-42a3-9297-7335608ff02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c21ea76c73461f873a37705412d375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m hadm_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24962904\u001b[39m  \u001b[38;5;66;03m# example HADM ID\u001b[39;00m\n\u001b[1;32m     44\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize the radiological tests and findings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 45\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhadm_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdischarge_sections_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiology_sections_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[0;34m(hadm_id, discharge_df, radiology_df, question)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Generate the response using the model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Decode and return the summary\u001b[39;00m\n\u001b[1;32m     27\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/generation/utils.py:1693\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1685\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1686\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1687\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1688\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1689\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1690\u001b[0m     )\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1709\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1710\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1711\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1717\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1718\u001b[0m     )\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/generation/utils.py:3612\u001b[0m, in \u001b[0;36mGenerationMixin._beam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3606\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3607\u001b[0m     outputs,\n\u001b[1;32m   3608\u001b[0m     model_kwargs,\n\u001b[1;32m   3609\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3610\u001b[0m )\n\u001b[1;32m   3611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3612\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_temporary_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_key_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\n\u001b[1;32m   3614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[1;32m   3617\u001b[0m     beam_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((beam_indices[beam_idx[i]] \u001b[38;5;241m+\u001b[39m (beam_idx[i],) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(beam_indices))))\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/generation/utils.py:2888\u001b[0m, in \u001b[0;36mGenerationMixin._temporary_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;66;03m# Exception 1: code path for models using the legacy cache format\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m-> 2888\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;66;03m# Exception 2: models with different cache formats. These are limited to `DynamicCache` until their\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;66;03m# cache format is standardized, to avoid adding complexity to the codebase.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbloom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_class \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgptbigcode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_class:\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1342\u001b[0m, in \u001b[0;36mLlamaForCausalLM._reorder_cache\u001b[0;34m(past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   1339\u001b[0m reordered_past \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_past \u001b[38;5;129;01min\u001b[39;00m past_key_values:\n\u001b[1;32m   1341\u001b[0m     reordered_past \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1342\u001b[0m         \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1343\u001b[0m     )\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reordered_past\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1342\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1339\u001b[0m reordered_past \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_past \u001b[38;5;129;01min\u001b[39;00m past_key_values:\n\u001b[1;32m   1341\u001b[0m     reordered_past \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1342\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m past_state \u001b[38;5;129;01min\u001b[39;00m layer_past),\n\u001b[1;32m   1343\u001b[0m     )\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reordered_past\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "def generate_summary(hadm_id, discharge_df, radiology_df, question):\n",
    "    # Columns relevant for the discharge summary and radiology summary\n",
    "    discharge_cols = ['Pertinent Results']\n",
    "    radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Prepare the input for the model\n",
    "    combined_input = f\"{question} Based on the following details: {radiology_info} {discharge_info}\"\n",
    "    inputs = tokenizer(combined_input, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=1024, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Assuming the summary starts after the question, you could use the following method to extract it:\n",
    "    # Find the end of the question in the summary\n",
    "    summary_start_idx = summary.find(question) + len(question)\n",
    "    if summary_start_idx >= len(question):\n",
    "        # Extract text after the question\n",
    "        summary = summary[summary_start_idx:].strip()\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary(hadm_id, discharge_sections_df, radiology_sections_df, question)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fca914-7667-4442-992f-f52f23fc9008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum input length of the model: 1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# Access the model's configuration to find the maximum input length\n",
    "max_model_length = tokenizer.model_max_length\n",
    "print(\"Maximum input length of the model:\", max_model_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266b9163-82f2-4da2-b766-a2dddbbf9a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in input: 13\n",
      "The input text fits within the model's maximum input length.\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "input_text = \"Example input text that you want to process with the model.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=max_model_length)\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = tokens.input_ids.size(1)  # .size(1) gives the number of tokens (ignoring batch dimension)\n",
    "print(\"Number of tokens in input:\", num_tokens)\n",
    "\n",
    "# Compare with the model's max length\n",
    "if num_tokens > max_model_length:\n",
    "    print(\"The input text is too long and will be truncated.\")\n",
    "else:\n",
    "    print(\"The input text fits within the model's maximum input length.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7a08e-76b4-4e15-aacf-7101b5545c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "input_text = \"Example input text that you want to process with the model.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=max_model_length)\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = tokens.input_ids.size(1)  # .size(1) gives the number of tokens (ignoring batch dimension)\n",
    "print(\"Number of tokens in input:\", num_tokens)\n",
    "\n",
    "# Compare with the model's max length\n",
    "if num_tokens > max_model_length:\n",
    "    print(\"The input text is too long and will be truncated.\")\n",
    "else:\n",
    "    print(\"The input text fits within the model's maximum input length.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7731ac0-cf87-4d79-8b1f-3eaf6ba642e6",
   "metadata": {},
   "source": [
    "## Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7ed4da-8524-4379-9cee-0200945b70ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11000f6a5c644e6bfff65dbb00bb511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the following details: Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15\n",
      "___ 06:38AM BLOOD Calcium-9.8 Phos-4.1 Mg-2.0\n",
      "___ 06:38AM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 06:38AM BLOOD Lactate-1.5\n",
      "___ 06:38AM BLOOD proBNP-181\n",
      "___ 06:38AM BLOOD cTropnT-<0.01\n",
      "\n",
      "What are the radiological findings?\n",
      "What are the laboratory findings?\n",
      "What are the electrocardiogram (ECG) findings?\n",
      "What are the discharge laboratory findings?\n",
      "\n",
      "Based on the details provided, the radiological findings are:\n",
      "\n",
      "* Mild basilar atelectasis without definite focal consolidation on the chest X-ray.\n",
      "\n",
      "The laboratory findings are:\n",
      "\n",
      "* White blood cell count (WBC) of 7.1 x 10^9/L with a neutrophil count of 81.8%, lymphocyte count of 9.6%, monocyte count of 7.6%, and eosinophil count of 0.3%.\n",
      "* Red blood cell (RBC) count of 4.74 x 10^12/L with a hemoglobin (Hb) level of 12.8 g/dL, hematocrit (Hct) level of 41.1%, mean corpuscular volume (MCV) of 87 fL, mean corpuscular hemoglobin (MCH) level of 27.0 pg, and mean corpuscular hemoglobin concentration (MCHC) level of 31.1%.\n",
      "* Platelet count of 144 x 10^9/L.\n",
      "* Blood urea nitrogen (BUN) level of 18 mg/dL, creatinine level of 0.8 mg/dL, sodium level of 137 mM, potassium level of 3.1 mM (repleted), chloride level of 94 mM, and bicarbonate level of 31 mM.\n",
      "* Lactate level of 1.5 mM.\n",
      "* Pro-brain-type natriuretic peptide (proBNP) level of 181 pg/mL.\n",
      "\n",
      "The electrocardiogram (ECG) findings are:\n",
      "\n",
      "* Sinus rhythm at a heart rate of 69 beats per minute (bpm).\n",
      "* Left bundle branch block (LBBB).\n",
      "* No acute ST or T wave changes.\n",
      "\n",
      "The discharge laboratory findings are:\n",
      "\n",
      "* White blood cell count (WBC) of 14.4 x 10^9/L with a neutrophil count of 58.2%, lymphocyte count of 0.68%, monocyte count of 0.54%, and eosinophil count of 0.02%.\n",
      "* Red blood cell (RBC) count of 4.34 x 10^12/L with a hemoglobin (Hb) level of 11.8 g/dL, hematocrit (Hct) level of 37.6%, mean corpuscular volume (MCV) of 87 fL, mean corpuscular hemoglobin (MCH) level of 27.2 pg, and mean corpuscular hemoglobin concentration (MCHC) level of 31.4%.\n",
      "* Platelet count of 144 x 10^9/L.\n",
      "* Blood urea nitrogen (BUN) level of 18 mg/dL, creatinine level of 0.8 mg/dL, sodium level of 137 mM, potassium level of 3.1 mM (repleted), chloride level of 94 mM, and bicarbonate level of 31 mM.\n",
      "* Lactate level of 1.5 mM.\n",
      "* Pro-brain-type natriuretic peptide (proBNP) level of\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "def generate_summary(hadm_id, discharge_df, radiology_df, question):\n",
    "    # Columns relevant for the discharge summary and radiology summary\n",
    "    discharge_cols = ['Pertinent Results']\n",
    "    radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Prepare the input for the model\n",
    "    context = f\"{radiology_info} {discharge_info}\"\n",
    "    combined_input = f\"{question} Based on the following details: {context}\"\n",
    "    context_length = len(tokenizer.tokenize(context))\n",
    "\n",
    "    # Tokenize the input\n",
    "    max_input_length = min(1024 + context_length, tokenizer.model_max_length)  # to avoid exceeding the model's maximum capacity\n",
    "    inputs = tokenizer(combined_input, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
    "\n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=max_input_length, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Assuming the summary starts after the question, you could use the following method to extract it:\n",
    "    # Find the end of the question in the summary\n",
    "    summary_start_idx = summary.find(question) + len(question)\n",
    "    if summary_start_idx >= len(question):\n",
    "        # Extract text after the question\n",
    "        summary = summary[summary_start_idx:].strip()\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary(hadm_id, discharge_sections_df, radiology_sections_df, question)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59ded49-af6f-46bb-b5e6-b4b3c7d85dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Add token as git credential? (Y/n) Token is valid (permission: read).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n",
      "\n",
      "/usr/lib/python3.9/getpass.py:91: GetPassWarning: Can not control echo on the terminal.\n",
      "  passwd = fallback_getpass(prompt, stream)\n",
      "Warning: Password input may be echoed.\n",
      "Enter your token (input will not be visible): \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "token = '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'\n",
    "input_text = f\"{token}\\nY\\n\"  # Combine token and 'Y' input\n",
    "\n",
    "# Run the Huggingface CLI login command\n",
    "process = subprocess.Popen(['huggingface-cli', 'login'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate(input_text.encode())\n",
    "\n",
    "# Print any output or error if necessary (optional)\n",
    "print(stdout.decode())\n",
    "print(stderr.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b939360-0239-4de5-ae1c-4ff28efa7490",
   "metadata": {},
   "source": [
    "## Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667a1cd9-7342-4cc4-b106-872889ff28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q&A with model: Llama-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5d5e10b647432ebec4dd7bf95901f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: Context: Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15 \n",
      "\n",
      "Question: Based on the information provided, Summarize the radiological tests and findings \n",
      "\n",
      "Answer: Chest x-ray showed mild basilar atelectasis without definite focal consolidation. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely diagnosis? \n",
      "\n",
      "Answer: The most likely diagnosis is community-acquired pneumonia (CAP) based on the clinical presentation of dyspnea, fever, and cough, along with the presence of mild basilar atelectasis on chest x-ray. \n",
      "\n",
      "Question: Based on the information provided, What is the next best step in management? \n",
      "\n",
      "Answer: The next best step in management is to start antibiotics and initiate supplemental oxygen therapy as needed. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely complication of CAP? \n",
      "\n",
      "Answer: The most likely complication of CAP is respiratory failure, which can occur due to the presence of pneumonia, especially in patients with underlying lung disease. Other potential complications include sepsis and secondary infections such as empyema or lung abscess. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of respiratory failure in this patient? \n",
      "\n",
      "Answer: The most likely cause of respiratory failure in this patient is the presence of pneumonia, especially in the setting of underlying lung disease. Other potential causes of respiratory failure include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for respiratory failure in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for respiratory failure in this patient is to provide supplemental oxygen therapy as needed to maintain oxygen saturation levels above 90%. Other interventions such as noninvasive ventilation or intubation may be necessary in severe cases of respiratory failure. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of hypoxemia in this patient? \n",
      "\n",
      "Answer: The most likely cause of hypoxemia in this patient is the presence of pneumonia, especially in the setting of underlying lung disease. Other potential causes of hypoxemia include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for hypoxemia in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for hypoxemia in this patient is to provide supplemental oxygen therapy as needed to maintain oxygen saturation levels above 90%. Other interventions such as noninvasive ventilation or intubation may be necessary in severe cases of hypoxemia. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of tachypnea in this patient? \n",
      "\n",
      "Answer: The most likely cause of tachypnea in this patient is the presence of pneumonia, especially in the setting of underlying lung disease. Other potential causes of tachypnea include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for tachypnea in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for tachypnea in this patient is to provide supplemental oxygen therapy as needed to maintain oxygen saturation levels above 90%. Other interventions such as noninvasive ventilation or intubation may be necessary in severe cases of tachypnea. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of tachycardia in this patient? \n",
      "\n",
      "Answer: The most likely cause of tachycardia in this patient is the presence of fever and tachypnea, which can lead to increased sympathetic tone and increased heart rate. Other potential causes of tachycardia include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for tachycardia in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for tachycardia in this patient is to treat the underlying cause (e.g., pneumonia) and monitor heart rate closely. If the heart rate remains elevated despite treatment, beta-blockers may be considered. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of bradycardia in this patient? \n",
      "\n",
      "Answer: The most likely cause of bradycardia in this patient is the presence of sepsis, which can lead to decreased sympathetic tone and decreased heart rate. Other potential causes of bradycardia include heart failure, neuromuscular disorders, and medications such as beta-blockers. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for bradycardia in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for bradycardia in this patient is to treat the underlying cause (e.g., sepsis) and monitor heart rate closely. If the heart rate remains low despite treatment, atropine may be considered. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of hypertension in this patient? \n",
      "\n",
      "Answer: The most likely cause of hypertension in this patient is the presence of fever and tachycardia, which can lead to increased sympathetic tone and increased blood pressure. Other\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "\n",
    "def generate_summary_with_pipeline(hadm_id, discharge_df, radiology_df, question, discharge_cols, radiology_cols, tokenizer):\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Combine all relevant information into one context string\n",
    "    context = f\"{radiology_info} {discharge_info}\"\n",
    "    \n",
    "    # Prepare the final prompt for the model\n",
    "    final_prompt = f\"Context: {context} \\n\\nQuestion: Based on the information provided, {question} \\n\\nAnswer:\"\n",
    "    context_length = len(tokenizer.tokenize(final_prompt))\n",
    "    max_input_length = min(1024 + context_length, tokenizer.model_max_length)\n",
    "    \n",
    "    # Initialize the pipeline with the Llama-3 model\n",
    "    print(\"\\nQ&A with model: Llama-3\")\n",
    "    llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B')\n",
    "\n",
    "    # Generate the response using the model\n",
    "    generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\n",
    "\n",
    "    # Output the generated text\n",
    "    return generated_text[0]['generated_text']\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B')\n",
    "\n",
    "# Specify the columns to use\n",
    "discharge_cols = ['Pertinent Results']\n",
    "radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary_with_pipeline(hadm_id, discharge_sections_df, radiology_sections_df, question, discharge_cols, radiology_cols, tokenizer)\n",
    "print(\"Generated Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b93aa95-df69-4e47-9d43-662edf7c0a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting cmake>=3.21 (from vllm)\n",
      "  Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (5.9.8)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.31.0)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.40.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.19.1)\n",
      "Collecting fastapi (from vllm)\n",
      "  Using cached fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.7.1)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.20.0)\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.6.0)\n",
      "Collecting lm-format-enforcer==0.9.8 (from vllm)\n",
      "  Using cached lm_format_enforcer-0.9.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting outlines==0.0.34 (from vllm)\n",
      "  Using cached outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.11.0)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (3.13.4)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Using cached ray-2.20.0-cp39-cp39-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting nvidia-ml-py (from vllm)\n",
      "  Using cached nvidia_ml_py-12.550.52-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting vllm-nccl-cu12<2.19,>=2.18 (from vllm)\n",
      "  Using cached vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==2.2.1 (from vllm)\n",
      "  Using cached torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting xformers==0.0.25 (from vllm)\n",
      "  Using cached xformers-0.0.25-cp39-cp39-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (23.2)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (3.1.3)\n",
      "Collecting lark (from outlines==0.0.34->vllm)\n",
      "  Using cached lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.6.0)\n",
      "Collecting cloudpickle (from outlines==0.0.34->vllm)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines==0.0.34->vllm)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.13.0)\n",
      "Collecting numba (from outlines==0.0.34->vllm)\n",
      "  Using cached numba-0.59.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.4.0)\n",
      "Requirement already satisfied: referencing in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (0.35.0)\n",
      "Requirement already satisfied: jsonschema in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (4.21.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tiktoken==0.6.0->vllm) (2024.4.16)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch==2.2.1->vllm)\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (2.18.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (8.1.7)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm)\n",
      "  Using cached msgpack-1.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (5.26.1)\n",
      "Requirement already satisfied: aiosignal in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2024.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tokenizers>=0.19.1->vllm) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (4.66.2)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->vllm)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Using cached websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from starlette<0.38.0,>=0.37.2->fastapi->vllm) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.18.0)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->outlines==0.0.34->vllm)\n",
      "  Using cached llvmlite-0.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from sympy->torch==2.2.1->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.2.1)\n",
      "Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl (84.0 MB)\n",
      "Using cached lm_format_enforcer-0.9.8-py3-none-any.whl (40 kB)\n",
      "Using cached outlines-0.0.34-py3-none-any.whl (76 kB)\n",
      "Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m644.2/755.5 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 102, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"/usr/lib/python3.9/tempfile.py\", line 478, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/usr/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5c1549-41c5-4055-86c5-930c2431d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting cmake>=3.21 (from vllm)\n",
      "  Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (5.9.8)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.31.0)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.40.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.19.1)\n",
      "Collecting fastapi (from vllm)\n",
      "  Using cached fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.7.1)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.20.0)\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.6.0)\n",
      "Collecting lm-format-enforcer==0.9.8 (from vllm)\n",
      "  Using cached lm_format_enforcer-0.9.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting outlines==0.0.34 (from vllm)\n",
      "  Using cached outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.11.0)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (3.13.4)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Using cached ray-2.20.0-cp39-cp39-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting nvidia-ml-py (from vllm)\n",
      "  Using cached nvidia_ml_py-12.550.52-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting vllm-nccl-cu12<2.19,>=2.18 (from vllm)\n",
      "  Using cached vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==2.2.1 (from vllm)\n",
      "  Using cached torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting xformers==0.0.25 (from vllm)\n",
      "  Using cached xformers-0.0.25-cp39-cp39-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (23.2)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (3.1.3)\n",
      "Collecting lark (from outlines==0.0.34->vllm)\n",
      "  Using cached lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.6.0)\n",
      "Collecting cloudpickle (from outlines==0.0.34->vllm)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines==0.0.34->vllm)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.13.0)\n",
      "Collecting numba (from outlines==0.0.34->vllm)\n",
      "  Using cached numba-0.59.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.4.0)\n",
      "Requirement already satisfied: referencing in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (0.35.0)\n",
      "Requirement already satisfied: jsonschema in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (4.21.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tiktoken==0.6.0->vllm) (2024.4.16)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch==2.2.1->vllm)\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (2.18.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (8.1.7)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm)\n",
      "  Using cached msgpack-1.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (5.26.1)\n",
      "Requirement already satisfied: aiosignal in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2024.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tokenizers>=0.19.1->vllm) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (4.66.2)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->vllm)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Using cached websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from starlette<0.38.0,>=0.37.2->fastapi->vllm) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.18.0)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->outlines==0.0.34->vllm)\n",
      "  Using cached llvmlite-0.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from sympy->torch==2.2.1->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.2.1)\n",
      "Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl (84.0 MB)\n",
      "Using cached lm_format_enforcer-0.9.8-py3-none-any.whl (40 kB)\n",
      "Using cached outlines-0.0.34-py3-none-any.whl (76 kB)\n",
      "Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m644.2/755.5 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 102, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"/usr/lib/python3.9/tempfile.py\", line 478, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/usr/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d22a384-f533-495e-845c-b318a9427c8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vllm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM, SamplingParams\n\u001b[1;32m      2\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLM(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vllm'"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15829a75-c32c-4377-bd7d-d64891240804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting cmake>=3.21 (from vllm)\n",
      "  Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting psutil (from vllm)\n",
      "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Using cached sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting numpy (from vllm)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting requests (from vllm)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.40.0 (from vllm)\n",
      "  Using cached transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting tokenizers>=0.19.1 (from vllm)\n",
      "  Using cached tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting fastapi (from vllm)\n",
      "  Using cached fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pydantic>=2.0 (from vllm)\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "Collecting prometheus-client>=0.18.0 (from vllm)\n",
      "  Using cached prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tiktoken==0.6.0 (from vllm)\n",
      "  Using cached tiktoken-0.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting lm-format-enforcer==0.9.8 (from vllm)\n",
      "  Using cached lm_format_enforcer-0.9.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting outlines==0.0.34 (from vllm)\n",
      "  Using cached outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting typing-extensions (from vllm)\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting filelock>=3.10.4 (from vllm)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Using cached ray-2.20.0-cp39-cp39-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting nvidia-ml-py (from vllm)\n",
      "  Using cached nvidia_ml_py-12.550.52-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting vllm-nccl-cu12<2.19,>=2.18 (from vllm)\n",
      "  Using cached vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==2.2.1 (from vllm)\n",
      "  Using cached torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting xformers==0.0.25 (from vllm)\n",
      "  Using cached xformers-0.0.25-cp39-cp39-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting jinja2 (from outlines==0.0.34->vllm)\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting lark (from outlines==0.0.34->vllm)\n",
      "  Using cached lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting nest-asyncio (from outlines==0.0.34->vllm)\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting cloudpickle (from outlines==0.0.34->vllm)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines==0.0.34->vllm)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting scipy (from outlines==0.0.34->vllm)\n",
      "  Using cached scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting numba (from outlines==0.0.34->vllm)\n",
      "  Using cached numba-0.59.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting joblib (from outlines==0.0.34->vllm)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting referencing (from outlines==0.0.34->vllm)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting jsonschema (from outlines==0.0.34->vllm)\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken==0.6.0->vllm)\n",
      "  Using cached regex-2024.4.28-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting sympy (from torch==2.2.1->vllm)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.2.1->vllm)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting fsspec (from torch==2.2.1->vllm)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.1->vllm)\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->vllm)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic>=2.0->vllm)\n",
      "  Using cached pydantic_core-2.18.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting click>=7.0 (from ray>=2.9->vllm)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm)\n",
      "  Using cached msgpack-1.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray>=2.9->vllm)\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting aiosignal (from ray>=2.9->vllm)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist (from ray>=2.9->vllm)\n",
      "  Using cached frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->vllm)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->vllm)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->vllm)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->vllm)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.19.1->vllm)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.40.0->vllm)\n",
      "  Using cached safetensors-0.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers>=4.40.0->vllm)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->vllm)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Using cached websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting anyio<5,>=3.4.0 (from starlette<0.38.0,>=0.37.2->fastapi->vllm)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->outlines==0.0.34->vllm)\n",
      "  Using cached MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema->outlines==0.0.34->vllm)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->outlines==0.0.34->vllm)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->outlines==0.0.34->vllm)\n",
      "  Using cached rpds_py-0.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->outlines==0.0.34->vllm)\n",
      "  Using cached llvmlite-0.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.2.1->vllm)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm)\n",
      "  Using cached exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl (84.0 MB)\n",
      "Using cached lm_format_enforcer-0.9.8-py3-none-any.whl (40 kB)\n",
      "Using cached outlines-0.0.34-py3-none-any.whl (76 kB)\n",
      "Using cached tiktoken-0.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m698.4/755.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:16\u001b[0mm\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 102, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"/usr/lib/python3.9/tempfile.py\", line 478, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/usr/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15dbad19-a3dd-401f-ab4e-7d937e91db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                 Version\n",
      "--------------------------------------- --------------\n",
      "accelerate                              0.29.3\n",
      "aiohttp                                 3.9.5\n",
      "aiosignal                               1.3.1\n",
      "annotated-types                         0.6.0\n",
      "anyio                                   4.3.0\n",
      "argon2-cffi                             23.1.0\n",
      "argon2-cffi-bindings                    21.2.0\n",
      "arrow                                   1.3.0\n",
      "asttokens                               2.4.1\n",
      "async-lru                               2.0.4\n",
      "async-timeout                           4.0.3\n",
      "attrs                                   23.2.0\n",
      "Babel                                   2.14.0\n",
      "beautifulsoup4                          4.12.3\n",
      "bitsandbytes                            0.43.1\n",
      "bleach                                  6.1.0\n",
      "certifi                                 2024.2.2\n",
      "cffi                                    1.16.0\n",
      "charset-normalizer                      3.3.2\n",
      "click                                   8.1.7\n",
      "comm                                    0.2.2\n",
      "dataclasses-json                        0.6.5\n",
      "debugpy                                 1.8.1\n",
      "decorator                               5.1.1\n",
      "defusedxml                              0.7.1\n",
      "Deprecated                              1.2.14\n",
      "dirtyjson                               1.0.8\n",
      "distro                                  1.9.0\n",
      "einops                                  0.8.0\n",
      "exceptiongroup                          1.2.1\n",
      "executing                               2.0.1\n",
      "fastjsonschema                          2.19.1\n",
      "filelock                                3.13.4\n",
      "fqdn                                    1.5.1\n",
      "frozenlist                              1.4.1\n",
      "fsspec                                  2024.3.1\n",
      "greenlet                                3.0.3\n",
      "h11                                     0.14.0\n",
      "httpcore                                1.0.5\n",
      "httpx                                   0.27.0\n",
      "huggingface-hub                         0.20.3\n",
      "idna                                    3.7\n",
      "importlib_metadata                      7.1.0\n",
      "install                                 1.3.5\n",
      "ipykernel                               6.29.4\n",
      "ipython                                 8.18.1\n",
      "ipywidgets                              8.1.2\n",
      "isoduration                             20.11.0\n",
      "jedi                                    0.19.1\n",
      "Jinja2                                  3.1.3\n",
      "joblib                                  1.4.0\n",
      "json5                                   0.9.25\n",
      "jsonpatch                               1.33\n",
      "jsonpointer                             2.4\n",
      "jsonschema                              4.21.1\n",
      "jsonschema-specifications               2023.12.1\n",
      "jupyter                                 1.0.0\n",
      "jupyter_client                          8.6.1\n",
      "jupyter-console                         6.6.3\n",
      "jupyter_core                            5.7.2\n",
      "jupyter-events                          0.10.0\n",
      "jupyter-lsp                             2.2.5\n",
      "jupyter_server                          2.14.0\n",
      "jupyter_server_terminals                0.5.3\n",
      "jupyterlab                              4.1.6\n",
      "jupyterlab_pygments                     0.3.0\n",
      "jupyterlab_server                       2.27.1\n",
      "jupyterlab_widgets                      3.0.10\n",
      "langchain                               0.1.16\n",
      "langchain-community                     0.0.34\n",
      "langchain-core                          0.1.47\n",
      "langchain-text-splitters                0.0.1\n",
      "langsmith                               0.1.52\n",
      "llama-index                             0.10.33\n",
      "llama-index-agent-openai                0.2.3\n",
      "llama-index-cli                         0.1.12\n",
      "llama-index-core                        0.10.33\n",
      "llama-index-embeddings-huggingface      0.2.0\n",
      "llama-index-embeddings-langchain        0.1.2\n",
      "llama-index-embeddings-openai           0.1.9\n",
      "llama-index-indices-managed-llama-cloud 0.1.6\n",
      "llama-index-legacy                      0.9.48\n",
      "llama-index-llms-huggingface            0.1.4\n",
      "llama-index-llms-openai                 0.1.16\n",
      "llama-index-multi-modal-llms-openai     0.1.5\n",
      "llama-index-program-openai              0.1.6\n",
      "llama-index-question-gen-openai         0.1.3\n",
      "llama-index-readers-file                0.1.19\n",
      "llama-index-readers-llama-parse         0.1.4\n",
      "llama-parse                             0.4.2\n",
      "llamaindex-py-client                    0.1.19\n",
      "MarkupSafe                              2.1.5\n",
      "marshmallow                             3.21.1\n",
      "matplotlib-inline                       0.1.7\n",
      "mistune                                 3.0.2\n",
      "mpmath                                  1.3.0\n",
      "multidict                               6.0.5\n",
      "mypy-extensions                         1.0.0\n",
      "nbclient                                0.10.0\n",
      "nbconvert                               7.16.3\n",
      "nbformat                                5.10.4\n",
      "nest-asyncio                            1.6.0\n",
      "networkx                                3.2.1\n",
      "nltk                                    3.8.1\n",
      "notebook                                7.1.3\n",
      "notebook_shim                           0.2.4\n",
      "numpy                                   1.26.4\n",
      "nvidia-cublas-cu12                      12.1.3.1\n",
      "nvidia-cuda-cupti-cu12                  12.1.105\n",
      "nvidia-cuda-nvrtc-cu12                  12.1.105\n",
      "nvidia-cuda-runtime-cu12                12.1.105\n",
      "nvidia-cudnn-cu12                       8.9.2.26\n",
      "nvidia-cufft-cu12                       11.0.2.54\n",
      "nvidia-curand-cu12                      10.3.2.106\n",
      "nvidia-cusolver-cu12                    11.4.5.107\n",
      "nvidia-cusparse-cu12                    12.1.0.106\n",
      "nvidia-nccl-cu12                        2.20.5\n",
      "nvidia-nvjitlink-cu12                   12.4.127\n",
      "nvidia-nvtx-cu12                        12.1.105\n",
      "openai                                  1.25.0\n",
      "orjson                                  3.10.1\n",
      "overrides                               7.7.0\n",
      "packaging                               23.2\n",
      "pandas                                  2.2.2\n",
      "pandocfilters                           1.5.1\n",
      "parso                                   0.8.4\n",
      "pexpect                                 4.9.0\n",
      "pillow                                  10.3.0\n",
      "pip                                     24.0\n",
      "platformdirs                            4.2.1\n",
      "prometheus_client                       0.20.0\n",
      "prompt-toolkit                          3.0.43\n",
      "protobuf                                5.26.1\n",
      "psutil                                  5.9.8\n",
      "ptyprocess                              0.7.0\n",
      "pure-eval                               0.2.2\n",
      "pycparser                               2.22\n",
      "pydantic                                2.7.1\n",
      "pydantic_core                           2.18.2\n",
      "Pygments                                2.17.2\n",
      "pypdf                                   4.2.0\n",
      "python-dateutil                         2.9.0.post0\n",
      "python-json-logger                      2.0.7\n",
      "pytz                                    2024.1\n",
      "PyYAML                                  6.0.1\n",
      "pyzmq                                   26.0.2\n",
      "qtconsole                               5.5.1\n",
      "QtPy                                    2.4.1\n",
      "referencing                             0.35.0\n",
      "regex                                   2024.4.16\n",
      "requests                                2.31.0\n",
      "rfc3339-validator                       0.1.4\n",
      "rfc3986-validator                       0.1.1\n",
      "rpds-py                                 0.18.0\n",
      "safetensors                             0.4.3\n",
      "scikit-learn                            1.4.2\n",
      "scipy                                   1.13.0\n",
      "Send2Trash                              1.8.3\n",
      "sentence-transformers                   2.7.0\n",
      "sentencepiece                           0.2.0\n",
      "setuptools                              69.2.0\n",
      "six                                     1.16.0\n",
      "sniffio                                 1.3.1\n",
      "soupsieve                               2.5\n",
      "SQLAlchemy                              2.0.29\n",
      "stack-data                              0.6.3\n",
      "striprtf                                0.0.26\n",
      "sympy                                   1.12\n",
      "tenacity                                8.2.3\n",
      "terminado                               0.18.1\n",
      "threadpoolctl                           3.5.0\n",
      "tiktoken                                0.6.0\n",
      "tinycss2                                1.3.0\n",
      "tokenizers                              0.19.1\n",
      "tomli                                   2.0.1\n",
      "torch                                   2.3.0\n",
      "tornado                                 6.4\n",
      "tqdm                                    4.66.2\n",
      "traitlets                               5.14.3\n",
      "transformers                            4.40.1\n",
      "triton                                  2.3.0\n",
      "types-python-dateutil                   2.9.0.20240316\n",
      "typing_extensions                       4.11.0\n",
      "typing-inspect                          0.9.0\n",
      "tzdata                                  2024.1\n",
      "uri-template                            1.3.0\n",
      "urllib3                                 2.2.1\n",
      "wcwidth                                 0.2.13\n",
      "webcolors                               1.13\n",
      "webencodings                            0.5.1\n",
      "websocket-client                        1.8.0\n",
      "wheel                                   0.43.0\n",
      "widgetsnbextension                      4.0.10\n",
      "wrapt                                   1.16.0\n",
      "yarl                                    1.9.4\n",
      "zipp                                    3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a56fe6-8e42-41f2-874b-3010b2ff33d4",
   "metadata": {},
   "source": [
    "## Meta-Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d02e6d-0ffe-4854-8e3d-e2ad127b0a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Add token as git credential? (Y/n) Token is valid (permission: read).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n",
      "\n",
      "/opt/conda/lib/python3.10/getpass.py:91: GetPassWarning: Can not control echo on the terminal.\n",
      "  passwd = fallback_getpass(prompt, stream)\n",
      "Warning: Password input may be echoed.\n",
      "Enter your token (input will not be visible): \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "token = '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'\n",
    "input_text = f\"{token}\\nY\\n\"  # Combine token and 'Y' input\n",
    "\n",
    "# Run the Huggingface CLI login command\n",
    "process = subprocess.Popen(['huggingface-cli', 'login'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate(input_text.encode())\n",
    "\n",
    "# Print any output or error if necessary (optional)\n",
    "print(stdout.decode())\n",
    "print(stderr.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33083dff-a4f5-4278-8857-c23e8860f11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-02 19:39:35 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='meta-llama/Meta-Llama-3-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/discharge_me/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-02 19:39:35 utils.py:608] Found nccl from library /home/ubuntu/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-02 19:39:36 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 05-02 19:39:36 selector.py:33] Using XFormers backend.\n",
      "INFO 05-02 19:39:37 weight_utils.py:193] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4d96cdd1de45159ff1aaaa5080aede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36e2b410ab6483182e17addfcc477ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45faf84916f2411abb5687efdbd242d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116f78cb191e4676bb348e3ff66703ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-02 19:40:02 model_runner.py:173] Loading model weights took 14.9595 GB\n",
      "INFO 05-02 19:40:04 gpu_executor.py:119] # GPU blocks: 1477, # CPU blocks: 2048\n",
      "INFO 05-02 19:40:06 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-02 19:40:06 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-02 19:40:11 model_runner.py:1057] Graph capturing finished in 6 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664a6955-f33d-4306-b141-c98fc5862ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/discharge_me/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q&A with model: Llama-3 8B Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████| 1/1 [00:12<00:00, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15\n",
      "\n",
      "\n",
      "Generated Summary: [\"\\n\\n\\n\\nSummary:\\n\\nThe patient, a 30-year-old male, was admitted to the intensive care unit (ICU) with a chief complaint of fever. He had a history of stage IV Hodgkin's lymphoma, systemic sarcoidosis, inflammatory bowel disease, obstructive sleep apnea, and idiopathic thrombocytopenic purpura. He presented with neutropenic fever, supraventricular tachycardia, and hypotension.\\n\\nInitial diagnostic workup included a complete blood count, lactate levels, and a computed tomography (CT) scan of the chest, which showed no signs of pneumonia or other infections. The patient was treated with antibiotics and anti-fungal medications.\\n\\nDuring his stay, the patient experienced episodes of supraventricular tachycardia, which were treated with esmolol and neosynephrine. He also required vasopressor support and oxygen therapy. The patient's condition improved, and he was eventually discharged from the ICU.\\n\\nThe patient's medications were adjusted during his stay, including the addition of filgrastim to stimulate white blood cell production. He was also given stress dose steroids to treat his sarcoidosis.\\n\\nThe patient's discharge diagnoses included neutropenic fever, Hodgkin's lymphoma, and sarcoidosis. He was prescribed a regimen of antibiotics, anti-fungal medications, and filgrastim to continue his treatment at home.\\n\\nThe patient's overall condition improved during his stay, and he was discharged in stable condition. The patient's family was educated on his condition and treatment plan, and follow-up appointments were scheduled to monitor his progress.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def generate_summary_with_pipeline(hadm_id, discharge_df, radiology_df, question, discharge_cols, radiology_cols, tokenizer):\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Combine all relevant information into one context string\n",
    "    context = f\"{radiology_info} {discharge_info}\"\n",
    "    \n",
    "    # Prepare the final prompt for the model\n",
    "    # final_prompt = f\"Context: {context} \\n\\nQuestion: Based on the information provided, {question} \\n\\nAnswer:\"\n",
    "    final_prompt = '''\n",
    "            Using the provided patient-specific data from the electronic healthcare record, generate a concise and brief summary of the patient's hospital course.  Focus on the key diagnosis, events, treatments, outcomes, and medication changes during the stay, including:\n",
    "        Admission Details: the reason for admission, and initial diagnosis.\n",
    "        Diagnosis: What were the acute and chronic medical conditions they were treated for?\n",
    "        Diagnostic Overview: what major diagnostic workup was performed.  What were the most pertinent test results related to the treatments?\n",
    "        Treatment Overview: Major treatments administered, including medications, supportive treatments, and any surgeries or procedures performed.\n",
    "        Changes to baseline treatments and medications: Medication dose ajustments, new medications, discontinued medications, and the reason for the change. \n",
    "        Progress and Monitoring: Significant changes in the patient’s condition during the stay, and any notable responses to treatments.\n",
    "        Consultations and Examinations: Key consultations with specialists and results of important examinations.\n",
    "        Ensure the summary is factual, clear, and free from any patient-identifiable information to maintain confidentiality. Use a professional yet accessible tone suitable for a summary that might be read by both medical professionals and the patient. \n",
    "        Context: <The chief complaint was: fever \n",
    "        The HPI was:\n",
    "        Mr ___ is a ___ with h/o stage IV Hodgkins c1d10 of ABVD, \n",
    "        systemic sarcoidosis on high dose steroids, IBD, OSA w/ CPAP, \n",
    "        ITP s/p splenectomy, prior SVT, who presents to FICU w/ \n",
    "        neutropenic fever, SVT, hypotension. Last night, he reports \n",
    "        chills and temp to 102.2F.  Had a minor cough, nonproductive. No \n",
    "        chest pain, shortness of breath, or palpitations at home or in \n",
    "        the ED. Denies sorethroat, rhinorrhea, or nasal congestion. No \n",
    "        sick contacts but lives with grandkids who go to daycare. Recent \n",
    "        diarrhea that he has attributed to chemo. Denies dysuria or \n",
    "        abdominal pain as well as oral pain/dysphagia. No lines yet- \n",
    "        port to be placed on ___\n",
    "        \n",
    "        In the ED, initial vitals were 99.8 119 129/51 22 99%ra. Labs \n",
    "        significant for ANC 8, lactate 3.2, Cr 1.3 from baseline 1.1. \n",
    "        Given 2L NS and lactate normalized. Given vancomycin and \n",
    "        cefepime. Discussed w/ BMT fellow and held off on tamiflu.\n",
    "        \n",
    "        Pt triggered in the ED at 1:27 pm for tachycardia to the 140s. \n",
    "        EKG revealed AVNRT. Dropped pressures to ___ systolic in this \n",
    "        setting. Resolved spontaneously, without intervention. Has h/o \n",
    "        prior ___ note).Is on metoprolol at home since ___. \n",
    "        Then triggered again for SVT w/ pressures to 70's, and esmolol \n",
    "        gtt was started. HR did not respond to esmolol and remained in \n",
    "        the 130s, and pt dropped SBPs to ___. He was started on neo per \n",
    "        cards recs. CVL (RIJ) was placed and during placement pt self \n",
    "        converted to sinus (spontaneously for ___ time). Pt received \n",
    "        total of 4L IVF in ED. Cards said to continue pressors, nothing \n",
    "        for rate control and no ablation given immuncompromised state. \n",
    "        Pt's sats dropped to 93% RA and so repeat CXR done. Stress dose \n",
    "        steroids (hydrocortisone 100mg IV) was also given.  \n",
    "        \n",
    "        On arrival to the MICU, \n",
    "        Vital signs 124/67 on neosynephrin 1.5mcg/kg/min, pulse 74, 95% \n",
    "        O2 sats on room air. Has no complaints. \n",
    "        The admission and discharge medication lists:\n",
    "        The Preadmission Medication list is accurate and complete.\n",
    "        1. Ondansetron 8 mg PO Q8H:PRN nausea \n",
    "        2. PredniSONE 30 mg PO DAILY \n",
    "        3. Prochlorperazine 10 mg PO Q6H:PRN nausea \n",
    "        4. Fluconazole 400 mg PO Q24H \n",
    "        5. Metoprolol Succinate XL 25 mg PO DAILY \n",
    "        6. Ursodiol 250 mg PO TID \n",
    "        7. Simvastatin 20 mg PO DAILY \n",
    "        8. Acyclovir 400 mg PO Q8H \n",
    "        9. Fluticasone Propionate 110mcg 2 PUFF IH BID \n",
    "        10. Omeprazole 40 mg PO BID \n",
    "        11. Fexofenadine 180 mg PO DAILY PRN seasonal allergies \n",
    "        12. Fluoxetine 40 mg PO DAILY \n",
    "        13. Sulfameth/Trimethoprim SS 1 TAB PO DAILY \n",
    "        \n",
    "         \n",
    "        Discharge Medications:\n",
    "        1. Acyclovir 400 mg PO Q8H \n",
    "        2. Fluconazole 400 mg PO Q24H \n",
    "        3. Fluoxetine 40 mg PO DAILY \n",
    "        4. Fluticasone Propionate 110mcg 2 PUFF IH BID \n",
    "        5. Omeprazole 40 mg PO BID \n",
    "        6. Ondansetron 8 mg PO Q8H:PRN nausea \n",
    "        7. PredniSONE 30 mg PO DAILY \n",
    "        8. Sulfameth/Trimethoprim SS 1 TAB PO DAILY \n",
    "        9. Fexofenadine 180 mg PO DAILY PRN seasonal allergies \n",
    "        10. Metoprolol Succinate XL 25 mg PO DAILY \n",
    "        11. Prochlorperazine 10 mg PO Q6H:PRN nausea \n",
    "        12. Vitamin D 50,000 UNIT PO 1X/WEEK (WE) \n",
    "        RX *ergocalciferol (vitamin D2) 50,000 unit 1 capsule(s) by \n",
    "        mouth once every ___ Disp #*7 Capsule Refills:*0\n",
    "        13. Filgrastim 300 mcg SC Q24H \n",
    "        take daily until ___. await clinic visit for further \n",
    "        instruction. \n",
    "        \n",
    "         \n",
    "        Discharge \n",
    "        The patient was diagnosed with:\n",
    "        Primary Diagnosis\n",
    "        Neutropenic Fever, no source identified\n",
    "        \n",
    "        Secondary Diagnosis\n",
    "        Hodgkin's Lymphoma\n",
    "        Sarcoidosis \n",
    "        The patient was initially diagnosed with ICD Diagnosis titles: \n",
    "        NEUTROPENIA, UNSPECIFIED \n",
    "         FEVER, UNSPECIFIED\n",
    "         > \n",
    "    '''\n",
    "    context_length = len(tokenizer.tokenize(final_prompt))\n",
    "    max_input_length = min(256 + context_length, tokenizer.model_max_length)\n",
    "    \n",
    "    # Initialize the pipeline with the Llama-3 model\n",
    "    print(\"\\nQ&A with model: Llama-3 8B Instruct\")\n",
    "    sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=max_input_length)    \n",
    "       \n",
    "    # llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "    # # Generate the response using the model\n",
    "    # generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\n",
    "    outputs = llm.generate(final_prompt, sampling_params)\n",
    "    answer_texts = [output.outputs[0].text for output in outputs]\n",
    "\n",
    "    # Output the generated text\n",
    "    return context, answer_texts\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('data/discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('data/radiology_sections.csv')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "# Specify the columns to use\n",
    "discharge_cols = ['Pertinent Results']\n",
    "radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "context, summary = generate_summary_with_pipeline(hadm_id, discharge_sections_df, radiology_sections_df, question, discharge_cols, radiology_cols, tokenizer)\n",
    "print(\"Context: \", context)\n",
    "print(\"\\n\\nGenerated Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba9fd8-deb6-4414-a5ba-84d3d02f9cef",
   "metadata": {},
   "source": [
    "## 05/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c0e621-527f-47fc-a878-65b77b572560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-03 18:52:18 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='meta-llama/Meta-Llama-3-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/discharge_me/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-03 18:52:19 utils.py:608] Found nccl from library /home/ubuntu/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-03 18:52:19 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 05-03 18:52:19 selector.py:33] Using XFormers backend.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 21.99 GiB of which 188.12 MiB is free. Process 53251 has 20.11 GiB memory in use. Including non-PyTorch memory, this process has 1.68 GiB memory in use. Of the allocated memory 1.06 GiB is allocated by PyTorch, and 18.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM, SamplingParams\n\u001b[0;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/entrypoints/llm.py:118\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, enforce_eager, max_context_len_to_capture, disable_custom_all_reduce, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    100\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    101\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/engine/llm_engine.py:277\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context)\u001b[0m\n\u001b[1;32m    274\u001b[0m     executor_class \u001b[38;5;241m=\u001b[39m GPUExecutor\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/engine/llm_engine.py:148\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, vision_language_config, speculative_config, decoding_config, executor_class, log_stats, usage_context)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_counter \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config_fields \u001b[38;5;241m=\u001b[39m _load_generation_config_dict(\n\u001b[1;32m    146\u001b[0m     model_config)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvision_language_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeculative_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeculative_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# If usage stat is enabled, collect relevant info.\u001b[39;00m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/executor/executor_base.py:41\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, vision_language_config, speculative_config)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_language_config \u001b[38;5;241m=\u001b[39m vision_language_config\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeculative_config \u001b[38;5;241m=\u001b[39m speculative_config\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:22\u001b[0m, in \u001b[0;36mGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the worker and load the model.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mIf speculative decoding is enabled, we instead create the speculative\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mworker.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeculative_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_non_spec_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_spec_worker()\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/executor/gpu_executor.py:51\u001b[0m, in \u001b[0;36mGPUExecutor._init_non_spec_worker\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m Worker(\n\u001b[1;32m     37\u001b[0m     model_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[1;32m     38\u001b[0m     parallel_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     is_driver_worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker\u001b[38;5;241m.\u001b[39minit_device()\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/worker/worker.py:117\u001b[0m, in \u001b[0;36mWorker.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/worker/model_runner.py:162\u001b[0m, in \u001b[0;36mModelRunner.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m CudaMemoryProfiler() \u001b[38;5;28;01mas\u001b[39;00m m:\n\u001b[0;32m--> 162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_language_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mconsumed_memory\n\u001b[1;32m    173\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model weights took \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py:19\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, load_config, device_config, parallel_config, scheduler_config, lora_config, vision_language_config)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;241m*\u001b[39m, model_config: ModelConfig, load_config: LoadConfig,\n\u001b[1;32m     15\u001b[0m         device_config: DeviceConfig, parallel_config: ParallelConfig,\n\u001b[1;32m     16\u001b[0m         scheduler_config: SchedulerConfig, lora_config: Optional[LoRAConfig],\n\u001b[1;32m     17\u001b[0m         vision_language_config: Optional[VisionLanguageConfig]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m     18\u001b[0m     loader \u001b[38;5;241m=\u001b[39m get_model_loader(load_config)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvision_language_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py:222\u001b[0m, in \u001b[0;36mDefaultModelLoader.load_model\u001b[0;34m(self, model_config, device_config, lora_config, vision_language_config, parallel_config, scheduler_config)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_default_torch_dtype(model_config\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(device_config\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[0;32m--> 222\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43m_initialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_weights_iterator(model_config\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    226\u001b[0m                                    model_config\u001b[38;5;241m.\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m                                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfall_back_to_pt_during_load\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m                                        \u001b[38;5;28;01mTrue\u001b[39;00m)), )\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py:90\u001b[0m, in \u001b[0;36m_initialize_model\u001b[0;34m(model_config, load_config, lora_config, vision_language_config)\u001b[0m\n\u001b[1;32m     87\u001b[0m model_class \u001b[38;5;241m=\u001b[39m get_model_architecture(model_config)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     88\u001b[0m linear_method \u001b[38;5;241m=\u001b[39m _get_linear_method(model_config, load_config)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_get_model_initialization_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvision_language_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/models/llama.py:334\u001b[0m, in \u001b[0;36mLlamaForCausalLM.__init__\u001b[0;34m(self, config, linear_method, lora_config)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_method \u001b[38;5;241m=\u001b[39m linear_method\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpadded_vocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lora_config:\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/models/llama.py:262\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, config, linear_method, lora_config)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morg_vocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m VocabParallelEmbedding(\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    259\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    260\u001b[0m     org_num_embeddings\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    261\u001b[0m )\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[1;32m    263\u001b[0m     LlamaDecoderLayer(config, linear_method)\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    265\u001b[0m ])\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/models/llama.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morg_vocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m VocabParallelEmbedding(\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    259\u001b[0m     config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    260\u001b[0m     org_num_embeddings\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\n\u001b[0;32m--> 263\u001b[0m     \u001b[43mLlamaDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    265\u001b[0m ])\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/models/llama.py:202\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[0;34m(self, config, linear_method)\u001b[0m\n\u001b[1;32m    188\u001b[0m attention_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    189\u001b[0m     config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m LlamaAttention(\n\u001b[1;32m    191\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    192\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_attention_heads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m     sliding_window\u001b[38;5;241m=\u001b[39msliding_window,\n\u001b[1;32m    201\u001b[0m )\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaMLP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_act\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_act\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    209\u001b[0m                                eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm \u001b[38;5;241m=\u001b[39m RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[1;32m    211\u001b[0m                                         eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/models/llama.py:62\u001b[0m, in \u001b[0;36mLlamaMLP.__init__\u001b[0;34m(self, hidden_size, intermediate_size, hidden_act, linear_method)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m     hidden_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     linear_method: Optional[LinearMethodBase] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     60\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_up_proj \u001b[38;5;241m=\u001b[39m \u001b[43mMergedColumnParallelLinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mintermediate_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj \u001b[38;5;241m=\u001b[39m RowParallelLinear(intermediate_size,\n\u001b[1;32m     67\u001b[0m                                        hidden_size,\n\u001b[1;32m     68\u001b[0m                                        bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     69\u001b[0m                                        linear_method\u001b[38;5;241m=\u001b[39mlinear_method)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hidden_act \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py:286\u001b[0m, in \u001b[0;36mMergedColumnParallelLinear.__init__\u001b[0;34m(self, input_size, output_sizes, bias, gather_output, skip_bias_add, params_dtype, linear_method)\u001b[0m\n\u001b[1;32m    284\u001b[0m tp_size \u001b[38;5;241m=\u001b[39m get_tensor_model_parallel_world_size()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(output_size \u001b[38;5;241m%\u001b[39m tp_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m output_size \u001b[38;5;129;01min\u001b[39;00m output_sizes)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgather_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mskip_bias_add\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinear_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_sizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py:208\u001b[0m, in \u001b[0;36mColumnParallelLinear.__init__\u001b[0;34m(self, input_size, output_size, bias, gather_output, skip_bias_add, params_dtype, linear_method, output_sizes)\u001b[0m\n\u001b[1;32m    206\u001b[0m     output_sizes \u001b[38;5;241m=\u001b[39m [output_size]\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_method \u001b[38;5;241m=\u001b[39m linear_method\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtp_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_sizes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mweight_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m    217\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size_per_partition,\n\u001b[1;32m    218\u001b[0m                     dtype\u001b[38;5;241m=\u001b[39mparams_dtype))\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/vllm/model_executor/layers/linear.py:87\u001b[0m, in \u001b[0;36mUnquantizedLinearMethod.create_weights\u001b[0;34m(self, layer, input_size_per_partition, output_partition_sizes, input_size, output_size, params_dtype, **extra_weight_attrs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, layer: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m     82\u001b[0m                    input_size_per_partition: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     83\u001b[0m                    output_partition_sizes: List[\u001b[38;5;28mint\u001b[39m], input_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     84\u001b[0m                    output_size: \u001b[38;5;28mint\u001b[39m, params_dtype: torch\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     85\u001b[0m                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_weight_attrs):\n\u001b[1;32m     86\u001b[0m     output_size_per_partition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(output_partition_sizes)\n\u001b[0;32m---> 87\u001b[0m     weight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43minput_size_per_partition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     90\u001b[0m                        requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     91\u001b[0m     set_weight_attrs(weight, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m})\n\u001b[1;32m     92\u001b[0m     layer\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight)\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.10/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 21.99 GiB of which 188.12 MiB is free. Process 53251 has 20.11 GiB memory in use. Including non-PyTorch memory, this process has 1.68 GiB memory in use. Of the allocated memory 1.06 GiB is allocated by PyTorch, and 18.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa554dc-e0cd-4e13-945b-4473f49098e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/discharge_me/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q&A with model: Llama-3 8B Instruct\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 142\u001b[0m\n\u001b[1;32m    140\u001b[0m hadm_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24962904\u001b[39m  \u001b[38;5;66;03m# example HADM ID\u001b[39;00m\n\u001b[1;32m    141\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize the radiological tests and findings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 142\u001b[0m context, summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary_with_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhadm_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdischarge_sections_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiology_sections_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdischarge_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiology_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext: \u001b[39m\u001b[38;5;124m\"\u001b[39m, context)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerated Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m, summary)\n",
      "Cell \u001b[0;32mIn[3], line 122\u001b[0m, in \u001b[0;36mgenerate_summary_with_pipeline\u001b[0;34m(hadm_id, discharge_df, radiology_df, question, discharge_cols, radiology_cols, tokenizer)\u001b[0m\n\u001b[1;32m    116\u001b[0m sampling_params \u001b[38;5;241m=\u001b[39m SamplingParams(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39mmax_input_length)    \n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B-Instruct')\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# # Generate the response using the model\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(final_prompt, sampling_params)\n\u001b[1;32m    123\u001b[0m answer_texts \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Output the generated text\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def generate_summary_with_pipeline(hadm_id, discharge_df, radiology_df, question, discharge_cols, radiology_cols, tokenizer):\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Combine all relevant information into one context string\n",
    "    context = f\"{radiology_info} {discharge_info}\"\n",
    "    \n",
    "    # Prepare the final prompt for the model\n",
    "    # final_prompt = f\"Context: {context} \\n\\nQuestion: Based on the information provided, {question} \\n\\nAnswer:\"\n",
    "    final_prompt = '''\n",
    "            Using the provided patient-specific data from the electronic healthcare record, generate a concise and brief summary of the patient's hospital course.  Focus on the key diagnosis, events, treatments, outcomes, and medication changes during the stay, including:\n",
    "        Admission Details: the reason for admission, and initial diagnosis.\n",
    "        Diagnosis: What were the acute and chronic medical conditions they were treated for?\n",
    "        Diagnostic Overview: what major diagnostic workup was performed.  What were the most pertinent test results related to the treatments?\n",
    "        Treatment Overview: Major treatments administered, including medications, supportive treatments, and any surgeries or procedures performed.\n",
    "        Changes to baseline treatments and medications: Medication dose ajustments, new medications, discontinued medications, and the reason for the change. \n",
    "        Progress and Monitoring: Significant changes in the patient’s condition during the stay, and any notable responses to treatments.\n",
    "        Consultations and Examinations: Key consultations with specialists and results of important examinations.\n",
    "        Ensure the summary is factual, clear, and free from any patient-identifiable information to maintain confidentiality. Use a professional yet accessible tone suitable for a summary that might be read by both medical professionals and the patient. \n",
    "        Context: <The chief complaint was: fever \n",
    "        The HPI was:\n",
    "        Mr ___ is a ___ with h/o stage IV Hodgkins c1d10 of ABVD, \n",
    "        systemic sarcoidosis on high dose steroids, IBD, OSA w/ CPAP, \n",
    "        ITP s/p splenectomy, prior SVT, who presents to FICU w/ \n",
    "        neutropenic fever, SVT, hypotension. Last night, he reports \n",
    "        chills and temp to 102.2F.  Had a minor cough, nonproductive. No \n",
    "        chest pain, shortness of breath, or palpitations at home or in \n",
    "        the ED. Denies sorethroat, rhinorrhea, or nasal congestion. No \n",
    "        sick contacts but lives with grandkids who go to daycare. Recent \n",
    "        diarrhea that he has attributed to chemo. Denies dysuria or \n",
    "        abdominal pain as well as oral pain/dysphagia. No lines yet- \n",
    "        port to be placed on ___\n",
    "        \n",
    "        In the ED, initial vitals were 99.8 119 129/51 22 99%ra. Labs \n",
    "        significant for ANC 8, lactate 3.2, Cr 1.3 from baseline 1.1. \n",
    "        Given 2L NS and lactate normalized. Given vancomycin and \n",
    "        cefepime. Discussed w/ BMT fellow and held off on tamiflu.\n",
    "        \n",
    "        Pt triggered in the ED at 1:27 pm for tachycardia to the 140s. \n",
    "        EKG revealed AVNRT. Dropped pressures to ___ systolic in this \n",
    "        setting. Resolved spontaneously, without intervention. Has h/o \n",
    "        prior ___ note).Is on metoprolol at home since ___. \n",
    "        Then triggered again for SVT w/ pressures to 70's, and esmolol \n",
    "        gtt was started. HR did not respond to esmolol and remained in \n",
    "        the 130s, and pt dropped SBPs to ___. He was started on neo per \n",
    "        cards recs. CVL (RIJ) was placed and during placement pt self \n",
    "        converted to sinus (spontaneously for ___ time). Pt received \n",
    "        total of 4L IVF in ED. Cards said to continue pressors, nothing \n",
    "        for rate control and no ablation given immuncompromised state. \n",
    "        Pt's sats dropped to 93% RA and so repeat CXR done. Stress dose \n",
    "        steroids (hydrocortisone 100mg IV) was also given.  \n",
    "        \n",
    "        On arrival to the MICU, \n",
    "        Vital signs 124/67 on neosynephrin 1.5mcg/kg/min, pulse 74, 95% \n",
    "        O2 sats on room air. Has no complaints. \n",
    "        The admission and discharge medication lists:\n",
    "        The Preadmission Medication list is accurate and complete.\n",
    "        1. Ondansetron 8 mg PO Q8H:PRN nausea \n",
    "        2. PredniSONE 30 mg PO DAILY \n",
    "        3. Prochlorperazine 10 mg PO Q6H:PRN nausea \n",
    "        4. Fluconazole 400 mg PO Q24H \n",
    "        5. Metoprolol Succinate XL 25 mg PO DAILY \n",
    "        6. Ursodiol 250 mg PO TID \n",
    "        7. Simvastatin 20 mg PO DAILY \n",
    "        8. Acyclovir 400 mg PO Q8H \n",
    "        9. Fluticasone Propionate 110mcg 2 PUFF IH BID \n",
    "        10. Omeprazole 40 mg PO BID \n",
    "        11. Fexofenadine 180 mg PO DAILY PRN seasonal allergies \n",
    "        12. Fluoxetine 40 mg PO DAILY \n",
    "        13. Sulfameth/Trimethoprim SS 1 TAB PO DAILY \n",
    "        \n",
    "         \n",
    "        Discharge Medications:\n",
    "        1. Acyclovir 400 mg PO Q8H \n",
    "        2. Fluconazole 400 mg PO Q24H \n",
    "        3. Fluoxetine 40 mg PO DAILY \n",
    "        4. Fluticasone Propionate 110mcg 2 PUFF IH BID \n",
    "        5. Omeprazole 40 mg PO BID \n",
    "        6. Ondansetron 8 mg PO Q8H:PRN nausea \n",
    "        7. PredniSONE 30 mg PO DAILY \n",
    "        8. Sulfameth/Trimethoprim SS 1 TAB PO DAILY \n",
    "        9. Fexofenadine 180 mg PO DAILY PRN seasonal allergies \n",
    "        10. Metoprolol Succinate XL 25 mg PO DAILY \n",
    "        11. Prochlorperazine 10 mg PO Q6H:PRN nausea \n",
    "        12. Vitamin D 50,000 UNIT PO 1X/WEEK (WE) \n",
    "        RX *ergocalciferol (vitamin D2) 50,000 unit 1 capsule(s) by \n",
    "        mouth once every ___ Disp #*7 Capsule Refills:*0\n",
    "        13. Filgrastim 300 mcg SC Q24H \n",
    "        take daily until ___. await clinic visit for further \n",
    "        instruction. \n",
    "        \n",
    "         \n",
    "        Discharge \n",
    "        The patient was diagnosed with:\n",
    "        Primary Diagnosis\n",
    "        Neutropenic Fever, no source identified\n",
    "        \n",
    "        Secondary Diagnosis\n",
    "        Hodgkin's Lymphoma\n",
    "        Sarcoidosis \n",
    "        The patient was initially diagnosed with ICD Diagnosis titles: \n",
    "        NEUTROPENIA, UNSPECIFIED \n",
    "         FEVER, UNSPECIFIED\n",
    "         > \n",
    "    '''\n",
    "    context_length = len(tokenizer.tokenize(final_prompt))\n",
    "    max_input_length = min(256 + context_length, tokenizer.model_max_length)\n",
    "    \n",
    "    # Initialize the pipeline with the Llama-3 model\n",
    "    print(\"\\nQ&A with model: Llama-3 8B Instruct\")\n",
    "    sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=max_input_length)    \n",
    "       \n",
    "    # llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "    # # Generate the response using the model\n",
    "    # generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\n",
    "    outputs = llm.generate(final_prompt, sampling_params)\n",
    "    answer_texts = [output.outputs[0].text for output in outputs]\n",
    "\n",
    "    # Output the generated text\n",
    "    return context, answer_texts\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('data/discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('data/radiology_sections.csv')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "# Specify the columns to use\n",
    "discharge_cols = ['Pertinent Results']\n",
    "radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "context, summary = generate_summary_with_pipeline(hadm_id, discharge_sections_df, radiology_sections_df, question, discharge_cols, radiology_cols, tokenizer)\n",
    "print(\"Context: \", context)\n",
    "print(\"\\n\\nGenerated Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992cbc3d-debf-43bd-8a02-f1e46ed0a044",
   "metadata": {},
   "source": [
    "## 05/05 Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b756d8de-edf1-432d-9b8a-19ed008ae0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "def generate_summary_with_pipeline(final_prompt):\n",
    "    # Load the tokenizer\n",
    "    # torch.cuda.empty_cache()\n",
    "    tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B')\n",
    "    context_length = len(tokenizer.tokenize(final_prompt))\n",
    "    max_input_length = min(256 + context_length, tokenizer.model_max_length)\n",
    "    \n",
    "    # Initialize the pipeline with the Llama-3 model\n",
    "    print(\"\\nQ&A with model: Llama-3 8B\")\n",
    "    sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=max_input_length)    \n",
    "    # sampling_params = SamplingParams(temperature=0.5, top_k=5, top_p=0.95, max_tokens=max_input_length, frequency_penalty = 1.5, best_of=5)       \n",
    "    # llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "    # # Generate the response using the model\n",
    "    # generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\n",
    "    outputs = llm.generate(final_prompt, sampling_params)\n",
    "    answer_texts = [output.outputs[0].text for output in outputs]\n",
    "\n",
    "    # Output the generated text\n",
    "    return answer_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf584bc-dc90-44f0-ae4f-3dc2adb682fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discharge_sections_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m hadm_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22774359\u001b[39m\n\u001b[1;32m      2\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mUsing the provided patient-specific data from the electronic healthcare record, generate a concise and brief summary of the patient\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms hospital course. \u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mFocus on the key diagnosis, events, treatments, outcomes, and medication changes during the stay, including:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mEnsure the summary is text-based, factual, clear, and free from any patient-identifiable information to maintain confidentiality. \u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdischarge_sections_df\u001b[49m\n\u001b[1;32m     16\u001b[0m cur_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhadm_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m hadm_id]\n\u001b[1;32m     17\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discharge_sections_df' is not defined"
     ]
    }
   ],
   "source": [
    "hadm_id = 22774359\n",
    "system_prompt = \"\"\"\n",
    "Using the provided patient-specific data from the electronic healthcare record, generate a concise and brief summary of the patient's hospital course. \n",
    "Focus on the key diagnosis, events, treatments, outcomes, and medication changes during the stay, including:\n",
    "- Admission Details: the reason for admission, and initial diagnosis.\n",
    "- Diagnosis: What were the acute and chronic medical conditions they were treated for?\n",
    "- Diagnostic Overview: what major diagnostic workup was performed. What were the most pertinent test results related to the treatments?\n",
    "- Treatment Overview: Major treatments administered, including medications, supportive treatments, and any surgeries or procedures performed.\n",
    "- Changes to baseline treatments and medications: Medication dose adjustments, new medications, discontinued medications, and the reason for the change.\n",
    "- Progress and Monitoring: Significant changes in the patient’s condition during the stay, and any notable responses to treatments.\n",
    "- Consultations and Examinations: Key consultations with specialists and results of important examinations.\n",
    "Ensure the summary is text-based, factual, clear, and free from any patient-identifiable information to maintain confidentiality. \n",
    "\"\"\"\n",
    "\n",
    "df = discharge_sections_df\n",
    "cur_df = df[df['hadm_id'] == hadm_id]\n",
    "cols = ['CC']\n",
    "context_data = cur_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep='\\n')\n",
    "context_str = f\"The chief complaint was: {context_data} \\n\"\n",
    "cols = ['HPI']\n",
    "context_data = cur_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep='\\n')\n",
    "context_str = context_str + f\"The HPI was:\\n{context_data} \\n\"\n",
    "cols = ['Medication Lists']\n",
    "context_data = cur_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep='\\n')\n",
    "context_str = context_str + f\"The admission and discharge medication lists:\\n{context_data} \\n\"\n",
    "cols = ['Discharge Diagnosis']\n",
    "context_data = cur_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep='\\n')\n",
    "context_str = context_str + f\"The patient was diagnosed with:\\n{context_data} \\n\"\n",
    "# cols = ['Pertinent Results']\n",
    "# context_data = cur_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep='\\n')\n",
    "# context_data = context_data.split('\\n\\n')[0] # grab only the first paragraph of the HPI for relevant pmh\n",
    "# context_str = context_str + f\"The Pertinent Results were:\\n{context_data} \\n\"\n",
    "\n",
    "df = diagnosis_df\n",
    "cols = ['icd_title']\n",
    "cur_df = df[df['hadm_id'] == hadm_id]\n",
    "context_data = cur_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep='\\n ')\n",
    "context_str = context_str + f\"The patient was initially diagnosed with ICD Diagnosis titles: \\n{context_data}\\n \"\n",
    "\n",
    "#final_prompt = f\"Topic: <{topic}> \\nContext: <{context_str}> \\n\\nQuestion: {question} \\n\\nAnswer:\"\n",
    "# final_prompt = f\"System: {prompt}\\nContext: <{}>\\n\\n\"\n",
    "final_prompt = f\"System: {system_prompt}\\nContext (delimited within triple quotes):\\n'''{context_str}'''\\nInstructions: Using the above details, generate a comprehensive summary of the patient's hospital course focusing on diagnosis, treatment and medication changes.\"\n",
    "print(final_prompt)\n",
    "\n",
    "# BHC_generated = generate_with_vllm(final_prompt)\n",
    "# print(BHC_generated)\n",
    "\n",
    "BHC = generate_summary_with_pipeline(final_prompt)\n",
    "print(BHC)\n",
    "\n",
    "# BHC = query_with_llama(final_prompt)\n",
    "# print(\"\\n echo off response:\\n\")\n",
    "# print(BHC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5edae-fdb9-43ee-b004-e6a72e8e8c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
