{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963b3498-ecea-47dc-940a-e553f873ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "# path for input and target data tables\n",
    "\n",
    "diagnosis_path = '../data/diagnosis_hadm.csv'\n",
    "discharge_path ='../data/discharge.csv'\n",
    "edstays_path = '../data/edstays.csv'\n",
    "radiology_path = '../data/radiology.csv'\n",
    "triage_path = '../data/triage.csv'\n",
    "target_path = '../data/discharge_target.csv'\n",
    "discharge_sections_path = '../data/discharge_sections.csv'\n",
    "radiology_sections_path = '../data/radiology_sections.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# read data\n",
    "diagnosis_df = pd.read_csv(diagnosis_path, keep_default_na=False)\n",
    "discharge_df = pd.read_csv(discharge_path, keep_default_na=False)\n",
    "edstays_df = pd.read_csv(edstays_path, keep_default_na=False)\n",
    "radiology_df = pd.read_csv(radiology_path, keep_default_na=False)\n",
    "triage_df = pd.read_csv(triage_path, keep_default_na=False)\n",
    "target_df = pd.read_csv(target_path, keep_default_na=False)\n",
    "\n",
    "discharge_sections_df = pd.read_csv(discharge_sections_path, keep_default_na=False)\n",
    "radiology_sections_df = pd.read_csv(radiology_sections_path, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67de483-daee-48f5-92a3-efa29760537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed data frames into a vector store.  Meta data should include hadm id and column name for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff8e413-e7d0-452b-977f-103d67a02e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4326ae9dfebc4420aa1e796c22a70a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70742c63-f029-41ff-9883-b88ecfd2ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Summarize the radiological tests and findings ...\n",
      "Name: radiology tests summary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def query_with_llama_raj(question, dataframes, column_lists, hadm_id, output_column):\n",
    "    \n",
    "    context_data = \"\"\n",
    "\n",
    "    # Iterate through each DataFrame and its corresponding columns to create the context\n",
    "    for df, cols in zip(dataframes, column_lists):\n",
    "        # Filter the dataframe for the specific hadm_id\n",
    "        target_df = df[df['hadm_id'] == hadm_id]\n",
    "        if not target_df.empty:\n",
    "            # Create a context string from the specified columns\n",
    "            context_part = target_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep=' ')\n",
    "            context_data += \" \" + context_part\n",
    "    \n",
    "    if not context_data:\n",
    "        dataframes[0].loc[dataframes[0]['hadm_id'] == hadm_id, output_column] = \"No records found for the given HADM ID.\"\n",
    "        return dataframes[0]\n",
    "\n",
    "    # Combine the question with the aggregated context data\n",
    "    inputs = tokenizer(question + \" \" + context_data, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs = model.generate(**inputs, max_length=1024)\n",
    "    \n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    \n",
    "    # Append the answer to the first DataFrame\n",
    "    dataframes[0].loc[dataframes[0]['hadm_id'] == hadm_id, output_column] = answer\n",
    "    return dataframes[0]\n",
    "\n",
    "# Example usage\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "hadm_id = 24962904  # Specify the HADM ID you want to query\n",
    "dfs = [discharge_sections_df, radiology_sections_df]  # List of DataFrames\n",
    "relevant_cols = [['Pertinent Results'], ['EXAMINATION','INDICATION','IMPRESSION']]  # List of column lists for each DataFrame\n",
    "output_col_name = 'radiology tests summary'  # Specify the name of the new column\n",
    "\n",
    "# Assuming df1 is the primary DataFrame where the output should be stored\n",
    "df1 = query_with_llama_raj(question, dfs, relevant_cols, hadm_id, output_col_name)\n",
    "print(df1.loc[df1['hadm_id'] == hadm_id, output_col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ed8fe7-473b-4cda-b9bd-ac308c20817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This conversation is about clinical notes from a patient's hospital stay. Use only information given to answer the at the end. Context: The history of present illness is: Ms. ___ is a ___ female with history of \n",
      "COPD on home O2, atrial fibrillation on apixaban, hypertension, \n",
      "CAD, and hyperlipidemia who presents with shortness of breath, \n",
      "cough, and wheezing for one day.\n",
      "\n",
      "The patient reports shortness of breath, increased cough \n",
      "productive of ___ red-flected sputum, and wheezing since \n",
      "yesterday evening.  She has been using albuterol IH more \n",
      "frequently (___) with ipratropium nebs every 4 hours with \n",
      "minimal relief. She had to increase her O2 flow up to 4L without \n",
      "significant improvement. She was currently taking 10mg of \n",
      "prednisone. She has also been taking tiotropium IH, \n",
      "theophylline, advair IH at home as prescribed. She denies sick \n",
      "contacts. She quit smoking approximately 1 month ago.\n",
      "\n",
      "She reports an episode of chest pain in waiting room while \n",
      "sitting down, non-exertional, resolved after 2 minutes. She \n",
      "denies fever/chills, abdominal pain, nausea/vomiting, \n",
      "palpitations, and diaphoresis.  \n",
      "\n",
      "She was recently admitted from ___ to ___ for dyspnea that \n",
      "was thought to be secondary to steroid taper for recent COPD \n",
      "exacerbation with a component of anxiety (not an acute COPD \n",
      "exacerbation) and was treated with steroids and duonebs but no \n",
      "antibiotics. She had a CT that showed emphysema but no evidence \n",
      "of infection such as ___. Pulmonary was consulted and \n",
      "recommended increasing her Advair dose to 500/50 (which was \n",
      "done) and switching from theophylline to \n",
      "roflumilast and initiation of long-term azithromycin therapy \n",
      "(which was deferred for outpatient follow-up) She was initiated \n",
      "on a steroid \n",
      "taper on ___ of prednisone 30 mg for 3 days, then 20 mg for 3 \n",
      "days, then 10 mg until outpatient follow-up.\n",
      "\n",
      "In the ED, initial vital signs were: 97.6 67 132/82 22 97% 4L. \n",
      "Exam was notable for limited air movement with wheezing \n",
      "bilaterally. Labs were notable for WBC 7.1, H/H 12.8/41.1, Plt \n",
      "233, Na 133, K 3.6, BUN/Cr ___, trop < 0.01, BNP 181, lactate \n",
      "1.5, VBG 7.43/___. Imaging with CXR showed mild basilar \n",
      "atelectasis without definite focal consolidation. The patient \n",
      "was given Duonebs and solumedrol 125mg IV. Vitals prior to \n",
      "transfer were:\n",
      "\n",
      "Upon arrival to the floor, she reports her breathing is \n",
      "improved.\n",
      "\n",
      "REVIEW OF SYSTEMS: Per HPI. Denies headache, visual changes, \n",
      "pharyngitis, rhinorrhea, nasal congestion, fevers, chills, \n",
      "sweats, weight loss, abdominal pain, nausea, vomiting, diarrhea, \n",
      "constipation, hematochezia, dysuria, rash, paresthesias, and \n",
      "weakness. \n",
      "The patient recieved the following diagnosis: Chronic obstructive pulmonary disease w (acute) exacerbation \n",
      " \n",
      "\n",
      "Question: Based on the information provided, Make a list of medical problems. Limit the list to 12 items \n",
      "\n",
      "Answer:\n",
      "1. Chronic obstructive pulmonary disease (COPD)\n",
      "2. Acute exacerbation of COPD\n",
      "3. Atrial fibrillation\n",
      "4. Hypertension\n",
      "5. Coronary artery disease (CAD)\n",
      "6. Hyperlipidemia\n",
      "7. Shortness of breath\n",
      "8. Cough\n",
      "9. Wheezing\n",
      "10. Chest pain\n",
      "11. Anxiety\n",
      "12. Steroid taper\n"
     ]
    }
   ],
   "source": [
    "def question_tester(prompt):\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=len(prompt))\n",
    "    max_input_length = min(1024 + len(prompt), tokenizer.model_max_length) \n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs = model.generate(**inputs, max_length=max_input_length)\n",
    "    \n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    answer = answer[len(prompt):] #strip out prompt echo\n",
    "    return answer\n",
    "\n",
    "# prepare prompt\n",
    "\n",
    "hadm_id = 24962904\n",
    "# Specify the columns to use\n",
    "df = discharge_sections_df\n",
    "cols = ['HPI']\n",
    "# Filter DataFrames for the given HADM ID\n",
    "discharge_info = df[df['hadm_id'] == hadm_id][cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "df = diagnosis_df\n",
    "cols = ['icd_title']\n",
    "diagnosis_info = df[df['hadm_id'] == hadm_id][cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "\n",
    "# Combine all relevant information into one context string\n",
    "context = f\"The history of present illness is: {discharge_info} \\n\"\n",
    "context = context + f\"The patient recieved the following ICD diagnosis: {diagnosis_info} \\n\"\n",
    "question = \"Make a list of the patient's medical problems. Limit the list to 12 items\"\n",
    "\n",
    "# Prepare the final prompt for the model\n",
    "final_prompt = f\"This conversation is about clinical notes from a patient's hospital stay. Use only information given to answer the at the end. Context: {context} \\n\\nQuestion: Based on the information provided, {question} \\n\\nAnswer:\"\n",
    "ans = question_tester(final_prompt)\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d291c6bf-1e24-48f5-95dc-7a2e368f2392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. COPD\n",
      "2. Atrial fibrillation\n",
      "3. Hypertension\n",
      "4. CAD\n",
      "5. Hyperlipidemia\n",
      "6. Shortness of breath\n",
      "7. Cough\n",
      "8. Wheezing\n",
      "9. Increased cough productive of red-flected sputum\n",
      "10. Chest pain\n",
      "11. Steroid taper\n",
      "12. Azithromycin therapy\n"
     ]
    }
   ],
   "source": [
    "response = ans[len(final_prompt):]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b98c75-4f19-49bd-ad50-4b78caa26064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
