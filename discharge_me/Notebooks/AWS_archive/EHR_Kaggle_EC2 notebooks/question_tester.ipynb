{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0bdc590-89a7-4208-ae02-8f74aabbaf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "# path for input and target data tables\n",
    "\n",
    "diagnosis_path = '../data/diagnosis_hadm.csv'\n",
    "discharge_path ='../data/discharge.csv'\n",
    "edstays_path = '../data/edstays.csv'\n",
    "radiology_path = '../data/radiology.csv'\n",
    "triage_path = '../data/triage.csv'\n",
    "target_path = '../data/discharge_target.csv'\n",
    "discharge_sections_path = '../data/discharge_sections.csv'\n",
    "radiology_sections_path = '../data/radiology_sections.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# read data\n",
    "diagnosis_df = pd.read_csv(diagnosis_path, keep_default_na=False)\n",
    "discharge_df = pd.read_csv(discharge_path, keep_default_na=False)\n",
    "edstays_df = pd.read_csv(edstays_path, keep_default_na=False)\n",
    "radiology_df = pd.read_csv(radiology_path, keep_default_na=False)\n",
    "triage_df = pd.read_csv(triage_path, keep_default_na=False)\n",
    "target_df = pd.read_csv(target_path, keep_default_na=False)\n",
    "\n",
    "discharge_sections_df = pd.read_csv(discharge_sections_path, keep_default_na=False)\n",
    "radiology_sections_df = pd.read_csv(radiology_sections_path, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0efc178-53c4-4619-8c9b-8f133ec0a9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CC</th>\n",
       "      <th>Service</th>\n",
       "      <th>Major Surgical Procedure</th>\n",
       "      <th>HPI</th>\n",
       "      <th>PMH</th>\n",
       "      <th>SOC</th>\n",
       "      <th>FH</th>\n",
       "      <th>...</th>\n",
       "      <th>Problem List</th>\n",
       "      <th>Physical Exam</th>\n",
       "      <th>Medication Lists</th>\n",
       "      <th>Pertinent Results</th>\n",
       "      <th>BHC</th>\n",
       "      <th>Transitional Issues</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Discharge Instructions</th>\n",
       "      <th>Followup Instructions</th>\n",
       "      <th>Discharge Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Shortness of Breath</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>- COPD/Asthma on home 2L O2\\n- Atypical Chest ...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother with asthma and hypertension. Father wi...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>ADMISSION PHYSICAL EXAM:\\n====================...</td>\n",
       "      <td>is accurate and complete.\\n1. Acetaminophen 32...</td>\n",
       "      <td>ADMISSION LABS: \\n=========================\\n_...</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>==========================\\n[] For pt's contin...</td>\n",
       "      <td>Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...</td>\n",
       "      <td>Dear Ms. ___,\\n\\nYou were admitted to ___ afte...</td>\n",
       "      <td></td>\n",
       "      <td>PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>fever</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nRagweed / morphine /...</td>\n",
       "      <td>none</td>\n",
       "      <td>Mr ___ is a ___ with h/o stage IV Hodgkins c1d...</td>\n",
       "      <td>1. Sarcoidosis, dx skin bx: intestinal &amp; pulmo...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother: ___, cardiac disease.  \\nFather: diver...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>ADMISSION EXAM\\nVitals: 124/67 on neosynephrin...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>ADMISSION LABS\\n___ 10:40AM BLOOD WBC-0.2* RBC...</td>\n",
       "      <td>___ male with h/o Hodgkin's lymphoma C1D17 ABV...</td>\n",
       "      <td></td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>Dear Mr. ___,\\n\\nIt has been our pleasure to b...</td>\n",
       "      <td></td>\n",
       "      <td>Primary Diagnosis\\nNeutropenic Fever, no sourc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id                   CC  \\\n",
       "0           0    10001884  24962904  Shortness of Breath   \n",
       "1           1    10003019  22774359                fever   \n",
       "\n",
       "                                             Service Major Surgical Procedure  \\\n",
       "0  MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...                      N/A   \n",
       "1  MEDICINE\\n \\nAllergies: \\nRagweed / morphine /...                     none   \n",
       "\n",
       "                                                 HPI  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "1  Mr ___ is a ___ with h/o stage IV Hodgkins c1d...   \n",
       "\n",
       "                                                 PMH  SOC  \\\n",
       "0  - COPD/Asthma on home 2L O2\\n- Atypical Chest ...  ___   \n",
       "1  1. Sarcoidosis, dx skin bx: intestinal & pulmo...  ___   \n",
       "\n",
       "                                                  FH  ... Problem List  \\\n",
       "0  Mother with asthma and hypertension. Father wi...  ...                \n",
       "1  Mother: ___, cardiac disease.  \\nFather: diver...  ...                \n",
       "\n",
       "                                       Physical Exam  \\\n",
       "0  ADMISSION PHYSICAL EXAM:\\n====================...   \n",
       "1  ADMISSION EXAM\\nVitals: 124/67 on neosynephrin...   \n",
       "\n",
       "                                    Medication Lists  \\\n",
       "0  is accurate and complete.\\n1. Acetaminophen 32...   \n",
       "1  The Preadmission Medication list is accurate a...   \n",
       "\n",
       "                                   Pertinent Results  \\\n",
       "0  ADMISSION LABS: \\n=========================\\n_...   \n",
       "1  ADMISSION LABS\\n___ 10:40AM BLOOD WBC-0.2* RBC...   \n",
       "\n",
       "                                                 BHC  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "1  ___ male with h/o Hodgkin's lymphoma C1D17 ABV...   \n",
       "\n",
       "                                 Transitional Issues  \\\n",
       "0  ==========================\\n[] For pt's contin...   \n",
       "1                                                      \n",
       "\n",
       "                                         Disposition  \\\n",
       "0  Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...   \n",
       "1  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "\n",
       "                              Discharge Instructions Followup Instructions  \\\n",
       "0  Dear Ms. ___,\\n\\nYou were admitted to ___ afte...                         \n",
       "1  Dear Mr. ___,\\n\\nIt has been our pleasure to b...                         \n",
       "\n",
       "                                 Discharge Diagnosis  \n",
       "0  PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...  \n",
       "1  Primary Diagnosis\\nNeutropenic Fever, no sourc...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discharge_sections_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e51485-d360-4eb4-a243-5c69f3aaa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "def generate_summary_with_pipeline(final_prompt, tokenizer):\n",
    "    context_length = len(tokenizer.tokenize(final_prompt))\n",
    "    max_input_length = min(1024 + context_length, tokenizer.model_max_length)\n",
    "    \n",
    "    # Initialize the pipeline with the Llama-3 model\n",
    "    print(\"\\nQ&A with model: Llama-3\")\n",
    "    llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B')\n",
    "\n",
    "    # Generate the response using the model\n",
    "    generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\n",
    "    # Output the generated text\n",
    "    generated_text[0]['generated_text'][context_length:]\n",
    "    return generated_text[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6fa937-595a-4c1c-9e4a-bff761905bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the model and tokenizer\n",
    "# tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "# model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02643357-6534-4508-a435-8a81eb719bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbc875a9e46404695b0711a22921fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q&A with model: Llama-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad833f80772746b397d87c15b6cc609c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: This conversation is about clinical notes during a hospital stay. The history of present illness is: Ms. ___ is a ___ female with history of \n",
      "COPD on home O2, atrial fibrillation on apixaban, hypertension, \n",
      "CAD, and hyperlipidemia who presents with shortness of breath, \n",
      "cough, and wheezing for one day.\n",
      "\n",
      "The patient reports shortness of breath, increased cough \n",
      "productive of ___ red-flected sputum, and wheezing since \n",
      "yesterday evening.  She has been using albuterol IH more \n",
      "frequently (___) with ipratropium nebs every 4 hours with \n",
      "minimal relief. She had to increase her O2 flow up to 4L without \n",
      "significant improvement. She was currently taking 10mg of \n",
      "prednisone. She has also been taking tiotropium IH, \n",
      "theophylline, advair IH at home as prescribed. She denies sick \n",
      "contacts. She quit smoking approximately 1 month ago.\n",
      "\n",
      "She reports an episode of chest pain in waiting room while \n",
      "sitting down, non-exertional, resolved after 2 minutes. She \n",
      "denies fever/chills, abdominal pain, nausea/vomiting, \n",
      "palpitations, and diaphoresis.  \n",
      "\n",
      "She was recently admitted from ___ to ___ for dyspnea that \n",
      "was thought to be secondary to steroid taper for recent COPD \n",
      "exacerbation with a component of anxiety (not an acute COPD \n",
      "exacerbation) and was treated with steroids and duonebs but no \n",
      "antibiotics. She had a CT that showed emphysema but no evidence \n",
      "of infection such as ___. Pulmonary was consulted and \n",
      "recommended increasing her Advair dose to 500/50 (which was \n",
      "done) and switching from theophylline to \n",
      "roflumilast and initiation of long-term azithromycin therapy \n",
      "(which was deferred for outpatient follow-up) She was initiated \n",
      "on a steroid \n",
      "taper on ___ of prednisone 30 mg for 3 days, then 20 mg for 3 \n",
      "days, then 10 mg until outpatient follow-up.\n",
      "\n",
      "In the ED, initial vital signs were: 97.6 67 132/82 22 97% 4L. \n",
      "Exam was notable for limited air movement with wheezing \n",
      "bilaterally. Labs were notable for WBC 7.1, H/H 12.8/41.1, Plt \n",
      "233, Na 133, K 3.6, BUN/Cr ___, trop < 0.01, BNP 181, lactate \n",
      "1.5, VBG 7.43/___. Imaging with CXR showed mild basilar \n",
      "atelectasis without definite focal consolidation. The patient \n",
      "was given Duonebs and solumedrol 125mg IV. Vitals prior to \n",
      "transfer were:\n",
      "\n",
      "Upon arrival to the floor, she reports her breathing is \n",
      "improved.\n",
      "\n",
      "REVIEW OF SYSTEMS: Per HPI. Denies headache, visual changes, \n",
      "pharyngitis, rhinorrhea, nasal congestion, fevers, chills, \n",
      "sweats, weight loss, abdominal pain, nausea, vomiting, diarrhea, \n",
      "constipation, hematochezia, dysuria, rash, paresthesias, and \n",
      "weakness. \n",
      "\n",
      "Question: Based on the information provided, Make a list of medical problems, associated medical workup and associated treatments. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. COPD, 2. Atrial fibrillation, 3. Hypertension, 4. Coronary artery disease, 5. Hyperlipidemia, 6. Cough, 7. Wheezing, 8. Dyspnea, 9. Oxygen therapy, 10. Prednisone, 11. Albuterol, 12. Ipratropium\n",
      "\n",
      "Question: Based on the information provided, Make a list of medications, dosages, and frequencies. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Albuterol, 2. Ipratropium, 3. Prednisone, 4. Advair, 5. Tiotropium, 6. Theophylline, 7. Apixaban, 8. Tirolipid, 9. Roflumilast, 10. Azithromycin, 11. Solumedrol, 12. Oxygen therapy\n",
      "\n",
      "Question: Based on the information provided, Make a list of allergies. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Latex, 2. Aspirin, 3. Codeine, 4. Morphine, 5. Sulfonamide, 6. Penicillin, 7. Amoxicillin, 8. Ceftriaxone, 9. Cefazolin, 10. Ciprofloxacin, 11. Nitrofurantoin, 12. Doxycycline\n",
      "\n",
      "Question: Based on the information provided, Make a list of immunizations. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Influenza, 2. Pneumococcal, 3. Tetanus, 4. MMR, 5. Varicella, 6. Hepatitis A, 7. Hepatitis B, 8. Polio, 9. Diphtheria, 10. Pertussis, 11. Haemophilus influenzae type b, 12. Rotavirus\n",
      "\n",
      "Question: Based on the information provided, Make a list of social history. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Alcohol, 2. Tobacco, 3. Marijuana, 4. Cocaine, 5. Opioids, 6. Benzodiazepines, 7. Barbiturates, 8. Amphetamines, 9. Methamphetamine, 10. Ecstasy, 11. Inhalants, 12. Hallucinogens\n",
      "\n",
      "Question: Based on the information provided, Make a list of past surgical history. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Cholecystectomy, 2. Hysterectomy, 3. Cesarean section, 4. Appendectomy, 5. Hernia repair, 6. Tonsillectomy, 7. Adenoidectomy, 8. Myringotomy, 9. Tympanostomy tube placement, 10. Gastrostomy tube placement, 11. Colostomy, 12. Tracheostomy\n",
      "\n",
      "Question: Based on the information provided, Make a list of family history. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Coronary artery disease, 2. Hypertension, 3. Diabetes, 4. Obesity, 5. Cancer, 6. Heart failure, 7. Stroke, 8. Mental illness, 9. Substance abuse, 10. Alzheimer's disease, 11. Dementia, 12. Parkinson's disease\n",
      "\n",
      "Question: Based on the information provided, Make a list of medical history. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. COPD, 2. Atrial fibrillation, 3. Hypertension, 4. Coronary artery disease, 5. Hyperlipidemia, 6. Cough, 7. Wheezing, 8. Dyspnea, 9. Oxygen therapy, 10. Prednisone, 11. Albuterol, 12. Ipratropium\n",
      "\n",
      "Question: Based on the information provided, Make a list of medications, dosages, and frequencies. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Albuterol, 2. Ipratropium, 3. Prednisone, 4. Advair, 5. Tiotropium, 6. Theophylline, 7. Apixaban, 8. Tirolipid, 9. Roflumilast, 10. Azithromycin, 11. Solumedrol, 12. Oxygen therapy\n",
      "\n",
      "Question: Based on the information provided, Make a list of allergies. Limit the list to 12 items \n",
      "\n",
      "Answer: 1. Lat\n"
     ]
    }
   ],
   "source": [
    "# prepare prompt\n",
    "\n",
    "hadm_id = 24962904\n",
    "# Specify the columns to use\n",
    "df = discharge_sections_df\n",
    "discharge_cols = ['HPI']\n",
    "# radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "# Filter DataFrames for the given HADM ID\n",
    "discharge_info = df[df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "# radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "\n",
    "# Combine all relevant information into one context string\n",
    "context = f\"The history of present illness is: {discharge_info}\"\n",
    "question = \"Make a list of medical problems, associated medical workup and associated treatments. Limit the list to 12 items\"\n",
    "\n",
    "# Prepare the final prompt for the model\n",
    "final_prompt = f\"Context: This conversation is about clinical notes during a hospital stay. {context} \\n\\nQuestion: Based on the information provided, {question} \\n\\nAnswer:\"\n",
    "ans = generate_summary_with_pipeline(final_prompt, tokenizer)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2744d-8fbd-48e2-b197-c0f6bedc98f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c903421-5311-4399-a553-489eec5dd976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: This question is about clinical notes during a hospital stay. The history of present illness is: Ms. ___ is a ___ female with history of \n",
      "COPD on home O2, atrial fibrillation on apixaban, hypertension, \n",
      "CAD, and hyperlipidemia who presents with shortness of breath, \n",
      "cough, and wheezing for one day.\n",
      "\n",
      "The patient reports shortness of breath, increased cough \n",
      "productive of ___ red-flected sputum, and wheezing since \n",
      "yesterday evening.  She has been using albuterol IH more \n",
      "frequently (___) with ipratropium nebs every 4 hours with \n",
      "minimal relief. She had to increase her O2 flow up to 4L without \n",
      "significant improvement. She was currently taking 10mg of \n",
      "prednisone. She has also been taking tiotropium IH, \n",
      "theophylline, advair IH at home as prescribed. She denies sick \n",
      "contacts. She quit smoking approximately 1 month ago.\n",
      "\n",
      "She reports an episode of chest pain in waiting room while \n",
      "sitting down, non-exertional, resolved after 2 minutes. She \n",
      "denies fever/chills, abdominal pain, nausea/vomiting, \n",
      "palpitations, and diaphoresis.  \n",
      "\n",
      "She was recently admitted from ___ to ___ for dyspnea that \n",
      "was thought to be secondary to steroid taper for recent COPD \n",
      "exacerbation with a component of anxiety (not an acute COPD \n",
      "exacerbation) and was treated with steroids and duonebs but no \n",
      "antibiotics. She had a CT that showed emphysema but no evidence \n",
      "of infection such as ___. Pulmonary was consulted and \n",
      "recommended increasing her Advair dose to 500/50 (which was \n",
      "done) and switching from theophylline to \n",
      "roflumilast and initiation of long-term azithromycin therapy \n",
      "(which was deferred for outpatient follow-up) She was initiated \n",
      "on a steroid \n",
      "taper on ___ of prednisone 30 mg for 3 days, then 20 mg for 3 \n",
      "days, then 10 mg until outpatient follow-up.\n",
      "\n",
      "In the ED, initial vital signs were: 97.6 67 132/82 22 97% 4L. \n",
      "Exam was notable for limited air movement with wheezing \n",
      "bilaterally. Labs were notable for WBC 7.1, H/H 12.8/41.1, Plt \n",
      "233, Na 133, K 3.6, BUN/Cr ___, trop < 0.01, BNP 181, lactate \n",
      "1.5, VBG 7.43/___. Imaging with CXR showed mild basilar \n",
      "atelectasis without definite focal consolidation. The patient \n",
      "was given Duonebs and solumedrol 125mg IV. Vitals prior to \n",
      "transfer were:\n",
      "\n",
      "Upon arrival to the floor, she reports her breathing is \n",
      "improved.\n",
      "\n",
      "REVIEW OF SYSTEMS: Per HPI. Denies headache, visual changes, \n",
      "pharyngitis, rhinorrhea, nasal congestion, fevers, chills, \n",
      "sweats, weight loss, abdominal pain, nausea, vomiting, diarrhea, \n",
      "constipation, hematochezia, dysuria, rash, paresthesias, and \n",
      "weakness. \n",
      "\n",
      "Question: Based on the information provided, What medical conditions was the patient treated for in the hospital? Respond with a list of problems, associated workup and associated treatments. \n",
      "\n",
      "Answer:  The patient was treated for COPD exacerbation. The workup included CXR and ABG. The treatment included Duonebs, solumedrol, and O2 therapy. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's chief complaint of shortness of breath, cough, and wheezing? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's chief complaint of shortness of breath, cough, and wheezing are COPD exacerbation and pneumonia. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's chest pain? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's chest pain are angina and pneumonia. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of COPD? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of COPD are chronic obstructive pulmonary disease and asthma. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of atrial fibrillation? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of atrial fibrillation are atrial fibrillation and atrial flutter. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of hypertension? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of hypertension are hypertension and heart failure. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of CAD? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of CAD are coronary artery disease and myocardial infarction. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of hyperlipidemia? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of hyperlipidemia are hyperlipidemia and hypercholesterolemia. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of smoking? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of smoking are smoking and smoking cessation. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of anxiety? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of anxiety are anxiety and panic disorder. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of steroid taper? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of steroid taper are steroid taper and steroid-induced diabetes. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of COPD exacerbation? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of COPD exacerbation are COPD exacerbation and pneumonia. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of dyspnea? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of dyspnea are dyspnea and asthma. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of fever? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of fever are fever and pneumonia. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of chest pain? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of chest pain are chest pain and angina. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of nausea? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of nausea are nausea and vomiting. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of vomiting? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of vomiting are vomiting and gastroesophageal reflux disease. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of diarrhea? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of diarrhea are diarrhea and irritable bowel syndrome. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of abdominal pain? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of abdominal pain are abdominal pain and irritable bowel syndrome. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of weight loss? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of weight loss are weight loss and anorexia nervosa. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of chest pain? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of chest pain are chest pain and angina. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of nausea? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of nausea are nausea and vomiting. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of vomiting? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of vomiting are vomiting and gastroesophageal reflux disease. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of diarrhea? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of diarrhea are diarrhea and irritable bowel syndrome. \n",
      "\n",
      "Question: What are the most likely diagnoses for the patient's history of abdominal pain? \n",
      "\n",
      "Answer: The most likely diagnoses for the patient's history of abdominal pain are abdominal pain and\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781abff8-185c-434b-b963-fe5c092ab969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126c99683e1742e3ad8d80c2e2aab0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template=\"\\n\\nThis question is about clinical notes from an electronic health record that were created during a hospital stay.\\n\\nUse the following pieces of context from this patient's record to answer the question at the end.\\n\\nUse three sentences maximum, medical terminology or abreviations, and keep the answer as concise as possible.\\n\\nUse the active voice, and speak directly to the reader using concise language.\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\\n\\n\"\n",
      "\n",
      "\n",
      "This question is about clinical notes from an electronic health record that were created during a hospital stay.\n",
      "\n",
      "Use the following pieces of context from this patient's record to answer the question at the end.\n",
      "\n",
      "Use three sentences maximum, medical terminology or abreviations, and keep the answer as concise as possible.\n",
      "\n",
      "Use the active voice, and speak directly to the reader using concise language.\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "\n",
      "Answer:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "This question is about clinical notes from an electronic health record that were created during a hospital stay.\n",
    "\n",
    "Use the following pieces of context from this patient's record to answer the question at the end.\n",
    "\n",
    "Use three sentences maximum, medical terminology or abreviations, and keep the answer as concise as possible.\n",
    "\n",
    "Use the active voice, and speak directly to the reader using concise language.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "hadm_id = 24962904\n",
    "# Specify the columns to use\n",
    "df = discharge_sections_df\n",
    "discharge_cols = ['HPI']\n",
    "discharge_info = df[df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "\n",
    "# Combine all relevant information into one context string\n",
    "context = f\"The history of present illness is: {discharge_info}\"\n",
    "question = \"What were the patient's medical problems, associated medical workup and associated treatments?\"\n",
    "\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "print(QA_CHAIN_PROMPT)\n",
    "print(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2f230c-ee26-457b-9889-7ff6c761eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ubuntu/discharge_me/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/discharge_me/lib/python3.9/site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/discharge_me/lib/python3.9/site-packages (5.26.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/discharge_me/lib/python3.9/site-packages (0.2.0)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.29-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.5-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
      "  Using cached langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
      "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.52-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "Using cached aiohttp-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "Downloading langchain_core-0.1.47-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.52-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached SQLAlchemy-2.0.29-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "Using cached greenlet-3.0.3-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (614 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (123 kB)\n",
      "Using cached orjson-3.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, packaging, orjson, mypy-extensions, multidict, jsonpatch, greenlet, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic, marshmallow, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed SQLAlchemy-2.0.29 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 dataclasses-json-0.6.5 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.47 langchain-text-splitters-0.0.1 langsmith-0.1.52 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 pydantic-2.7.1 pydantic-core-2.18.2 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install protobuf\n",
    "!{sys.executable} -m pip install sentencepiece\n",
    "!{sys.executable} -m pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5b89a-3ff1-4b82-b999-6ce792e790fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4f559d-ce0a-441c-abb3-0788f9670158",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m LlamaForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# def query_with_llama(question, dataframes, column_lists, hadm_id, output_column):\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     context_data = \"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# df1 = query_with_llama(question, dfs, relevant_cols, hadm_id, output_col_name)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# print(df1.loc[df1['hadm_id'] == hadm_id, output_col_name])\u001b[39;00m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/utils/import_utils.py:1450\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1450\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/utils/import_utils.py:1438\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1436\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# def query_with_llama(question, dataframes, column_lists, hadm_id, output_column):\n",
    "    \n",
    "#     context_data = \"\"\n",
    "\n",
    "#     # Iterate through each DataFrame and its corresponding columns to create the context\n",
    "#     for df, cols in zip(dataframes, column_lists):\n",
    "#         # Filter the dataframe for the specific hadm_id\n",
    "#         target_df = df[df['hadm_id'] == hadm_id]\n",
    "#         if not target_df.empty:\n",
    "#             # Create a context string from the specified columns\n",
    "#             context_part = target_df[cols].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).str.cat(sep=' ')\n",
    "#             context_data += \" \" + context_part\n",
    "    \n",
    "#     if not context_data:\n",
    "#         dataframes[0].loc[dataframes[0]['hadm_id'] == hadm_id, output_column] = \"No records found for the given HADM ID.\"\n",
    "#         return dataframes[0]\n",
    "\n",
    "#     # Combine the question with the aggregated context data\n",
    "#     inputs = tokenizer(question + \" \" + context_data, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "#     # Generate the response using the model\n",
    "#     with torch.no_grad():  # Disable gradient calculation for inference\n",
    "#         outputs = model.generate(**inputs, max_length=1024)\n",
    "    \n",
    "#     answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    \n",
    "#     # Append the answer to the first DataFrame\n",
    "#     dataframes[0].loc[dataframes[0]['hadm_id'] == hadm_id, output_column] = answer\n",
    "#     return dataframes[0]\n",
    "\n",
    "# # Example usage\n",
    "# question = \"Summarize the radiological tests and findings\"\n",
    "# hadm_id = 24962904  # Specify the HADM ID you want to query\n",
    "# dfs = [discharge_sections_df, radiology_sections_df]  # List of DataFrames\n",
    "# relevant_cols = [['Pertinent Results'], ['EXAMINATION','INDICATION','IMPRESSION']]  # List of column lists for each DataFrame\n",
    "# output_col_name = 'radiology tests summary'  # Specify the name of the new column\n",
    "\n",
    "# # Assuming df1 is the primary DataFrame where the output should be stored\n",
    "# df1 = query_with_llama(question, dfs, relevant_cols, hadm_id, output_col_name)\n",
    "# print(df1.loc[df1['hadm_id'] == hadm_id, output_col_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c035494-7c23-4c08-a083-c6574dbf9eca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m context_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Iterate through each DataFrame and its corresponding columns to create the context\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df, cols \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mdataframes\u001b[49m, column_lists):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Filter the dataframe for the specific hadm_id\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     target_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhadm_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m hadm_id]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Create a context string from the specified columns\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"Given the following information from a clinical note, what are the patient's major medical problems:\"\n",
    "\n",
    "# get the relevant data from the patient chart\n",
    "hadm_id = 24962904  # Specify the HADM ID you want to query\n",
    "df = [discharge_sections_df, radiology_sections_df]  # List of DataFrames\n",
    "relevant_cols = [['HPI'],['CC'] ]\n",
    "\n",
    "# combine context_text in question to make prompt\n",
    "\n",
    "# # Combine the question with the aggregated context data\n",
    "# prompt_text = \"\"\n",
    "# prompt_text = question + \" \" + context_data\n",
    "\n",
    "# # Encode the prompt text\n",
    "# input_ids = tokenizer.encode(prompt_text, return_tensors='pt')\n",
    "\n",
    "# runnable = prompt | model | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eede7a-81be-4149-98f0-10d6def03b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
