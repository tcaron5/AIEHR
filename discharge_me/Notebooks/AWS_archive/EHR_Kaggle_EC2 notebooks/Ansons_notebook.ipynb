{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aae1247-8177-4fa5-ab37-16cf2c7ef6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429c9d7a-ff55-486e-9f68-6a2aee7049f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CC</th>\n",
       "      <th>Service</th>\n",
       "      <th>Major Surgical Procedure</th>\n",
       "      <th>HPI</th>\n",
       "      <th>PMH</th>\n",
       "      <th>SOC</th>\n",
       "      <th>FH</th>\n",
       "      <th>...</th>\n",
       "      <th>Problem List</th>\n",
       "      <th>Physical Exam</th>\n",
       "      <th>Medication Lists</th>\n",
       "      <th>Pertinent Results</th>\n",
       "      <th>BHC</th>\n",
       "      <th>Transitional Issues</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Discharge Instructions</th>\n",
       "      <th>Followup Instructions</th>\n",
       "      <th>Discharge Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Shortness of Breath</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>- COPD/Asthma on home 2L O2\\n- Atypical Chest ...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother with asthma and hypertension. Father wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION PHYSICAL EXAM:\\n====================...</td>\n",
       "      <td>is accurate and complete.\\n1. Acetaminophen 32...</td>\n",
       "      <td>ADMISSION LABS: \\n=========================\\n_...</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>==========================\\n[] For pt's contin...</td>\n",
       "      <td>Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...</td>\n",
       "      <td>Dear Ms. ___,\\n\\nYou were admitted to ___ afte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>fever</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nRagweed / morphine /...</td>\n",
       "      <td>none</td>\n",
       "      <td>Mr ___ is a ___ with h/o stage IV Hodgkins c1d...</td>\n",
       "      <td>1. Sarcoidosis, dx skin bx: intestinal &amp; pulmo...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother: ___, cardiac disease.  \\nFather: diver...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION EXAM\\nVitals: 124/67 on neosynephrin...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>ADMISSION LABS\\n___ 10:40AM BLOOD WBC-0.2* RBC...</td>\n",
       "      <td>___ male with h/o Hodgkin's lymphoma C1D17 ABV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>Dear Mr. ___,\\n\\nIt has been our pleasure to b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary Diagnosis\\nNeutropenic Fever, no sourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10003299</td>\n",
       "      <td>29323205</td>\n",
       "      <td>left leg weakness, falls</td>\n",
       "      <td>NEUROLOGY\\n \\nAllergies: \\nIodine-Iodine Conta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>___ is a ___ RH female with a PMHx of\\nparamed...</td>\n",
       "      <td>- prior paramedian pontine infarct (___) \\n- r...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother had stroke in her ___ or ___.  Her pate...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Exam:\\nVitals: T: 97.4 P: 65 R: 16  ...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>___ 01:10PM   GLUCOSE-125* UREA N-9 CREAT-0.9 ...</td>\n",
       "      <td>___ RH female with a PMHx of paramedian pontin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>Dear ___ were hospitalized due to symptoms of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ischemic stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10003502</td>\n",
       "      <td>20459702</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nnifedipine / Amitrip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ms. ___ is an ___ with atrial fibrillation/flu...</td>\n",
       "      <td>Hypertension/hyperlipidemia\\nCoronary artery d...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother deceased at ___ yo from breast cancer. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On admission: \\nVS 97.4 140/P 62 18 96\\nGEN Al...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>___ 10:15AM BLOOD WBC-6.4 RBC-3.64* Hgb-11.1* ...</td>\n",
       "      <td>Hospitalization Summary: \\nMs. ___ is an ___ y...</td>\n",
       "      <td>- monitoring of volume status and titration of...</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>It was a pleasure caring for you at ___ \\n___....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary: \\nAcute diastolic CHF exacerbation\\nN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10004322</td>\n",
       "      <td>28755331</td>\n",
       "      <td>multiple falls at group home</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nNo Known Allergies /...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr. ___ is a ___ year old male with a h/o psyc...</td>\n",
       "      <td>Psychosis \\nDiabetes \\nCOPD</td>\n",
       "      <td>___</td>\n",
       "      <td>Unknown to patient.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION PHYSICAL EXAM: \\nVS: 98.1 117/62 97 ...</td>\n",
       "      <td>The Preadmission Medication list is accurate a...</td>\n",
       "      <td>ADMISSION LABS:\\n___ 03:40PM BLOOD WBC-17.7* R...</td>\n",
       "      <td>___ with h/o psychosis admitted because of mul...</td>\n",
       "      <td>-He was discharged back home to the ___ Home\\n...</td>\n",
       "      <td>Home With Service\\n \\nFacility:\\n___\\n \\nDisch...</td>\n",
       "      <td>Dear Mr. ___,\\n\\nIt was our pleasure to care f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Primary: mechanical fall\\nSecondary: \\npsychos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id                            CC  \\\n",
       "0           0    10001884  24962904           Shortness of Breath   \n",
       "1           1    10003019  22774359                         fever   \n",
       "2           2    10003299  29323205      left leg weakness, falls   \n",
       "3           3    10003502  20459702                        Nausea   \n",
       "4           4    10004322  28755331  multiple falls at group home   \n",
       "\n",
       "                                             Service Major Surgical Procedure  \\\n",
       "0  MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...                      NaN   \n",
       "1  MEDICINE\\n \\nAllergies: \\nRagweed / morphine /...                     none   \n",
       "2  NEUROLOGY\\n \\nAllergies: \\nIodine-Iodine Conta...                      NaN   \n",
       "3  MEDICINE\\n \\nAllergies: \\nnifedipine / Amitrip...                      NaN   \n",
       "4  MEDICINE\\n \\nAllergies: \\nNo Known Allergies /...                      NaN   \n",
       "\n",
       "                                                 HPI  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "1  Mr ___ is a ___ with h/o stage IV Hodgkins c1d...   \n",
       "2  ___ is a ___ RH female with a PMHx of\\nparamed...   \n",
       "3  Ms. ___ is an ___ with atrial fibrillation/flu...   \n",
       "4  Mr. ___ is a ___ year old male with a h/o psyc...   \n",
       "\n",
       "                                                 PMH  SOC  \\\n",
       "0  - COPD/Asthma on home 2L O2\\n- Atypical Chest ...  ___   \n",
       "1  1. Sarcoidosis, dx skin bx: intestinal & pulmo...  ___   \n",
       "2  - prior paramedian pontine infarct (___) \\n- r...  ___   \n",
       "3  Hypertension/hyperlipidemia\\nCoronary artery d...  ___   \n",
       "4                        Psychosis \\nDiabetes \\nCOPD  ___   \n",
       "\n",
       "                                                  FH  ... Problem List  \\\n",
       "0  Mother with asthma and hypertension. Father wi...  ...          NaN   \n",
       "1  Mother: ___, cardiac disease.  \\nFather: diver...  ...          NaN   \n",
       "2  Mother had stroke in her ___ or ___.  Her pate...  ...          NaN   \n",
       "3  Mother deceased at ___ yo from breast cancer. ...  ...          NaN   \n",
       "4                                Unknown to patient.  ...          NaN   \n",
       "\n",
       "                                       Physical Exam  \\\n",
       "0  ADMISSION PHYSICAL EXAM:\\n====================...   \n",
       "1  ADMISSION EXAM\\nVitals: 124/67 on neosynephrin...   \n",
       "2  Admission Exam:\\nVitals: T: 97.4 P: 65 R: 16  ...   \n",
       "3  On admission: \\nVS 97.4 140/P 62 18 96\\nGEN Al...   \n",
       "4  ADMISSION PHYSICAL EXAM: \\nVS: 98.1 117/62 97 ...   \n",
       "\n",
       "                                    Medication Lists  \\\n",
       "0  is accurate and complete.\\n1. Acetaminophen 32...   \n",
       "1  The Preadmission Medication list is accurate a...   \n",
       "2  The Preadmission Medication list is accurate a...   \n",
       "3  The Preadmission Medication list is accurate a...   \n",
       "4  The Preadmission Medication list is accurate a...   \n",
       "\n",
       "                                   Pertinent Results  \\\n",
       "0  ADMISSION LABS: \\n=========================\\n_...   \n",
       "1  ADMISSION LABS\\n___ 10:40AM BLOOD WBC-0.2* RBC...   \n",
       "2  ___ 01:10PM   GLUCOSE-125* UREA N-9 CREAT-0.9 ...   \n",
       "3  ___ 10:15AM BLOOD WBC-6.4 RBC-3.64* Hgb-11.1* ...   \n",
       "4  ADMISSION LABS:\\n___ 03:40PM BLOOD WBC-17.7* R...   \n",
       "\n",
       "                                                 BHC  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "1  ___ male with h/o Hodgkin's lymphoma C1D17 ABV...   \n",
       "2  ___ RH female with a PMHx of paramedian pontin...   \n",
       "3  Hospitalization Summary: \\nMs. ___ is an ___ y...   \n",
       "4  ___ with h/o psychosis admitted because of mul...   \n",
       "\n",
       "                                 Transitional Issues  \\\n",
       "0  ==========================\\n[] For pt's contin...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  - monitoring of volume status and titration of...   \n",
       "4  -He was discharged back home to the ___ Home\\n...   \n",
       "\n",
       "                                         Disposition  \\\n",
       "0  Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...   \n",
       "1  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "2  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "3  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "4  Home With Service\\n \\nFacility:\\n___\\n \\nDisch...   \n",
       "\n",
       "                              Discharge Instructions Followup Instructions  \\\n",
       "0  Dear Ms. ___,\\n\\nYou were admitted to ___ afte...                   NaN   \n",
       "1  Dear Mr. ___,\\n\\nIt has been our pleasure to b...                   NaN   \n",
       "2  Dear ___ were hospitalized due to symptoms of ...                   NaN   \n",
       "3  It was a pleasure caring for you at ___ \\n___....                   NaN   \n",
       "4  Dear Mr. ___,\\n\\nIt was our pleasure to care f...                   NaN   \n",
       "\n",
       "                                 Discharge Diagnosis  \n",
       "0  PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...  \n",
       "1  Primary Diagnosis\\nNeutropenic Fever, no sourc...  \n",
       "2                                    Ischemic stroke  \n",
       "3  Primary: \\nAcute diastolic CHF exacerbation\\nN...  \n",
       "4  Primary: mechanical fall\\nSecondary: \\npsychos...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discharge_sections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89368b2a-adfa-4c9c-8a4a-b141f0add9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>EXAMINATION</th>\n",
       "      <th>INDICATION</th>\n",
       "      <th>TECHNIQUE</th>\n",
       "      <th>COMPARISON</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Chest:  Frontal and lateral views</td>\n",
       "      <td>History: ___ with dyspnea  // eval for pneumonia</td>\n",
       "      <td>Chest:  Frontal and Lateral</td>\n",
       "      <td>:  ___</td>\n",
       "      <td>Mild basilar atelectasis is seen without focal...</td>\n",
       "      <td>Mild basilar atelectasis without definite foca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>Chest, frontal and lateral views.</td>\n",
       "      <td>Fever, on chemotherapy.\\n\\n___.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frontal and lateral views of the chest were ob...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>Chest, single AP upright portable view.</td>\n",
       "      <td>Neutropenic fever, septic shock, worsening hyp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There has been interval placement of a right i...</td>\n",
       "      <td>Interval placement of right internal jugular c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AP chest compared to ___:\\n\\nMultifocal pulmon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10003019</td>\n",
       "      <td>22774359</td>\n",
       "      <td>Evaluation of the patient with Hodgkin's lymph...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDCT of the chest was obtained from thoracic i...</td>\n",
       "      <td>:  ___ PET CT and chest radiograph from ___.</td>\n",
       "      <td>Aorta and pulmonary arteries are normal in dia...</td>\n",
       "      <td>1.  No evidence of new pulmonary abnormalities...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id  \\\n",
       "0           0    10001884  24962904   \n",
       "1           1    10003019  22774359   \n",
       "2           2    10003019  22774359   \n",
       "3           3    10003019  22774359   \n",
       "4           4    10003019  22774359   \n",
       "\n",
       "                                         EXAMINATION  \\\n",
       "0                  Chest:  Frontal and lateral views   \n",
       "1                  Chest, frontal and lateral views.   \n",
       "2            Chest, single AP upright portable view.   \n",
       "3                                                NaN   \n",
       "4  Evaluation of the patient with Hodgkin's lymph...   \n",
       "\n",
       "                                          INDICATION  \\\n",
       "0   History: ___ with dyspnea  // eval for pneumonia   \n",
       "1                    Fever, on chemotherapy.\\n\\n___.   \n",
       "2  Neutropenic fever, septic shock, worsening hyp...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                           TECHNIQUE  \\\n",
       "0                        Chest:  Frontal and Lateral   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  MDCT of the chest was obtained from thoracic i...   \n",
       "\n",
       "                                     COMPARISON  \\\n",
       "0                                        :  ___   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4  :  ___ PET CT and chest radiograph from ___.   \n",
       "\n",
       "                                            FINDINGS  \\\n",
       "0  Mild basilar atelectasis is seen without focal...   \n",
       "1  Frontal and lateral views of the chest were ob...   \n",
       "2  There has been interval placement of a right i...   \n",
       "3                                                NaN   \n",
       "4  Aorta and pulmonary arteries are normal in dia...   \n",
       "\n",
       "                                          IMPRESSION  \n",
       "0  Mild basilar atelectasis without definite foca...  \n",
       "1                                                NaN  \n",
       "2  Interval placement of right internal jugular c...  \n",
       "3  AP chest compared to ___:\\n\\nMultifocal pulmon...  \n",
       "4  1.  No evidence of new pulmonary abnormalities...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiology_sections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f5823c-fc20-4ce4-a215-6c55f3893112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CC</th>\n",
       "      <th>Service</th>\n",
       "      <th>Major Surgical Procedure</th>\n",
       "      <th>HPI</th>\n",
       "      <th>PMH</th>\n",
       "      <th>SOC</th>\n",
       "      <th>FH</th>\n",
       "      <th>...</th>\n",
       "      <th>Problem List</th>\n",
       "      <th>Physical Exam</th>\n",
       "      <th>Medication Lists</th>\n",
       "      <th>Pertinent Results</th>\n",
       "      <th>BHC</th>\n",
       "      <th>Transitional Issues</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Discharge Instructions</th>\n",
       "      <th>Followup Instructions</th>\n",
       "      <th>Discharge Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Shortness of Breath</td>\n",
       "      <td>MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>- COPD/Asthma on home 2L O2\\n- Atypical Chest ...</td>\n",
       "      <td>___</td>\n",
       "      <td>Mother with asthma and hypertension. Father wi...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMISSION PHYSICAL EXAM:\\n====================...</td>\n",
       "      <td>is accurate and complete.\\n1. Acetaminophen 32...</td>\n",
       "      <td>ADMISSION LABS: \\n=========================\\n_...</td>\n",
       "      <td>Ms. ___ is a ___ female with history of \\nCOPD...</td>\n",
       "      <td>==========================\\n[] For pt's contin...</td>\n",
       "      <td>Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...</td>\n",
       "      <td>Dear Ms. ___,\\n\\nYou were admitted to ___ afte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id                   CC  \\\n",
       "0           0    10001884  24962904  Shortness of Breath   \n",
       "\n",
       "                                             Service Major Surgical Procedure  \\\n",
       "0  MEDICINE\\n \\nAllergies: \\nIV Dye, Iodine Conta...                      NaN   \n",
       "\n",
       "                                                 HPI  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "\n",
       "                                                 PMH  SOC  \\\n",
       "0  - COPD/Asthma on home 2L O2\\n- Atypical Chest ...  ___   \n",
       "\n",
       "                                                  FH  ... Problem List  \\\n",
       "0  Mother with asthma and hypertension. Father wi...  ...          NaN   \n",
       "\n",
       "                                       Physical Exam  \\\n",
       "0  ADMISSION PHYSICAL EXAM:\\n====================...   \n",
       "\n",
       "                                    Medication Lists  \\\n",
       "0  is accurate and complete.\\n1. Acetaminophen 32...   \n",
       "\n",
       "                                   Pertinent Results  \\\n",
       "0  ADMISSION LABS: \\n=========================\\n_...   \n",
       "\n",
       "                                                 BHC  \\\n",
       "0  Ms. ___ is a ___ female with history of \\nCOPD...   \n",
       "\n",
       "                                 Transitional Issues  \\\n",
       "0  ==========================\\n[] For pt's contin...   \n",
       "\n",
       "                                         Disposition  \\\n",
       "0  Extended Care\\n \\nFacility:\\n___\\n \\n___ Diagn...   \n",
       "\n",
       "                              Discharge Instructions Followup Instructions  \\\n",
       "0  Dear Ms. ___,\\n\\nYou were admitted to ___ afte...                   NaN   \n",
       "\n",
       "                                 Discharge Diagnosis  \n",
       "0  PRIMARY:\\nCOPD Exacerbation\\n\\nSECONDARY:\\nAfi...  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discharge_sections_df[discharge_sections_df['hadm_id']==24962904]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59b1ad5-183e-4632-ba3e-b69422e4779c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>EXAMINATION</th>\n",
       "      <th>INDICATION</th>\n",
       "      <th>TECHNIQUE</th>\n",
       "      <th>COMPARISON</th>\n",
       "      <th>FINDINGS</th>\n",
       "      <th>IMPRESSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001884</td>\n",
       "      <td>24962904</td>\n",
       "      <td>Chest:  Frontal and lateral views</td>\n",
       "      <td>History: ___ with dyspnea  // eval for pneumonia</td>\n",
       "      <td>Chest:  Frontal and Lateral</td>\n",
       "      <td>:  ___</td>\n",
       "      <td>Mild basilar atelectasis is seen without focal...</td>\n",
       "      <td>Mild basilar atelectasis without definite foca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id   hadm_id                        EXAMINATION  \\\n",
       "0           0    10001884  24962904  Chest:  Frontal and lateral views   \n",
       "\n",
       "                                         INDICATION  \\\n",
       "0  History: ___ with dyspnea  // eval for pneumonia   \n",
       "\n",
       "                     TECHNIQUE COMPARISON  \\\n",
       "0  Chest:  Frontal and Lateral     :  ___   \n",
       "\n",
       "                                            FINDINGS  \\\n",
       "0  Mild basilar atelectasis is seen without focal...   \n",
       "\n",
       "                                          IMPRESSION  \n",
       "0  Mild basilar atelectasis without definite foca...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiology_sections_df[radiology_sections_df['hadm_id']==24962904]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119ca17e-187d-4277-bca8-de378b53327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-5.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138d23c8-6c21-4963-bc23-18f5ed13c9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11f1bb798794961935bf5df91d68863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the radiological tests and findings Based on the following details: Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15\n",
      "___ 06:38AM BLOOD Calcium-9.8 Phos-4.1 Mg-2.0\n",
      "___ 06:38AM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 06:38AM BLOOD Lactate-1.5\n",
      "___ 06:38AM BLOOD proBNP-181\n",
      "___ 06:38AM BLOOD cTropnT-<0.01\n",
      "\n",
      "DIAGNOSIS: \n",
      "=========================\n",
      "Pneumonia due to Streptococcus pneumoniae.\n",
      "\n",
      "What are the radiological findings?\n",
      "What are the laboratory findings?\n",
      "What is the diagnosis?\n",
      "\n",
      "Based on the details provided, the radiological findings are:\n",
      "\n",
      "* Mild basilar atelectasis without definite focal consolidation (as seen on the frontal and lateral views of the chest X-ray)\n",
      "\n",
      "The laboratory findings are:\n",
      "\n",
      "* White blood cell count (WBC) of 7.1 x 10^9/L with a neutrophil count of 81.8%\n",
      "* Red blood cell count (RBC) of 4.74 x 10^12/L with a hemoglobin (Hb) level of 12.8 g/dL and a hematocrit (Hct) level of 41.1%\n",
      "* Mean corpuscular volume (MCV) of 87 fL, mean corpuscular hemoglobin (MCH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "def generate_summary(hadm_id, discharge_df, radiology_df, question):\n",
    "    # Columns relevant for the discharge summary and radiology summary\n",
    "    discharge_cols = ['Pertinent Results']\n",
    "    radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Prepare the input for the model\n",
    "    combined_input = f\"{question} Based on the following details: {radiology_info} {discharge_info}\"\n",
    "    inputs = tokenizer(combined_input, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=1024, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary(hadm_id, discharge_sections_df, radiology_sections_df, question)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8022fd-61a2-42a3-9297-7335608ff02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c21ea76c73461f873a37705412d375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m hadm_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m24962904\u001b[39m  \u001b[38;5;66;03m# example HADM ID\u001b[39;00m\n\u001b[1;32m     44\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarize the radiological tests and findings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 45\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhadm_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdischarge_sections_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradiology_sections_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m, in \u001b[0;36mgenerate_summary\u001b[0;34m(hadm_id, discharge_df, radiology_df, question)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Generate the response using the model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Decode and return the summary\u001b[39;00m\n\u001b[1;32m     27\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/generation/utils.py:1693\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1685\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1686\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1687\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1688\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1689\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1690\u001b[0m     )\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1709\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1710\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1711\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1717\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1718\u001b[0m     )\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/generation/utils.py:3612\u001b[0m, in \u001b[0;36mGenerationMixin._beam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3606\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3607\u001b[0m     outputs,\n\u001b[1;32m   3608\u001b[0m     model_kwargs,\n\u001b[1;32m   3609\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3610\u001b[0m )\n\u001b[1;32m   3611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3612\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_temporary_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_key_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\n\u001b[1;32m   3614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[1;32m   3617\u001b[0m     beam_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((beam_indices[beam_idx[i]] \u001b[38;5;241m+\u001b[39m (beam_idx[i],) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(beam_indices))))\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/generation/utils.py:2888\u001b[0m, in \u001b[0;36mGenerationMixin._temporary_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;66;03m# Exception 1: code path for models using the legacy cache format\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m-> 2888\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;66;03m# Exception 2: models with different cache formats. These are limited to `DynamicCache` until their\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;66;03m# cache format is standardized, to avoid adding complexity to the codebase.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbloom\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_class \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgptbigcode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_class:\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1342\u001b[0m, in \u001b[0;36mLlamaForCausalLM._reorder_cache\u001b[0;34m(past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   1339\u001b[0m reordered_past \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_past \u001b[38;5;129;01min\u001b[39;00m past_key_values:\n\u001b[1;32m   1341\u001b[0m     reordered_past \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1342\u001b[0m         \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1343\u001b[0m     )\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reordered_past\n",
      "File \u001b[0;32m~/discharge_me/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1342\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1339\u001b[0m reordered_past \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_past \u001b[38;5;129;01min\u001b[39;00m past_key_values:\n\u001b[1;32m   1341\u001b[0m     reordered_past \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1342\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m past_state \u001b[38;5;129;01min\u001b[39;00m layer_past),\n\u001b[1;32m   1343\u001b[0m     )\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reordered_past\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "def generate_summary(hadm_id, discharge_df, radiology_df, question):\n",
    "    # Columns relevant for the discharge summary and radiology summary\n",
    "    discharge_cols = ['Pertinent Results']\n",
    "    radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Prepare the input for the model\n",
    "    combined_input = f\"{question} Based on the following details: {radiology_info} {discharge_info}\"\n",
    "    inputs = tokenizer(combined_input, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=1024, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Assuming the summary starts after the question, you could use the following method to extract it:\n",
    "    # Find the end of the question in the summary\n",
    "    summary_start_idx = summary.find(question) + len(question)\n",
    "    if summary_start_idx >= len(question):\n",
    "        # Extract text after the question\n",
    "        summary = summary[summary_start_idx:].strip()\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary(hadm_id, discharge_sections_df, radiology_sections_df, question)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fca914-7667-4442-992f-f52f23fc9008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum input length of the model: 1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "# Access the model's configuration to find the maximum input length\n",
    "max_model_length = tokenizer.model_max_length\n",
    "print(\"Maximum input length of the model:\", max_model_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266b9163-82f2-4da2-b766-a2dddbbf9a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in input: 13\n",
      "The input text fits within the model's maximum input length.\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "input_text = \"Example input text that you want to process with the model.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=max_model_length)\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = tokens.input_ids.size(1)  # .size(1) gives the number of tokens (ignoring batch dimension)\n",
    "print(\"Number of tokens in input:\", num_tokens)\n",
    "\n",
    "# Compare with the model's max length\n",
    "if num_tokens > max_model_length:\n",
    "    print(\"The input text is too long and will be truncated.\")\n",
    "else:\n",
    "    print(\"The input text fits within the model's maximum input length.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7a08e-76b4-4e15-aacf-7101b5545c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "input_text = \"Example input text that you want to process with the model.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=max_model_length)\n",
    "\n",
    "# Get the number of tokens\n",
    "num_tokens = tokens.input_ids.size(1)  # .size(1) gives the number of tokens (ignoring batch dimension)\n",
    "print(\"Number of tokens in input:\", num_tokens)\n",
    "\n",
    "# Compare with the model's max length\n",
    "if num_tokens > max_model_length:\n",
    "    print(\"The input text is too long and will be truncated.\")\n",
    "else:\n",
    "    print(\"The input text fits within the model's maximum input length.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7731ac0-cf87-4d79-8b1f-3eaf6ba642e6",
   "metadata": {},
   "source": [
    "## Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7ed4da-8524-4379-9cee-0200945b70ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11000f6a5c644e6bfff65dbb00bb511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the following details: Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15\n",
      "___ 06:38AM BLOOD Calcium-9.8 Phos-4.1 Mg-2.0\n",
      "___ 06:38AM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 06:38AM BLOOD Lactate-1.5\n",
      "___ 06:38AM BLOOD proBNP-181\n",
      "___ 06:38AM BLOOD cTropnT-<0.01\n",
      "\n",
      "What are the radiological findings?\n",
      "What are the laboratory findings?\n",
      "What are the electrocardiogram (ECG) findings?\n",
      "What are the discharge laboratory findings?\n",
      "\n",
      "Based on the details provided, the radiological findings are:\n",
      "\n",
      "* Mild basilar atelectasis without definite focal consolidation on the chest X-ray.\n",
      "\n",
      "The laboratory findings are:\n",
      "\n",
      "* White blood cell count (WBC) of 7.1 x 10^9/L with a neutrophil count of 81.8%, lymphocyte count of 9.6%, monocyte count of 7.6%, and eosinophil count of 0.3%.\n",
      "* Red blood cell (RBC) count of 4.74 x 10^12/L with a hemoglobin (Hb) level of 12.8 g/dL, hematocrit (Hct) level of 41.1%, mean corpuscular volume (MCV) of 87 fL, mean corpuscular hemoglobin (MCH) level of 27.0 pg, and mean corpuscular hemoglobin concentration (MCHC) level of 31.1%.\n",
      "* Platelet count of 144 x 10^9/L.\n",
      "* Blood urea nitrogen (BUN) level of 18 mg/dL, creatinine level of 0.8 mg/dL, sodium level of 137 mM, potassium level of 3.1 mM (repleted), chloride level of 94 mM, and bicarbonate level of 31 mM.\n",
      "* Lactate level of 1.5 mM.\n",
      "* Pro-brain-type natriuretic peptide (proBNP) level of 181 pg/mL.\n",
      "\n",
      "The electrocardiogram (ECG) findings are:\n",
      "\n",
      "* Sinus rhythm at a heart rate of 69 beats per minute (bpm).\n",
      "* Left bundle branch block (LBBB).\n",
      "* No acute ST or T wave changes.\n",
      "\n",
      "The discharge laboratory findings are:\n",
      "\n",
      "* White blood cell count (WBC) of 14.4 x 10^9/L with a neutrophil count of 58.2%, lymphocyte count of 0.68%, monocyte count of 0.54%, and eosinophil count of 0.02%.\n",
      "* Red blood cell (RBC) count of 4.34 x 10^12/L with a hemoglobin (Hb) level of 11.8 g/dL, hematocrit (Hct) level of 37.6%, mean corpuscular volume (MCV) of 87 fL, mean corpuscular hemoglobin (MCH) level of 27.2 pg, and mean corpuscular hemoglobin concentration (MCHC) level of 31.4%.\n",
      "* Platelet count of 144 x 10^9/L.\n",
      "* Blood urea nitrogen (BUN) level of 18 mg/dL, creatinine level of 0.8 mg/dL, sodium level of 137 mM, potassium level of 3.1 mM (repleted), chloride level of 94 mM, and bicarbonate level of 31 mM.\n",
      "* Lactate level of 1.5 mM.\n",
      "* Pro-brain-type natriuretic peptide (proBNP) level of\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "def generate_summary(hadm_id, discharge_df, radiology_df, question):\n",
    "    # Columns relevant for the discharge summary and radiology summary\n",
    "    discharge_cols = ['Pertinent Results']\n",
    "    radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Prepare the input for the model\n",
    "    context = f\"{radiology_info} {discharge_info}\"\n",
    "    combined_input = f\"{question} Based on the following details: {context}\"\n",
    "    context_length = len(tokenizer.tokenize(context))\n",
    "\n",
    "    # Tokenize the input\n",
    "    max_input_length = min(1024 + context_length, tokenizer.model_max_length)  # to avoid exceeding the model's maximum capacity\n",
    "    inputs = tokenizer(combined_input, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
    "\n",
    "    # Generate the response using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=max_input_length, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Assuming the summary starts after the question, you could use the following method to extract it:\n",
    "    # Find the end of the question in the summary\n",
    "    summary_start_idx = summary.find(question) + len(question)\n",
    "    if summary_start_idx >= len(question):\n",
    "        # Extract text after the question\n",
    "        summary = summary[summary_start_idx:].strip()\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary(hadm_id, discharge_sections_df, radiology_sections_df, question)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59ded49-af6f-46bb-b5e6-b4b3c7d85dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Add token as git credential? (Y/n) Token is valid (permission: read).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n",
      "\n",
      "/usr/lib/python3.9/getpass.py:91: GetPassWarning: Can not control echo on the terminal.\n",
      "  passwd = fallback_getpass(prompt, stream)\n",
      "Warning: Password input may be echoed.\n",
      "Enter your token (input will not be visible): \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from config import HF_TOKEN\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "token = HF_TOKEN\n",
    "input_text = f\"{token}\\nY\\n\"  # Combine token and 'Y' input\n",
    "\n",
    "# Run the Huggingface CLI login command\n",
    "process = subprocess.Popen(['huggingface-cli', 'login'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate(input_text.encode())\n",
    "\n",
    "# Print any output or error if necessary (optional)\n",
    "print(stdout.decode())\n",
    "print(stderr.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b939360-0239-4de5-ae1c-4ff28efa7490",
   "metadata": {},
   "source": [
    "## Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667a1cd9-7342-4cc4-b106-872889ff28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q&A with model: Llama-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5d5e10b647432ebec4dd7bf95901f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: Context: Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15 \n",
      "\n",
      "Question: Based on the information provided, Summarize the radiological tests and findings \n",
      "\n",
      "Answer: Chest x-ray showed mild basilar atelectasis without definite focal consolidation. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely diagnosis? \n",
      "\n",
      "Answer: The most likely diagnosis is community-acquired pneumonia (CAP) based on the clinical presentation of dyspnea, fever, and cough, along with the presence of mild basilar atelectasis on chest x-ray. \n",
      "\n",
      "Question: Based on the information provided, What is the next best step in management? \n",
      "\n",
      "Answer: The next best step in management is to start antibiotics and initiate supplemental oxygen therapy as needed. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely complication of CAP? \n",
      "\n",
      "Answer: The most likely complication of CAP is respiratory failure, which can occur due to the presence of pneumonia, especially in patients with underlying lung disease. Other potential complications include sepsis and secondary infections such as empyema or lung abscess. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of respiratory failure in this patient? \n",
      "\n",
      "Answer: The most likely cause of respiratory failure in this patient is the presence of pneumonia, especially in the setting of underlying lung disease. Other potential causes of respiratory failure include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for respiratory failure in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for respiratory failure in this patient is to provide supplemental oxygen therapy as needed to maintain oxygen saturation levels above 90%. Other interventions such as noninvasive ventilation or intubation may be necessary in severe cases of respiratory failure. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of hypoxemia in this patient? \n",
      "\n",
      "Answer: The most likely cause of hypoxemia in this patient is the presence of pneumonia, especially in the setting of underlying lung disease. Other potential causes of hypoxemia include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for hypoxemia in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for hypoxemia in this patient is to provide supplemental oxygen therapy as needed to maintain oxygen saturation levels above 90%. Other interventions such as noninvasive ventilation or intubation may be necessary in severe cases of hypoxemia. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of tachypnea in this patient? \n",
      "\n",
      "Answer: The most likely cause of tachypnea in this patient is the presence of pneumonia, especially in the setting of underlying lung disease. Other potential causes of tachypnea include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for tachypnea in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for tachypnea in this patient is to provide supplemental oxygen therapy as needed to maintain oxygen saturation levels above 90%. Other interventions such as noninvasive ventilation or intubation may be necessary in severe cases of tachypnea. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of tachycardia in this patient? \n",
      "\n",
      "Answer: The most likely cause of tachycardia in this patient is the presence of fever and tachypnea, which can lead to increased sympathetic tone and increased heart rate. Other potential causes of tachycardia include sepsis, heart failure, and neuromuscular disorders. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for tachycardia in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for tachycardia in this patient is to treat the underlying cause (e.g., pneumonia) and monitor heart rate closely. If the heart rate remains elevated despite treatment, beta-blockers may be considered. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of bradycardia in this patient? \n",
      "\n",
      "Answer: The most likely cause of bradycardia in this patient is the presence of sepsis, which can lead to decreased sympathetic tone and decreased heart rate. Other potential causes of bradycardia include heart failure, neuromuscular disorders, and medications such as beta-blockers. \n",
      "\n",
      "Question: Based on the information provided, What is the most appropriate intervention for bradycardia in this patient? \n",
      "\n",
      "Answer: The most appropriate intervention for bradycardia in this patient is to treat the underlying cause (e.g., sepsis) and monitor heart rate closely. If the heart rate remains low despite treatment, atropine may be considered. \n",
      "\n",
      "Question: Based on the information provided, What is the most likely cause of hypertension in this patient? \n",
      "\n",
      "Answer: The most likely cause of hypertension in this patient is the presence of fever and tachycardia, which can lead to increased sympathetic tone and increased blood pressure. Other\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "\n",
    "def generate_summary_with_pipeline(hadm_id, discharge_df, radiology_df, question, discharge_cols, radiology_cols, tokenizer):\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Combine all relevant information into one context string\n",
    "    context = f\"{radiology_info} {discharge_info}\"\n",
    "    \n",
    "    # Prepare the final prompt for the model\n",
    "    final_prompt = f\"Context: {context} \\n\\nQuestion: Based on the information provided, {question} \\n\\nAnswer:\"\n",
    "    context_length = len(tokenizer.tokenize(final_prompt))\n",
    "    max_input_length = min(1024 + context_length, tokenizer.model_max_length)\n",
    "    \n",
    "    # Initialize the pipeline with the Llama-3 model\n",
    "    print(\"\\nQ&A with model: Llama-3\")\n",
    "    llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B')\n",
    "\n",
    "    # Generate the response using the model\n",
    "    generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\n",
    "\n",
    "    # Output the generated text\n",
    "    return generated_text[0]['generated_text']\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B')\n",
    "\n",
    "# Specify the columns to use\n",
    "discharge_cols = ['Pertinent Results']\n",
    "radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "summary = generate_summary_with_pipeline(hadm_id, discharge_sections_df, radiology_sections_df, question, discharge_cols, radiology_cols, tokenizer)\n",
    "print(\"Generated Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b93aa95-df69-4e47-9d43-662edf7c0a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting cmake>=3.21 (from vllm)\n",
      "  Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (5.9.8)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.31.0)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.40.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.19.1)\n",
      "Collecting fastapi (from vllm)\n",
      "  Using cached fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.7.1)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.20.0)\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.6.0)\n",
      "Collecting lm-format-enforcer==0.9.8 (from vllm)\n",
      "  Using cached lm_format_enforcer-0.9.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting outlines==0.0.34 (from vllm)\n",
      "  Using cached outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.11.0)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (3.13.4)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Using cached ray-2.20.0-cp39-cp39-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting nvidia-ml-py (from vllm)\n",
      "  Using cached nvidia_ml_py-12.550.52-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting vllm-nccl-cu12<2.19,>=2.18 (from vllm)\n",
      "  Using cached vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==2.2.1 (from vllm)\n",
      "  Using cached torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting xformers==0.0.25 (from vllm)\n",
      "  Using cached xformers-0.0.25-cp39-cp39-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (23.2)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (3.1.3)\n",
      "Collecting lark (from outlines==0.0.34->vllm)\n",
      "  Using cached lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.6.0)\n",
      "Collecting cloudpickle (from outlines==0.0.34->vllm)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines==0.0.34->vllm)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.13.0)\n",
      "Collecting numba (from outlines==0.0.34->vllm)\n",
      "  Using cached numba-0.59.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.4.0)\n",
      "Requirement already satisfied: referencing in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (0.35.0)\n",
      "Requirement already satisfied: jsonschema in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (4.21.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tiktoken==0.6.0->vllm) (2024.4.16)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch==2.2.1->vllm)\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (2.18.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (8.1.7)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm)\n",
      "  Using cached msgpack-1.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (5.26.1)\n",
      "Requirement already satisfied: aiosignal in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2024.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tokenizers>=0.19.1->vllm) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (4.66.2)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->vllm)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Using cached websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from starlette<0.38.0,>=0.37.2->fastapi->vllm) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.18.0)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->outlines==0.0.34->vllm)\n",
      "  Using cached llvmlite-0.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from sympy->torch==2.2.1->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.2.1)\n",
      "Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl (84.0 MB)\n",
      "Using cached lm_format_enforcer-0.9.8-py3-none-any.whl (40 kB)\n",
      "Using cached outlines-0.0.34-py3-none-any.whl (76 kB)\n",
      "Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m644.2/755.5 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 102, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"/usr/lib/python3.9/tempfile.py\", line 478, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/usr/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5c1549-41c5-4055-86c5-930c2431d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting cmake>=3.21 (from vllm)\n",
      "  Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (5.9.8)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.31.0)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.40.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.19.1)\n",
      "Collecting fastapi (from vllm)\n",
      "  Using cached fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (2.7.1)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.20.0)\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (0.6.0)\n",
      "Collecting lm-format-enforcer==0.9.8 (from vllm)\n",
      "  Using cached lm_format_enforcer-0.9.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting outlines==0.0.34 (from vllm)\n",
      "  Using cached outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (4.11.0)\n",
      "Requirement already satisfied: filelock>=3.10.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from vllm) (3.13.4)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Using cached ray-2.20.0-cp39-cp39-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting nvidia-ml-py (from vllm)\n",
      "  Using cached nvidia_ml_py-12.550.52-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting vllm-nccl-cu12<2.19,>=2.18 (from vllm)\n",
      "  Using cached vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==2.2.1 (from vllm)\n",
      "  Using cached torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting xformers==0.0.25 (from vllm)\n",
      "  Using cached xformers-0.0.25-cp39-cp39-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (23.2)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from lm-format-enforcer==0.9.8->vllm) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (3.1.3)\n",
      "Collecting lark (from outlines==0.0.34->vllm)\n",
      "  Using cached lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.6.0)\n",
      "Collecting cloudpickle (from outlines==0.0.34->vllm)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines==0.0.34->vllm)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.13.0)\n",
      "Collecting numba (from outlines==0.0.34->vllm)\n",
      "  Using cached numba-0.59.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (1.4.0)\n",
      "Requirement already satisfied: referencing in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (0.35.0)\n",
      "Requirement already satisfied: jsonschema in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from outlines==0.0.34->vllm) (4.21.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tiktoken==0.6.0->vllm) (2024.4.16)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from torch==2.2.1->vllm) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch==2.2.1->vllm)\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->vllm) (12.4.127)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from pydantic>=2.0->vllm) (2.18.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (8.1.7)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm)\n",
      "  Using cached msgpack-1.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (5.26.1)\n",
      "Requirement already satisfied: aiosignal in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from ray>=2.9->vllm) (1.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from requests->vllm) (2024.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from tokenizers>=0.19.1->vllm) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from transformers>=4.40.0->vllm) (4.66.2)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->vllm)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Using cached websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from starlette<0.38.0,>=0.37.2->fastapi->vllm) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.18.0)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->outlines==0.0.34->vllm)\n",
      "  Using cached llvmlite-0.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from sympy->torch==2.2.1->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/discharge_me/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm) (1.2.1)\n",
      "Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl (84.0 MB)\n",
      "Using cached lm_format_enforcer-0.9.8-py3-none-any.whl (40 kB)\n",
      "Using cached outlines-0.0.34-py3-none-any.whl (76 kB)\n",
      "Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m674.6/755.5 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m679.1/755.5 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d22a384-f533-495e-845c-b318a9427c8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vllm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM, SamplingParams\n\u001b[1;32m      2\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLM(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vllm'"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(model=\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15829a75-c32c-4377-bd7d-d64891240804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting cmake>=3.21 (from vllm)\n",
      "  Using cached cmake-3.29.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting psutil (from vllm)\n",
      "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Using cached sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting numpy (from vllm)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting requests (from vllm)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.40.0 (from vllm)\n",
      "  Using cached transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting tokenizers>=0.19.1 (from vllm)\n",
      "  Using cached tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting fastapi (from vllm)\n",
      "  Using cached fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pydantic>=2.0 (from vllm)\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "Collecting prometheus-client>=0.18.0 (from vllm)\n",
      "  Using cached prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tiktoken==0.6.0 (from vllm)\n",
      "  Using cached tiktoken-0.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting lm-format-enforcer==0.9.8 (from vllm)\n",
      "  Using cached lm_format_enforcer-0.9.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting outlines==0.0.34 (from vllm)\n",
      "  Using cached outlines-0.0.34-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting typing-extensions (from vllm)\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting filelock>=3.10.4 (from vllm)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Using cached ray-2.20.0-cp39-cp39-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting nvidia-ml-py (from vllm)\n",
      "  Using cached nvidia_ml_py-12.550.52-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting vllm-nccl-cu12<2.19,>=2.18 (from vllm)\n",
      "  Using cached vllm_nccl_cu12-2.18.1.0.4.0.tar.gz (6.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==2.2.1 (from vllm)\n",
      "  Using cached torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting xformers==0.0.25 (from vllm)\n",
      "  Using cached xformers-0.0.25-cp39-cp39-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml (from lm-format-enforcer==0.9.8->vllm)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting jinja2 (from outlines==0.0.34->vllm)\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting lark (from outlines==0.0.34->vllm)\n",
      "  Using cached lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting nest-asyncio (from outlines==0.0.34->vllm)\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting cloudpickle (from outlines==0.0.34->vllm)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines==0.0.34->vllm)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting scipy (from outlines==0.0.34->vllm)\n",
      "  Using cached scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting numba (from outlines==0.0.34->vllm)\n",
      "  Using cached numba-0.59.1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting joblib (from outlines==0.0.34->vllm)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting referencing (from outlines==0.0.34->vllm)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting jsonschema (from outlines==0.0.34->vllm)\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken==0.6.0->vllm)\n",
      "  Using cached regex-2024.4.28-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting sympy (from torch==2.2.1->vllm)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.2.1->vllm)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting fsspec (from torch==2.2.1->vllm)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.1->vllm)\n",
      "  Using cached triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->vllm)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->vllm)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic>=2.0->vllm)\n",
      "  Using cached pydantic_core-2.18.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting click>=7.0 (from ray>=2.9->vllm)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm)\n",
      "  Using cached msgpack-1.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray>=2.9->vllm)\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting aiosignal (from ray>=2.9->vllm)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist (from ray>=2.9->vllm)\n",
      "  Using cached frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->vllm)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->vllm)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->vllm)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->vllm)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.19.1->vllm)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.40.0->vllm)\n",
      "  Using cached safetensors-0.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers>=4.40.0->vllm)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->vllm)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Using cached uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Using cached watchfiles-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Using cached websockets-12.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting anyio<5,>=3.4.0 (from starlette<0.38.0,>=0.37.2->fastapi->vllm)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->outlines==0.0.34->vllm)\n",
      "  Using cached MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema->outlines==0.0.34->vllm)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->outlines==0.0.34->vllm)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->outlines==0.0.34->vllm)\n",
      "  Using cached rpds_py-0.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->outlines==0.0.34->vllm)\n",
      "  Using cached llvmlite-0.42.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.2.1->vllm)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->vllm)\n",
      "  Using cached exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Using cached vllm-0.4.1-cp39-cp39-manylinux1_x86_64.whl (84.0 MB)\n",
      "Using cached lm_format_enforcer-0.9.8-py3-none-any.whl (40 kB)\n",
      "Using cached outlines-0.0.34-py3-none-any.whl (76 kB)\n",
      "Using cached tiktoken-0.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "Downloading torch-2.2.1-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m698.4/755.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:16\u001b[0mm\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 102, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"/usr/lib/python3.9/tempfile.py\", line 478, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/usr/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/ubuntu/discharge_me/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15dbad19-a3dd-401f-ab4e-7d937e91db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                 Version\n",
      "--------------------------------------- --------------\n",
      "accelerate                              0.29.3\n",
      "aiohttp                                 3.9.5\n",
      "aiosignal                               1.3.1\n",
      "annotated-types                         0.6.0\n",
      "anyio                                   4.3.0\n",
      "argon2-cffi                             23.1.0\n",
      "argon2-cffi-bindings                    21.2.0\n",
      "arrow                                   1.3.0\n",
      "asttokens                               2.4.1\n",
      "async-lru                               2.0.4\n",
      "async-timeout                           4.0.3\n",
      "attrs                                   23.2.0\n",
      "Babel                                   2.14.0\n",
      "beautifulsoup4                          4.12.3\n",
      "bitsandbytes                            0.43.1\n",
      "bleach                                  6.1.0\n",
      "certifi                                 2024.2.2\n",
      "cffi                                    1.16.0\n",
      "charset-normalizer                      3.3.2\n",
      "click                                   8.1.7\n",
      "comm                                    0.2.2\n",
      "dataclasses-json                        0.6.5\n",
      "debugpy                                 1.8.1\n",
      "decorator                               5.1.1\n",
      "defusedxml                              0.7.1\n",
      "Deprecated                              1.2.14\n",
      "dirtyjson                               1.0.8\n",
      "distro                                  1.9.0\n",
      "einops                                  0.8.0\n",
      "exceptiongroup                          1.2.1\n",
      "executing                               2.0.1\n",
      "fastjsonschema                          2.19.1\n",
      "filelock                                3.13.4\n",
      "fqdn                                    1.5.1\n",
      "frozenlist                              1.4.1\n",
      "fsspec                                  2024.3.1\n",
      "greenlet                                3.0.3\n",
      "h11                                     0.14.0\n",
      "httpcore                                1.0.5\n",
      "httpx                                   0.27.0\n",
      "huggingface-hub                         0.20.3\n",
      "idna                                    3.7\n",
      "importlib_metadata                      7.1.0\n",
      "install                                 1.3.5\n",
      "ipykernel                               6.29.4\n",
      "ipython                                 8.18.1\n",
      "ipywidgets                              8.1.2\n",
      "isoduration                             20.11.0\n",
      "jedi                                    0.19.1\n",
      "Jinja2                                  3.1.3\n",
      "joblib                                  1.4.0\n",
      "json5                                   0.9.25\n",
      "jsonpatch                               1.33\n",
      "jsonpointer                             2.4\n",
      "jsonschema                              4.21.1\n",
      "jsonschema-specifications               2023.12.1\n",
      "jupyter                                 1.0.0\n",
      "jupyter_client                          8.6.1\n",
      "jupyter-console                         6.6.3\n",
      "jupyter_core                            5.7.2\n",
      "jupyter-events                          0.10.0\n",
      "jupyter-lsp                             2.2.5\n",
      "jupyter_server                          2.14.0\n",
      "jupyter_server_terminals                0.5.3\n",
      "jupyterlab                              4.1.6\n",
      "jupyterlab_pygments                     0.3.0\n",
      "jupyterlab_server                       2.27.1\n",
      "jupyterlab_widgets                      3.0.10\n",
      "langchain                               0.1.16\n",
      "langchain-community                     0.0.34\n",
      "langchain-core                          0.1.47\n",
      "langchain-text-splitters                0.0.1\n",
      "langsmith                               0.1.52\n",
      "llama-index                             0.10.33\n",
      "llama-index-agent-openai                0.2.3\n",
      "llama-index-cli                         0.1.12\n",
      "llama-index-core                        0.10.33\n",
      "llama-index-embeddings-huggingface      0.2.0\n",
      "llama-index-embeddings-langchain        0.1.2\n",
      "llama-index-embeddings-openai           0.1.9\n",
      "llama-index-indices-managed-llama-cloud 0.1.6\n",
      "llama-index-legacy                      0.9.48\n",
      "llama-index-llms-huggingface            0.1.4\n",
      "llama-index-llms-openai                 0.1.16\n",
      "llama-index-multi-modal-llms-openai     0.1.5\n",
      "llama-index-program-openai              0.1.6\n",
      "llama-index-question-gen-openai         0.1.3\n",
      "llama-index-readers-file                0.1.19\n",
      "llama-index-readers-llama-parse         0.1.4\n",
      "llama-parse                             0.4.2\n",
      "llamaindex-py-client                    0.1.19\n",
      "MarkupSafe                              2.1.5\n",
      "marshmallow                             3.21.1\n",
      "matplotlib-inline                       0.1.7\n",
      "mistune                                 3.0.2\n",
      "mpmath                                  1.3.0\n",
      "multidict                               6.0.5\n",
      "mypy-extensions                         1.0.0\n",
      "nbclient                                0.10.0\n",
      "nbconvert                               7.16.3\n",
      "nbformat                                5.10.4\n",
      "nest-asyncio                            1.6.0\n",
      "networkx                                3.2.1\n",
      "nltk                                    3.8.1\n",
      "notebook                                7.1.3\n",
      "notebook_shim                           0.2.4\n",
      "numpy                                   1.26.4\n",
      "nvidia-cublas-cu12                      12.1.3.1\n",
      "nvidia-cuda-cupti-cu12                  12.1.105\n",
      "nvidia-cuda-nvrtc-cu12                  12.1.105\n",
      "nvidia-cuda-runtime-cu12                12.1.105\n",
      "nvidia-cudnn-cu12                       8.9.2.26\n",
      "nvidia-cufft-cu12                       11.0.2.54\n",
      "nvidia-curand-cu12                      10.3.2.106\n",
      "nvidia-cusolver-cu12                    11.4.5.107\n",
      "nvidia-cusparse-cu12                    12.1.0.106\n",
      "nvidia-nccl-cu12                        2.20.5\n",
      "nvidia-nvjitlink-cu12                   12.4.127\n",
      "nvidia-nvtx-cu12                        12.1.105\n",
      "openai                                  1.25.0\n",
      "orjson                                  3.10.1\n",
      "overrides                               7.7.0\n",
      "packaging                               23.2\n",
      "pandas                                  2.2.2\n",
      "pandocfilters                           1.5.1\n",
      "parso                                   0.8.4\n",
      "pexpect                                 4.9.0\n",
      "pillow                                  10.3.0\n",
      "pip                                     24.0\n",
      "platformdirs                            4.2.1\n",
      "prometheus_client                       0.20.0\n",
      "prompt-toolkit                          3.0.43\n",
      "protobuf                                5.26.1\n",
      "psutil                                  5.9.8\n",
      "ptyprocess                              0.7.0\n",
      "pure-eval                               0.2.2\n",
      "pycparser                               2.22\n",
      "pydantic                                2.7.1\n",
      "pydantic_core                           2.18.2\n",
      "Pygments                                2.17.2\n",
      "pypdf                                   4.2.0\n",
      "python-dateutil                         2.9.0.post0\n",
      "python-json-logger                      2.0.7\n",
      "pytz                                    2024.1\n",
      "PyYAML                                  6.0.1\n",
      "pyzmq                                   26.0.2\n",
      "qtconsole                               5.5.1\n",
      "QtPy                                    2.4.1\n",
      "referencing                             0.35.0\n",
      "regex                                   2024.4.16\n",
      "requests                                2.31.0\n",
      "rfc3339-validator                       0.1.4\n",
      "rfc3986-validator                       0.1.1\n",
      "rpds-py                                 0.18.0\n",
      "safetensors                             0.4.3\n",
      "scikit-learn                            1.4.2\n",
      "scipy                                   1.13.0\n",
      "Send2Trash                              1.8.3\n",
      "sentence-transformers                   2.7.0\n",
      "sentencepiece                           0.2.0\n",
      "setuptools                              69.2.0\n",
      "six                                     1.16.0\n",
      "sniffio                                 1.3.1\n",
      "soupsieve                               2.5\n",
      "SQLAlchemy                              2.0.29\n",
      "stack-data                              0.6.3\n",
      "striprtf                                0.0.26\n",
      "sympy                                   1.12\n",
      "tenacity                                8.2.3\n",
      "terminado                               0.18.1\n",
      "threadpoolctl                           3.5.0\n",
      "tiktoken                                0.6.0\n",
      "tinycss2                                1.3.0\n",
      "tokenizers                              0.19.1\n",
      "tomli                                   2.0.1\n",
      "torch                                   2.3.0\n",
      "tornado                                 6.4\n",
      "tqdm                                    4.66.2\n",
      "traitlets                               5.14.3\n",
      "transformers                            4.40.1\n",
      "triton                                  2.3.0\n",
      "types-python-dateutil                   2.9.0.20240316\n",
      "typing_extensions                       4.11.0\n",
      "typing-inspect                          0.9.0\n",
      "tzdata                                  2024.1\n",
      "uri-template                            1.3.0\n",
      "urllib3                                 2.2.1\n",
      "wcwidth                                 0.2.13\n",
      "webcolors                               1.13\n",
      "webencodings                            0.5.1\n",
      "websocket-client                        1.8.0\n",
      "wheel                                   0.43.0\n",
      "widgetsnbextension                      4.0.10\n",
      "wrapt                                   1.16.0\n",
      "yarl                                    1.9.4\n",
      "zipp                                    3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a56fe6-8e42-41f2-874b-3010b2ff33d4",
   "metadata": {},
   "source": [
    "## Meta-Llama-3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664a6955-f33d-4306-b141-c98fc5862ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q&A with model: Llama-3 8B Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c628f90369746cd9a2a163e240b5245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: Imagine you are an EHR (Electronic Health Records) summarizing machine, and given the below context:\n",
      "\n",
      "Chest:  Frontal and lateral views History: ___ with dyspnea  // eval for pneumonia Mild basilar atelectasis without definite focal consolidation. ADMISSION LABS: \n",
      "=========================\n",
      "___ 05:54PM BLOOD WBC-7.1 RBC-4.74 Hgb-12.8 Hct-41.1 MCV-87 \n",
      "MCH-27.0 MCHC-31.1* RDW-22.6* RDWSD-69.0* Plt ___\n",
      "___ 05:54PM BLOOD Neuts-81.8* Lymphs-9.6* Monos-7.6 \n",
      "Eos-0.3* Baso-0.1 Im ___ AbsNeut-5.82 AbsLymp-0.68* \n",
      "AbsMono-0.54 AbsEos-0.02* AbsBaso-0.01\n",
      "___ 06:35AM BLOOD Calcium-9.9 Phos-4.1 Mg-2.0\n",
      "___ 05:54PM BLOOD ___ pO2-52* pCO2-49* pH-7.43 \n",
      "calTCO2-34* Base XS-6\n",
      "___ 05:54PM BLOOD Lactate-1.5\n",
      "___ 05:54PM BLOOD proBNP-181\n",
      "___ 05:54PM BLOOD cTropnT-<0.01\n",
      "\n",
      "STUDIES: \n",
      "=========================\n",
      "+ CXR (___): Mild basilar atelectasis without definite focal \n",
      "consolidation.\n",
      "+ EKG: Sinus rhythm at 69, left bundle branch block, no acute ST \n",
      "or T wave changes.\n",
      "\n",
      "DISCHARGE LABS: \n",
      "=========================\n",
      "___ 06:38AM BLOOD WBC-14.4*# RBC-4.34 Hgb-11.8 Hct-37.6 \n",
      "MCV-87 MCH-27.2 MCHC-31.4* RDW-22.5* RDWSD-69.4* Plt ___\n",
      "___ 06:38AM BLOOD Glucose-113* UreaN-18 Creat-0.8 Na-137 \n",
      "K-3.1(repleted)* Cl-94* HCO3-31 AnGap-15\n",
      "\n",
      "Answer the following question:Summarize the radiological tests and findings \n",
      "\n",
      "Answer: \n",
      "\n",
      "Answer: The radiological tests include a Chest X-ray (CXR) and an Electrocardiogram (EKG). \n",
      "The findings are: \n",
      "- Mild basilar atelectasis without definite focal consolidation on the CXR. \n",
      "- Sinus rhythm at 69, left bundle branch block, no acute ST or T wave changes on the EKG. \n",
      "- No acute ST or T wave changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "- No acute changes. \n",
      "- No focal consolidation. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "def generate_summary_with_pipeline(hadm_id, discharge_df, radiology_df, question, discharge_cols, radiology_cols, tokenizer):\n",
    "    # Filter DataFrames for the given HADM ID\n",
    "    discharge_info = discharge_df[discharge_df['hadm_id'] == hadm_id][discharge_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "    radiology_info = radiology_df[radiology_df['hadm_id'] == hadm_id][radiology_cols].fillna('').agg(' '.join, axis=1).values[0]\n",
    "\n",
    "    # Combine all relevant information into one context string\n",
    "    context = f\"{radiology_info} {discharge_info}\"\n",
    "    \n",
    "    # Prepare the final prompt for the model\n",
    "    final_prompt = f\"Imagine you are an EHR (Electronic Health Records) summarizing machine, and given the below context:\\n\\n{context}\\n\\nAnswer the following question:{question} \\n\\nAnswer:\"\n",
    "    context_length = len(tokenizer.tokenize(final_prompt))\n",
    "    max_input_length = min(1024 + context_length, tokenizer.model_max_length)\n",
    "    \n",
    "    # Initialize the pipeline with the Llama-3 model\n",
    "    print(\"\\nQ&A with model: Llama-3 8B Instruct\")\n",
    "    sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=max_input_length)    \n",
    "       \n",
    "    # llama_pipe = pipeline('text-generation', model='meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "    # # Generate the response using the model\n",
    "    # generated_text = llama_pipe(final_prompt, max_length=max_input_length, num_return_sequences=1)\n",
    "    outputs = llm.generate(prompt, sampling_params)\n",
    "    answer_texts = [output.outputs[0].text for output in outputs]\n",
    "\n",
    "    # Output the generated text\n",
    "    return contexts, answer_texts\n",
    "\n",
    "# Load your data\n",
    "discharge_sections_df = pd.read_csv('discharge_sections.csv')\n",
    "radiology_sections_df = pd.read_csv('radiology_sections.csv')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "# Specify the columns to use\n",
    "discharge_cols = ['Pertinent Results']\n",
    "radiology_cols = ['EXAMINATION', 'INDICATION', 'IMPRESSION']\n",
    "\n",
    "# Example usage\n",
    "hadm_id = 24962904  # example HADM ID\n",
    "question = \"Summarize the radiological tests and findings\"\n",
    "context, summary = generate_summary_with_pipeline(hadm_id, discharge_sections_df, radiology_sections_df, question, discharge_cols, radiology_cols, tokenizer)\n",
    "print(\"Context: \", context)\n",
    "print(\"Generated Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa554dc-e0cd-4e13-945b-4473f49098e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
